{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ray\n",
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "class ProgressTracker:\n",
    "    \"\"\"ì§„í–‰ë¥  ì¶”ì ì„ ìœ„í•œ Ray Actor\"\"\"\n",
    "    def __init__(self, total_files: int):\n",
    "        self.total_files = total_files\n",
    "        self.completed_files = 0\n",
    "        self.failed_files = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def update_progress(self, success: bool = True):\n",
    "        if success:\n",
    "            self.completed_files += 1\n",
    "        else:\n",
    "            self.failed_files += 1\n",
    "            \n",
    "        progress = (self.completed_files + self.failed_files) / self.total_files * 100\n",
    "        elapsed = time.time() - self.start_time\n",
    "        \n",
    "        if (self.completed_files + self.failed_files) > 0:\n",
    "            avg_time = elapsed / (self.completed_files + self.failed_files)\n",
    "            remaining = (self.total_files - self.completed_files - self.failed_files) * avg_time\n",
    "            \n",
    "            print(f\"ğŸ“Š ì§„í–‰ë¥ : {progress:.1f}% | ì„±ê³µ: {self.completed_files} | ì‹¤íŒ¨: {self.failed_files} | \"\n",
    "                  f\"ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: {format_duration(remaining)}\")\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            'total_files': self.total_files,\n",
    "            'completed': self.completed_files,\n",
    "            'failed': self.failed_files,\n",
    "            'total_duration': time.time() - self.start_time\n",
    "        }\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def preprocess_batch_parallel(batch_data: pd.DataFrame, car_info: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"ë°°ì¹˜ ë°ì´í„° ë³‘ë ¬ ì „ì²˜ë¦¬\"\"\"\n",
    "    df = batch_data.copy()\n",
    "    \n",
    "    # í•„ë“œëª…ì—ì„œ ê³µë°± ì œê±°\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # í•„ë“œ ìˆœì„œë¥¼ ì•ŒíŒŒë²³ ìˆœìœ¼ë¡œ ì¬ì •ë ¬ (clientid, timestampëŠ” ì•ì— ìœ ì§€)\n",
    "    cols_sorted = cols[0:2] + sorted(cols[2:])\n",
    "    df = df[cols_sorted]\n",
    "    \n",
    "    # ' None' ë˜ëŠ” 'None'ì„ NaNìœ¼ë¡œ ë³€ê²½\n",
    "    df.replace([' None', 'None'], np.nan, inplace=True)\n",
    "    \n",
    "    # ì˜¤ë¥˜ ê°’ ì²˜ë¦¬ (clientid, timestamp ì œì™¸)\n",
    "    target_cols = cols_sorted[2:]\n",
    "    \n",
    "    # ìˆ«ì ê°’ì„ float íƒ€ì…ìœ¼ë¡œ ë³€ê²½\n",
    "    for field in target_cols:\n",
    "        try:\n",
    "            df[field] = df[field].astype(float)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # SOC, SOH í•„ë“œ ê²€ì¦ (0~100 ë²”ìœ„)\n",
    "    soc_soh_cols = [col for col in target_cols if 'soc' in col or 'soh' in col]\n",
    "    for col in soc_soh_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < 0 or val > 100)) else val)\n",
    "    \n",
    "    # ì „ì•• í•„ë“œ ê²€ì¦ (3000 ì´í•˜)\n",
    "    voltage_cols = [col for col in target_cols if '_v' in col]\n",
    "    for col in voltage_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and val > 3000) else val)\n",
    "    \n",
    "    # ì˜¨ë„ í•„ë“œ ê²€ì¦ (-35 ~ 80ë„)\n",
    "    temp_cols = [col for col in target_cols if 'temperature' in col]\n",
    "    for col in temp_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < -35 or val > 80)) else val)\n",
    "    \n",
    "    # ì „ë¥˜ í•„ë“œ ê²€ì¦ (-500 ~ 500)\n",
    "    current_cols = [col for col in target_cols if 'curr' in col or col.startswith('cell')]\n",
    "    for col in current_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < -500 or val > 500)) else val)\n",
    "    \n",
    "    # ì†ë„ í•„ë“œ ê²€ì¦ (0 ~ 180)\n",
    "    speed_cols = [col for col in target_cols if 'speed' in col]\n",
    "    for col in speed_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < 0 or val > 180)) else val)\n",
    "    \n",
    "    # ëˆ„ì ì£¼í–‰ê±°ë¦¬ í•„ë“œ ê²€ì¦ (0 ì´ˆê³¼ ~ 2,000,000 ì´í•˜)\n",
    "    mileage_cols = [col for col in target_cols if 'mileage' in col]\n",
    "    for col in mileage_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val <= 0 or val > 2000000)) else val)\n",
    "    \n",
    "    # ì°¨ì¢… ì •ë³´ ì¶”ê°€\n",
    "    df['car_type'] = car_info.get('car_type', np.nan)\n",
    "    df['model_year'] = car_info.get('model_year', np.nan)\n",
    "    df['model_month'] = car_info.get('model_month', np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def preproc_betterwhy_parallel(csv_file: str, output_dir: str, remove_duplicates: bool = True, \n",
    "                              progress_tracker=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    ë‹¨ì¼ CSV íŒŒì¼ì„ ë³‘ë ¬ë¡œ ì „ì²˜ë¦¬\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"ğŸ”„ ì²˜ë¦¬ ì‹œì‘: {os.path.basename(csv_file)}\")\n",
    "        file_start_time = time.time()\n",
    "        \n",
    "        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì •\n",
    "        batch_size = 30000  # ë³‘ë ¬ì²˜ë¦¬ì‹œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ ì¡°ê¸ˆ ì¤„ì„\n",
    "        skip_rows = 0\n",
    "        batch_futures = []\n",
    "        car_info = {}\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ ë°°ì¹˜ì—ì„œ ì°¨ëŸ‰ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "        first_batch = pd.read_csv(csv_file, nrows=1000, low_memory=False)\n",
    "        if not first_batch.empty:\n",
    "            carid = first_batch.iloc[0][\"clientid\"]\n",
    "            \n",
    "            # ì°¨ëŸ‰ íƒ€ì… ì •ë³´ ë¡œë“œ\n",
    "            try:\n",
    "                carid_df = pd.read_csv(\"/Users/moon/ev_streamlit/preproc/betterwhy_cartype_list.csv\")\n",
    "                result = carid_df[carid_df['client_id'] == carid]\n",
    "                \n",
    "                if len(result) > 0:\n",
    "                    row = result.iloc[0]\n",
    "                    car_info = {\n",
    "                        'car_type': row['car_type'],\n",
    "                        'model_year': row['model_year'],\n",
    "                        'model_month': row['model_month']\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"{os.path.basename(csv_file)}: clientidë¡œ car_typeì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                    car_info = {'car_type': np.nan, 'model_year': np.nan, 'model_month': np.nan}\n",
    "            except Exception as e:\n",
    "                print(f\"ì°¨ëŸ‰ íƒ€ì… ì •ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "                car_info = {'car_type': np.nan, 'model_year': np.nan, 'model_month': np.nan}\n",
    "        \n",
    "        # CSV íŒŒì¼ì„ ë°°ì¹˜ë¡œ ì½ì–´ì„œ ë³‘ë ¬ ì²˜ë¦¬\n",
    "        while True:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file, skiprows=skip_rows, nrows=batch_size, low_memory=False)\n",
    "                \n",
    "                if df.empty:\n",
    "                    break\n",
    "                \n",
    "                # ë°°ì¹˜ë¥¼ ë³‘ë ¬ë¡œ ì „ì²˜ë¦¬\n",
    "                batch_future = preprocess_batch_parallel.remote(df, car_info)\n",
    "                batch_futures.append(batch_future)\n",
    "                \n",
    "                skip_rows += batch_size\n",
    "                \n",
    "            except Exception as e:\n",
    "                if 'No columns to parse from file' in str(e):\n",
    "                    break\n",
    "                else:\n",
    "                    raise e\n",
    "        \n",
    "        if not batch_futures:\n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(False)\n",
    "            return {'success': False, 'error': 'ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}\n",
    "        \n",
    "        # ëª¨ë“  ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ì§‘\n",
    "        print(f\"ğŸ“¦ {os.path.basename(csv_file)}: {len(batch_futures)}ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\")\n",
    "        processed_batches = ray.get(batch_futures)\n",
    "        \n",
    "        # ëª¨ë“  ë°°ì¹˜ ë°ì´í„° ê²°í•©\n",
    "        final_df = pd.concat(processed_batches, ignore_index=True)\n",
    "        \n",
    "        # ì‹œê°„ìˆœ ì •ë ¬\n",
    "        final_df.sort_values(by='timestamp', inplace=True)\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Client IDë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì €ì¥\n",
    "        saved_files = save_by_client_id_parallel(final_df, output_dir, remove_duplicates)\n",
    "        \n",
    "        processing_time = time.time() - file_start_time\n",
    "        \n",
    "        if saved_files:\n",
    "            # ì €ì¥ ì„±ê³µ ì‹œ ì›ë³¸ íŒŒì¼ ì‚­ì œ\n",
    "            os.remove(csv_file)\n",
    "            \n",
    "            # ì›ë³¸ íŒŒì¼ì´ ìˆë˜ ë””ë ‰í† ë¦¬ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì‚­ì œ\n",
    "            original_dir = os.path.dirname(csv_file)\n",
    "            if original_dir and not os.listdir(original_dir):\n",
    "                os.rmdir(original_dir)\n",
    "            \n",
    "            result = {\n",
    "                'success': True,\n",
    "                'file': csv_file,\n",
    "                'saved_files': len(saved_files),\n",
    "                'rows_processed': len(final_df),\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "            \n",
    "            print(f\"âœ… {os.path.basename(csv_file)}: ì™„ë£Œ ({len(final_df):,}í–‰, {format_duration(processing_time)})\")\n",
    "            \n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(True)\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(False)\n",
    "            return {'success': False, 'error': 'íŒŒì¼ ì €ì¥ ì‹¤íŒ¨'}\n",
    "            \n",
    "    except Exception as e:\n",
    "        if progress_tracker:\n",
    "            progress_tracker.update_progress.remote(False)\n",
    "        return {'success': False, 'error': str(e), 'file': csv_file}\n",
    "\n",
    "\n",
    "def save_by_client_id_parallel(df: pd.DataFrame, output_dir: str, remove_duplicates: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Client IDë³„ë¡œ CSV íŒŒì¼ ì €ì¥ (ë³‘ë ¬ì²˜ë¦¬ ë²„ì „)\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    try:\n",
    "        # Client IDë³„ë¡œ ê·¸ë£¹í™”\n",
    "        grouped = df.groupby('clientid')\n",
    "        \n",
    "        for client_id, new_data in grouped:\n",
    "            # ì‹œì‘ ë‚ ì§œ ì¶”ì¶œ\n",
    "            try:\n",
    "                new_data_copy = new_data.copy()\n",
    "                new_data_copy['timestamp'] = pd.to_datetime(new_data_copy['timestamp'])\n",
    "                start_date = new_data_copy['timestamp'].min()\n",
    "                \n",
    "                year_month = start_date.strftime('%y%m')\n",
    "                start_date_str = start_date.strftime('%y%m%d')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"ë‚ ì§œ ë³€í™˜ ì˜¤ë¥˜ (Client {client_id}): {e}\")\n",
    "                now = datetime.now()\n",
    "                year_month = now.strftime('%y%m')\n",
    "                start_date_str = now.strftime('%y%m%d')\n",
    "            \n",
    "            # ì›”ë³„ í´ë” ê²½ë¡œ ìƒì„±\n",
    "            monthly_dir = os.path.join(output_dir, year_month)\n",
    "            os.makedirs(monthly_dir, exist_ok=True)\n",
    "            \n",
    "            # íŒŒì¼ëª… ìƒì„±\n",
    "            safe_client_id = str(client_id).replace('/', '_').replace('\\\\', '_')\n",
    "            filename = f\"{safe_client_id}_{start_date_str}.csv\"\n",
    "            filepath = os.path.join(monthly_dir, filename)\n",
    "            \n",
    "            # ê¸°ì¡´ íŒŒì¼ë“¤ í™•ì¸\n",
    "            existing_files = find_existing_client_files(output_dir, safe_client_id)\n",
    "            \n",
    "            if existing_files:\n",
    "                # ê¸°ì¡´ íŒŒì¼ë“¤ê³¼ ë³‘í•©\n",
    "                combined_data = merge_with_existing_files(existing_files, new_data, client_id, remove_duplicates)\n",
    "                save_data_by_month(combined_data, output_dir, safe_client_id)\n",
    "            else:\n",
    "                # ìƒˆ íŒŒì¼ ìƒì„±\n",
    "                if remove_duplicates:\n",
    "                    new_data = remove_duplicate_records(new_data, client_id)\n",
    "                \n",
    "                new_data.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            \n",
    "            saved_files.append(filepath)\n",
    "        \n",
    "        return saved_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def find_existing_client_files(output_dir: str, safe_client_id: str) -> List[str]:\n",
    "    \"\"\"íŠ¹ì • í´ë¼ì´ì–¸íŠ¸ì˜ ê¸°ì¡´ íŒŒì¼ë“¤ì„ ëª¨ë‘ ì°¾ê¸°\"\"\"\n",
    "    existing_files = []\n",
    "    pattern = os.path.join(output_dir, \"*\", f\"clientid_{safe_client_id}_*.csv\")\n",
    "    existing_files = glob.glob(pattern)\n",
    "    return existing_files\n",
    "\n",
    "\n",
    "def merge_with_existing_files(existing_files: List[str], new_data: pd.DataFrame, \n",
    "                            client_id: str, remove_duplicates: bool) -> pd.DataFrame:\n",
    "    \"\"\"ê¸°ì¡´ íŒŒì¼ë“¤ê³¼ ìƒˆ ë°ì´í„°ë¥¼ ë³‘í•©\"\"\"\n",
    "    try:\n",
    "        all_data = [new_data]\n",
    "        total_existing_rows = 0\n",
    "        \n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                existing_df = pd.read_csv(file_path, low_memory=False)\n",
    "                all_data.append(existing_df)\n",
    "                total_existing_rows += len(existing_df)\n",
    "            except Exception as e:\n",
    "                print(f\"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ {file_path}: {e}\")\n",
    "        \n",
    "        # ëª¨ë“  ë°ì´í„° ê²°í•©\n",
    "        combined_data = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # ì¤‘ë³µ ì œê±°\n",
    "        if remove_duplicates:\n",
    "            combined_data = remove_duplicate_records(combined_data, client_id)\n",
    "        \n",
    "        # ì‹œê°„ìˆœ ì •ë ¬\n",
    "        combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "        combined_data.sort_values(by='timestamp', inplace=True)\n",
    "        combined_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # ê¸°ì¡´ íŒŒì¼ë“¤ ì‚­ì œ\n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ {file_path}: {e}\")\n",
    "        \n",
    "        return combined_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client {client_id}): {e}\")\n",
    "        return new_data\n",
    "\n",
    "\n",
    "def save_data_by_month(df: pd.DataFrame, output_dir: str, safe_client_id: str):\n",
    "    \"\"\"ë°ì´í„°ë¥¼ ì›”ë³„ë¡œ ë¶„í• í•˜ì—¬ CSVë¡œ ì €ì¥\"\"\"\n",
    "    try:\n",
    "        # ì›”ë³„ë¡œ ê·¸ë£¹í™”\n",
    "        df['year_month'] = df['timestamp'].dt.strftime('%y%m')\n",
    "        monthly_groups = df.groupby('year_month')\n",
    "        \n",
    "        for year_month, month_data in monthly_groups:\n",
    "            start_date_str = month_data['timestamp'].min().strftime('%y%m%d')\n",
    "            \n",
    "            monthly_dir = os.path.join(output_dir, year_month)\n",
    "            os.makedirs(monthly_dir, exist_ok=True)\n",
    "            \n",
    "            filename = f\"{safe_client_id}_{start_date_str}.csv\"\n",
    "            filepath = os.path.join(monthly_dir, filename)\n",
    "            \n",
    "            month_data_clean = month_data.drop('year_month', axis=1)\n",
    "            month_data_clean.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "\n",
    "\n",
    "def remove_duplicate_records(df: pd.DataFrame, client_id: str) -> pd.DataFrame:\n",
    "    \"\"\"ì¤‘ë³µ ë ˆì½”ë“œ ì œê±° (timestamp ê¸°ì¤€)\"\"\"\n",
    "    try:\n",
    "        df_deduplicated = df.drop_duplicates(subset=['clientid', 'timestamp'], keep='last')\n",
    "        \n",
    "        original_count = len(df)\n",
    "        final_count = len(df_deduplicated)\n",
    "        \n",
    "        if original_count != final_count:\n",
    "            print(f\"  Client {client_id}: ì¤‘ë³µ ì œê±° ({original_count} -> {final_count})\")\n",
    "        \n",
    "        return df_deduplicated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ì¤‘ë³µ ì œê±° ì¤‘ ì˜¤ë¥˜ (Client {client_id}): {e}\")\n",
    "        return df\n",
    "\n",
    "\n",
    "def process_multiple_files_parallel(csv_files: List[str], output_dir: str = \"processed\", \n",
    "                                   remove_duplicates: bool = True, max_workers: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Rayë¥¼ ì‚¬ìš©í•œ ë³‘ë ¬ íŒŒì¼ ì²˜ë¦¬\n",
    "    \n",
    "    Args:\n",
    "        csv_files: ì²˜ë¦¬í•  CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸\n",
    "        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬\n",
    "        remove_duplicates: ì¤‘ë³µ ë°ì´í„° ì œê±° ì—¬ë¶€\n",
    "        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜ ì‚¬ìš©)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ray ì´ˆê¸°í™”\n",
    "    if not ray.is_initialized():\n",
    "        # CPU ì½”ì–´ ìˆ˜ì˜ 80% ì‚¬ìš© (ì‹œìŠ¤í…œ ì•ˆì •ì„±ì„ ìœ„í•´)\n",
    "        num_cpus = max_workers or max(1, int(os.cpu_count() * 0.8))\n",
    "        ray.init(num_cpus=num_cpus, ignore_reinit_error=True)\n",
    "        print(f\"ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: {num_cpus})\")\n",
    "    \n",
    "    total_files = len(csv_files)\n",
    "    print(f\"ğŸ“ ì´ {total_files}ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\")\n",
    "    print(f\"ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: {output_dir}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # ì§„í–‰ë¥  ì¶”ì ê¸° ìƒì„±\n",
    "    progress_tracker = ProgressTracker.remote(total_files)\n",
    "    \n",
    "    # ì „ì²´ ì²˜ë¦¬ ì‹œì‘ ì‹œê°„\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # ëª¨ë“  íŒŒì¼ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬\n",
    "    file_futures = []\n",
    "    for csv_file in csv_files:\n",
    "        future = preproc_betterwhy_parallel.remote(\n",
    "            csv_file, output_dir, remove_duplicates, progress_tracker\n",
    "        )\n",
    "        file_futures.append(future)\n",
    "    \n",
    "    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°\n",
    "    print(\"â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\")\n",
    "    results = ray.get(file_futures)\n",
    "    \n",
    "    # ìµœì¢… í†µê³„\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "    final_stats = ray.get(progress_tracker.get_stats.remote())\n",
    "    \n",
    "    successful_files = sum(1 for r in results if r.get('success', False))\n",
    "    failed_files = len(results) - successful_files\n",
    "    total_rows = sum(r.get('rows_processed', 0) for r in results if r.get('success', False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "    print(f\"ğŸ“ˆ ì„±ê³µ: {successful_files}ê°œ | âŒ ì‹¤íŒ¨: {failed_files}ê°œ\")\n",
    "    print(f\"ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {total_rows:,}í–‰\")\n",
    "    print(f\"â±ï¸  ì´ ì†Œìš”ì‹œê°„: {format_duration(total_duration)}\")\n",
    "    print(f\"âš¡ í‰ê·  íŒŒì¼ë‹¹: {format_duration(total_duration / total_files)}\")\n",
    "    \n",
    "    # ì‹¤íŒ¨í•œ íŒŒì¼ë“¤ ì¶œë ¥\n",
    "    if failed_files > 0:\n",
    "        print(f\"\\nâŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\")\n",
    "        for result in results:\n",
    "            if not result.get('success', False):\n",
    "                file_name = os.path.basename(result.get('file', 'Unknown'))\n",
    "                error = result.get('error', 'Unknown error')\n",
    "                print(f\"   - {file_name}: {error}\")\n",
    "    \n",
    "    return {\n",
    "        'total_files': total_files,\n",
    "        'successful': successful_files,\n",
    "        'failed': failed_files,\n",
    "        'total_duration': total_duration,\n",
    "        'avg_duration_per_file': total_duration / total_files,\n",
    "        'total_rows_processed': total_rows,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "\n",
    "def format_duration(seconds: float) -> str:\n",
    "    \"\"\"ì´ˆë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ë³€í™˜\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}ì´ˆ\"\n",
    "    elif seconds < 3600:\n",
    "        minutes = int(seconds // 60)\n",
    "        secs = seconds % 60\n",
    "        return f\"{minutes}ë¶„ {secs:.1f}ì´ˆ\"\n",
    "    else:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = seconds % 60\n",
    "        return f\"{hours}ì‹œê°„ {minutes}ë¶„ {secs:.1f}ì´ˆ\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d7dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:01:07,021\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 300ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 1357rqwe_V000BL0011_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 39.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 58.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 41.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 56.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 39.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 41.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 41.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65069)\u001b[0m ğŸ“¦ aim21c_V007AJ0000_NIRO LONGRANGE_201801.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65070)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-9_V020BG0010_IONIQ 2019_201701.csv\u001b[32m [repeated 14x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m ğŸ“¦ 48625ff_V004CA0001_EV6 LONGRANGE_202210.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65116)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: alice2235_V011AK0000_PORTER2_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 16.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 39.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: azking_V000CC0019_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: babaliian_V000CD0076_ST1_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.7% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 41.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m âœ… adreamcar_V011AI0001_PORTER2_202301.csv: ì™„ë£Œ (24,500í–‰, 11.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbotti_V000BE0017_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.0% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 18.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.3% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 42.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m ğŸ“¦ bbotti_V000BE0017_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m ğŸ“¦ babaliian_V000CD0076_ST1_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbs001_V020CA0000_IONIQ 2019_201710.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65196)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: beston_V013AK0001_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65069)\u001b[0m âœ… aim21c_V007AJ0000_NIRO LONGRANGE_201801.csv: ì™„ë£Œ (30,036í–‰, 14.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.7% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 1.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ bbs001_V020CA0000_IONIQ 2019_201710.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65085)\u001b[0m âœ… airme_V000CC0050_EV6 LONGRANGE_202403.csv: ì™„ë£Œ (29,998í–‰, 24.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 35.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65066)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.3% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 10.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m ğŸ“¦ bluesky8571_V000CD0059_EV3 LONGRANGE_202504.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.7% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 56.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m âœ… ableautos_V000CB0021_EV6 LONGRANGE_202206.csv: ì™„ë£Œ (48,218í–‰, 26.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 26.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: boxing0217_V026CA000_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.3% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 17.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ“¦ bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.7% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 53.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.0% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 30.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.3% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 9.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cgtaxi-1_V003BA0005_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.7% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 59.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.0% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 46.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m ğŸ“¦ bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65274)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.3% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 37.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m âœ… bbotti_V000BE0017_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (32,775í–‰, 23.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m âœ… babaliian_V000CD0076_ST1_202407.csv: ì™„ë£Œ (54,401í–‰, 23.6ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65274)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-007_V011BE0025_PORTER2.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.7% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 54.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.0% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 47.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65145)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.3% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 18.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-016_V011BE0022_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65274)\u001b[0m ğŸ“¦ cjl-dgds-011_V011BE0023_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m âœ… bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv: ì™„ë£Œ (21,290í–‰, 17.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65066)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.7% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 42.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 25.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.3% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 10.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-012_V011BE0013_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ“¦ cjl-dgss-012_V011BE0013_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.7% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 39.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m âœ… cjl-dgds-006_V011BE0024_PORTER2.csv: ì™„ë£Œ (57,476í–‰, 17.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.0% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 39.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65196)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.3% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 28.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.7% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 17.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.3% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 51.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.7% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 41.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 31.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m âœ… bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (49,084í–‰, 27.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.3% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 21.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.7% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 14.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-016_V012BE0139_BONGO3.csv\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ğŸ“¦ cjl-dgss-013_V011BE0014_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ“¦ cjl-gbyc-016_V012BE0139_BONGO3.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m âœ… c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (69,216í–‰, 27.0ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65259)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.0% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 23.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: clausewitx_V000CB0063_GV70_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.3% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 35.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.7% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 37.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m ğŸ“¦ clausewitx_V000CB0063_GV70_202210.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m âœ… cjawl74_V000CC0007_PORTER2_202412.csv: ì™„ë£Œ (135,662í–‰, 32.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m âœ… cjl-dgea-016_V011BE0022_PORTER2.csv: ì™„ë£Œ (126,135í–‰, 27.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65068)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 34.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cyberlmk_V021BJ0001_EV9_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.3% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 32.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.7% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 29.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.0% | ì„±ê³µ: 22 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 29.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ cjosooo_V000CD0023_ST1_202407.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m âœ… cjl-dgss-013_V011BE0014_PORTER2.csv: ì™„ë£Œ (33,859í–‰, 14.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ğŸ“¦ day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.3% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 27.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: daegitaxi-2_V03BA0020_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddongkolip_V000CA0035_ST1_202405.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65510)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.7% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.0% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 15.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.3% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 14.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ ddtaxi-1_V004BA0001_EV6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m âœ… clausewitx_V000CB0063_GV70_202210.csv: ì™„ë£Œ (20,442í–‰, 16.1ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-5_V004BA0003_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65448)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ“¦ ddongkolip_V000CA0035_ST1_202405.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dibidib_V021BJ0002_EV9_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.7% | ì„±ê³µ: 26 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 3.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m âœ… cyberlmk_V021BJ0001_EV9_202308.csv: ì™„ë£Œ (51,138í–‰, 21.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.0% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 57.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.3% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 49.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.7% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 55.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dlcksgh3595_V000CA0027_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m âœ… day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv: ì™„ë£Œ (33,700í–‰, 24.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m âœ… cjosooo_V000CD0023_ST1_202407.csv: ì™„ë£Œ (75,922í–‰, 29.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.0% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 53.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dufdl1025_V004BJ0000_EV6 LONGRANGE_202404.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv: ì™„ë£Œ (12,786í–‰, 8.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m ğŸ“¦ dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.3% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 20.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65450)\u001b[0m âœ… deeps7011_V000CC0052_EV6 LONGRANGE_202411.csv: ì™„ë£Œ (51,818í–‰, 28.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.7% | ì„±ê³µ: 31 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 19.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 12.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.3% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 4.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: eha031_V000CD0097_PORTER2_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ehdghans1_V000CC0074_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.7% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 55.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.0% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 47.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-1_V000BD0002_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ ekfmd3152_V009BL0002_KONA LONGRANGE_202004.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ğŸ“¦ emob-1_V000BD0002_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m âœ… ddtaxi-5_V004BA0003_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (59,745í–‰, 31.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.3% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 59.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-2_V020BD0000_IONIQ 2019.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.7% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 51.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.0% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 44.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.3% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 37.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ“¦ emob-2_V020BD0000_IONIQ 2019.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.7% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 31.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.0% | ì„±ê³µ: 35 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 26.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m âœ… ddongkolip_V000CA0035_ST1_202405.csv: ì™„ë£Œ (97,846í–‰, 39.7ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.3% | ì„±ê³µ: 36 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 30.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: geni8895_V000CD0081_BONGO3_202210.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m âœ… emob-1_V000BD0002_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (14,685í–‰, 10.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.7% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 25.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ğŸ“¦ geni8895_V000CD0081_BONGO3_202210.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.0% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 24.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.3% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 18.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: giugi_V004BE0005_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.7% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 11.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m âœ… dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv: ì™„ë£Œ (39,493í–‰, 29.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hahakuhyun_V004BI0000_EV6 LONGRANGE_202401.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 14.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ğŸ“¦ ha8519_V021BI0003_EV9_202401.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.3% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 12.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.7% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m âœ… fojokr_V000CC0029_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (19,547í–‰, 11.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heo3252_V009BL0004_KONA LONGRANGE_201901.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ğŸ“¦ heo3252_V009BL0004_KONA LONGRANGE_201901.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.0% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 9.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m âœ… dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv: ì™„ë£Œ (50,135í–‰, 30.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.3% | ì„±ê³µ: 42 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 13.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m âœ… geni8895_V000CD0081_BONGO3_202210.csv: ì™„ë£Œ (49,895í–‰, 17.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hmp4522_V000CB0085_EV3 LONGRANGE_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m ğŸ“¦ hmc1006_V000CD0036_ST1_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.7% | ì„±ê³µ: 43 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 12.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.0% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 9.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ hmp4522_V000CB0085_EV3 LONGRANGE_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65808)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… esm3100_V000CB0089_BONGO3_202304.csv: ì™„ë£Œ (63,510í–‰, 22.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.3% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 11.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.7% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 7.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65910)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hophip5677_V000CA0024_CASPER LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.0% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.3% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 2.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ hyisjung_V007AL0001_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.7% | ì„±ê³µ: 47 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 57.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.0% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 54.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… helleus77_V005CA0000_EV6 STANDARD_202108.csv: ì™„ë£Œ (27,107í–‰, 16.7ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ“¦ ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hyisjung_V007AL0001_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ğŸ“¦ iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.3% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.7% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 49.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65510)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: j227_V022BL0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… honeybto_V015BL0000_GV60_202205.csv: ì™„ë£Œ (11,975í–‰, 10.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 50.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ janko7_V000CE0001_EV3 LONGRANGE_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.3% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 48.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ğŸ“¦ j227_V022BL0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65975)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.7% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 49.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.0% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 48.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… dufdl1025_V004BJ0000_EV6 LONGRANGE_202404.csv: ì™„ë£Œ (124,926í–‰, 56.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ jhs3101_V000CD0065_PORTER2_202002.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jhs3101_V000CD0065_PORTER2_202002.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jinjinjw_V000CD0040_IONIQ5 LONGRANGE_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.3% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 45.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.7% | ì„±ê³µ: 54 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 41.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv: ì™„ë£Œ (18,649í–‰, 14.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65975)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m âœ… hmc1006_V000CD0036_ST1_202504.csv: ì™„ë£Œ (34,127í–‰, 24.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ jmjang2_V000CD0034_ST1_202405.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmjang2_V000CD0034_ST1_202405.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ“¦ jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.0% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 47.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m âœ… j227_V022BL0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: ì™„ë£Œ (38,610í–‰, 18.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.3% | ì„±ê³µ: 56 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 42.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65595)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.7% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… janko7_V000CE0001_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (50,008í–‰, 19.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.0% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 39.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.3% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 35.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.7% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 30.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-19_V000BA0008_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.0% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 27.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.3% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 22.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m âœ… iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv: ì™„ë£Œ (25,076í–‰, 20.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ jmmath_V000BD0000_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65808)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… jhs3101_V000CD0065_PORTER2_202002.csv: ì™„ë£Œ (30,601í–‰, 16.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-26_V004BA0030_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m ğŸ“¦ joiltaxi-21_V004BA0027_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66126)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-3_V000BA0004_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.7% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66126)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-7_V004BA0019_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 47 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 38.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.3% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 47 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 34.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m âœ… jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv: ì™„ë£Œ (63,216í–‰, 31.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.7% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 48 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 29.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.0% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 24.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.3% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 23.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.7% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 18.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m âœ… js5540810_V000CA0025_IONIQ 2019_201607.csv: ì™„ë£Œ (4,216í–‰, 2.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.0% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 16.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ğŸ“¦ js5540810_V000CA0025_IONIQ 2019_201607.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ jsmtnaud_V000CB0041_IONIQ5 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jtkim0601_V007AL0000_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.3% | ì„±ê³µ: 62 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 14.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… jmjang2_V000CD0034_ST1_202405.csv: ì™„ë£Œ (50,665í–‰, 28.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv: ì™„ë£Œ (40,596í–‰, 29.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.7% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 12.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m âœ… jinsu7426_V000CD0041_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (39,656í–‰, 31.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.0% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 12.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ junhyuk0413_V000CD0029_NIRO2_202209.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: juhwan7455_V000CE0018_EV3 LONGRANGE_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… jmmath_V000BD0000_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (37,205í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.3% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 15.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m âœ… joiltaxi-26_V004BA0030_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (26,822í–‰, 26.5ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.7% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ“¦ junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: k2elryu_V017BL0000_G80_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.0% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 13.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kate3070kr_V000CC0001_GV70_202107.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.3% | ì„±ê³µ: 67 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 10.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m âœ… jog5064_V000CB0077_EV6 LONGRANGE_202307.csv: ì™„ë£Œ (42,704í–‰, 34.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.7% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-3_V000BH0002_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 5.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ kate3070kr_V000CC0001_GV70_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kgs0002_V000CB0010_EV6 LONGRANGE_202205.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… jtkim0601_V007AL0000_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (33,713í–‰, 17.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.3% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 12.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ kgs0002_V000CB0010_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (18,512í–‰, 17.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kimdajo_V000CC0008_EV6 LONGRANGE_202210.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.7% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.0% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 6.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.3% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 4.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ“¦ kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m âœ… joiltaxi-21_V004BA0027_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (102,839í–‰, 45.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.7% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 6.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.0% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 3.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kkhjust00_V000CC0068_EV3 STANDARD_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m ğŸ“¦ kkhjust00_V000CC0068_EV3 STANDARD_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m âœ… junghun1155_V004AL0000_EV6 LONGRANGE_202302.csv: ì™„ë£Œ (39,510í–‰, 28.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66381)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.3% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 10.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m âœ… kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (18,699í–‰, 14.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ğŸ“¦ korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.7% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m âœ… kor87_V000CC0020_NIRO PLUS_202207.csv: ì™„ë£Œ (22,971í–‰, 10.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m ğŸ“¦ ksjksj87_V029BL0001_EV3 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.0% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksjksj87_V029BL0001_EV3 LONGRANGE_202409.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.3% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… kate3070kr_V000CC0001_GV70_202107.csv: ì™„ë£Œ (49,522í–‰, 34.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.7% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 4.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ“¦ koreataxi-1_V000BB0000_IONIQ5 LONGRANGE_202204.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ğŸ“¦ kung417s_V004AK0001_EV6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ky80901_V000CD0024_ST1_202406.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m âœ… kkhjust00_V000CC0068_EV3 STANDARD_202408.csv: ì™„ë£Œ (42,935í–‰, 22.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.0% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 8.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.3% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 8.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66535)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.7% | ì„±ê³µ: 81 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 4.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ğŸ“¦ ky80901_V000CD0024_ST1_202406.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lbk5510_V003CA0002_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 2.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv: ì™„ë£Œ (39,367í–‰, 33.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.3% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 58.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ğŸ“¦ ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.7% | ì„±ê³µ: 83 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 0.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… kimdajo_V000CC0008_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (71,624í–‰, 35.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee1174_V004CG0022_EV9_202505.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m âœ… korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv: ì™„ë£Œ (38,715í–‰, 32.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee5957_V000BH0015_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ“¦ lee1174_V004CG0022_EV9_202505.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ğŸ“¦ lee5957_V000BH0015_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.0% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m âœ… koreataxi-1_V000BB0000_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (66,058í–‰, 35.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ“¦ leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66615)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: leejh824_V000CB0009_GV70_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.3% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 10.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.7% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 6.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.0% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 2.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: legojeon_V000CB0036_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lijingice007_V000CA0038_ST1_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.3% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 1.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m âœ… kung417s_V004AK0001_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (30,162í–‰, 32.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (38,800í–‰, 33.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.7% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 2.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m âœ… leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (15,210í–‰, 12.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m ğŸ“¦ lijingice007_V000CA0038_ST1_202411.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lny-taxi-p1_V013BC0000_IONIQ6 LONGRANGE_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.0% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 59.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.3% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 56.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m âœ… lee5957_V000BH0015_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (29,953í–‰, 24.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.7% | ì„±ê³µ: 89 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 54.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.0% | ì„±ê³µ: 90 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 50.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.3% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 46.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv: ì™„ë£Œ (33,566í–‰, 31.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.7% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 42.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 58 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 39.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m âœ… ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv: ì™„ë£Œ (38,221í–‰, 31.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ğŸ“¦ lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m âœ… ky80901_V000CD0024_ST1_202406.csv: ì™„ë£Œ (85,190í–‰, 41.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.3% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 58 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.7% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 59 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 39.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ lotteglogis-dg-16_V011BD0001_PORTER2.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-31_V011BD0006_PORTER2_202401.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.0% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 37.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.3% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 33.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m âœ… lostcity1_V000CC0058_PORTER2_202412.csv: ì™„ë£Œ (23,571í–‰, 11.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ“¦ lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m âœ… lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv: ì™„ë£Œ (31,932í–‰, 18.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.7% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 38.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.0% | ì„±ê³µ: 96 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 36.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66847)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-7_V011BD0002_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m âœ… lotteglogis-dg-19_V012BD0018_BONGO3.csv: ì™„ë£Œ (55,193í–‰, 20.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.3% | ì„±ê³µ: 97 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 35.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66847)\u001b[0m ğŸ“¦ lotteglogis-dg-7_V011BD0002_PORTER2_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.7% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 33.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m âœ… lijingice007_V000CA0038_ST1_202411.csv: ì™„ë£Œ (72,451í–‰, 33.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m âœ… lotteglogis-dg-16_V011BD0001_PORTER2.csv: ì™„ë£Œ (94,610í–‰, 27.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-12_V011BE0001_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.0% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 33.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ“¦ lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ğŸ“¦ ltgdg-12_V011BE0001_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m âœ… lotteglogis-dg-10_V011BD0005_PORTER2_202310.csv: ì™„ë£Œ (140,054í–‰, 33.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.3% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 31.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.7% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 28.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66730)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-17_V012BE0016_BONGO3_2024.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.0% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 61 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 25.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.3% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 61 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 24.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66834)\u001b[0m ğŸ“¦ ltgdg-13_V011BE0003_PORTER2_2024.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.7% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 61 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 22.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m âœ… lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv: ì™„ë£Œ (81,403í–‰, 26.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66779)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 19.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-21_V011BE0002_PORTER2_2024.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.3% | ì„±ê³µ: 104 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 17.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.7% | ì„±ê³µ: 105 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 16.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ ltgdg-18_V011BE0009_PORTER2_2023.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m âœ… ltgdg-14_V012BE0013_BONGO3_2022.csv: ì™„ë£Œ (16,822í–‰, 6.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-24_V012BE0023_BONGO3_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.0% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 14.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.3% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 12.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.7% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 9.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ğŸ“¦ ltgdg-24_V012BE0023_BONGO3_2022.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m âœ… lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv: ì™„ë£Œ (97,769í–‰, 26.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67008)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-33_V011BE0006_PORTER2_2023.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.0% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 8.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ“¦ ltgdg-3_V011BE0005_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66834)\u001b[0m âœ… ltgdg-13_V011BE0003_PORTER2_2024.csv: ì™„ë£Œ (85,518í–‰, 22.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.3% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 7.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m âœ… ltgdg-24_V012BE0023_BONGO3_2022.csv: ì™„ë£Œ (20,744í–‰, 10.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-5_V011BE0008_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.7% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 64 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 5.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.0% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 64 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 6.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ğŸ“¦ ltgyc-3_V011BE0011_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgyc-3_V011BE0011_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… ltgdg-18_V011BE0009_PORTER2_2023.csv: ì™„ë£Œ (103,280í–‰, 28.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.3% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 65 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 3.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.7% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 59.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.0% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 57.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mailhera_V000CE0019_PORTER2_202307.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67008)\u001b[0m âœ… ltgdg-33_V011BE0006_PORTER2_2023.csv: ì™„ë£Œ (39,530í–‰, 19.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.3% | ì„±ê³µ: 112 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 58.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ“¦ mailhera_V000CE0019_PORTER2_202307.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.7% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 55.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 114 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 52.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.3% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 50.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.7% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 67 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 48.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.0% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 45.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: maxcom3_V021BA0000_EV9_202312.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m âœ… ltgdg-3_V011BE0005_PORTER2_2023.csv: ì™„ë£Œ (79,762í–‰, 24.0ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ğŸ“¦ mkj2449_V000BL0009_IONIQ5 LONGRANGE_202110.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.3% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 42.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.7% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 39.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66953)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: naeibbo_V000CD0025_BONGO3_202406.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m âœ… ltgdg-5_V011BE0008_PORTER2_2023.csv: ì™„ë£Œ (35,665í–‰, 19.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m ğŸ“¦ mxri13_V015BK0000_GV60_202307.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67008)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.0% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 42.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ğŸ“¦ naeibbo_V000CD0025_BONGO3_202406.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m âœ… man8243_V000BL0007_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (18,649í–‰, 14.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67173)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.3% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 41.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ğŸ“¦ myhkk1797_V000BI0003_EV3 LONGRANGE_202402.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: needman_V004BI0002_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.7% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 38.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.0% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 36.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m âœ… mkj2449_V000BL0009_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (19,108í–‰, 17.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ğŸ“¦ needman_V004BI0002_EV6 LONGRANGE_202403.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: nukesub_V000CE0014_EV3 LONGRANGE_202504.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.3% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 35.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67303)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m âœ… nukesub_V000CE0014_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (9,044í–‰, 4.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.7% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 34.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (59,831í–‰, 35.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parksw7022_V000CD0033_IONIQ6 STANDARD_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.0% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 32.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67155)\u001b[0m âœ… musein_V000CB0096_EV9_202404.csv: ì™„ë£Œ (42,694í–‰, 25.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ“¦ parksw7022_V000CD0033_IONIQ6 STANDARD_202502.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.3% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 32.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m âœ… naeibbo_V000CD0025_BONGO3_202406.csv: ì™„ë£Œ (116,268í–‰, 30.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ“¦ ocs7777_V000CA0039_ST1_202407.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.7% | ì„±ê³µ: 125 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 31.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 28.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ğŸ“¦ pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.3% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 27.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m âœ… ntragic_V004CA0000_EV6 LONGRANGE_202005.csv: ì™„ë£Œ (28,533í–‰, 20.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-16_V004BL0002_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67355)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-17_V003BL0003_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.7% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 24.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-4_V013BL0001_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.0% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 22.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pity2002_V000CA0010_IONIQ5 LONGRANGE_202111.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.3% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 71 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 19.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.7% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 72 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 16.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ“¦ polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.0% | ì„±ê³µ: 129 | ì‹¤íŒ¨: 72 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 13.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.3% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 72 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 11.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m ğŸ“¦ pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: printo2000_V000CB0100_PORTER2_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ“¦ printo2000_V000CB0100_PORTER2_202210.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m âœ… polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv: ì™„ë£Œ (2,101í–‰, 2.4ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pmkp37_V000CB0033_IONIQ5 LONGRANGE 2022_202309.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66730)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pyh8965_EV6 LONGRANGE_202406.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.7% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 73 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 10.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: relier_V018AL0000_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ğŸ“¦ relier_V018AL0000_NIRO2_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ“¦ pgtaxi-4_V013BL0001_IONIQ6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.0% | ì„±ê³µ: 131 | ì‹¤íŒ¨: 73 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 9.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m âœ… pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv: ì™„ë£Œ (24,499í–‰, 10.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.3% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 73 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 7.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.7% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 74 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m âœ… printo2000_V000CB0100_PORTER2_202210.csv: ì™„ë£Œ (22,462í–‰, 9.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-4_V009BH0001_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-7_V009BH0002_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.0% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 75 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 1.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67472)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-11_V009BL0006_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ“¦ revu-n-11_V009BL0006_KONA LONGRANGE_202104.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-12_V000BE0012_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.3% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 1.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-15_V004BE0002_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (54,857í–‰, 33.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.7% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 58.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 55.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m âœ… ocs7777_V000CA0039_ST1_202407.csv: ì™„ë£Œ (70,461í–‰, 34.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ğŸ“¦ revu-n-15_V004BE0002_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ revu-n-18_V012BE0040_BONGO3.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.3% | ì„±ê³µ: 135 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 53.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m âœ… pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (34,492í–‰, 26.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67517)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-21_V021BE0004_EV9.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.7% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 52.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-22_V004BE0008_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.0% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 50.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ“¦ revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m âœ… pgtaxi-16_V004BL0002_EV6 LONGRANGE.csv: ì™„ë£Œ (45,676í–‰, 29.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m âœ… relier_V018AL0000_NIRO2_202207.csv: ì™„ë£Œ (37,437í–‰, 17.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ğŸ“¦ revu-n-23_V004BE0004_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.3% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 49.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-23_V004BE0004_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.7% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 46.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ğŸ“¦ revu-n-21_V021BE0004_EV9.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.0% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 44.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m âœ… revu-n-15_V004BE0002_EV6 LONGRANGE.csv: ì™„ë£Œ (17,605í–‰, 13.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-25_V018BE0000_NIRO2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… revu-n-18_V012BE0040_BONGO3.csv: ì™„ë£Œ (27,007í–‰, 11.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_V004BE0011_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ“¦ revu-n-22_V004BE0008_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.3% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 42.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.7% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 77 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 39.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.0% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 37.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.3% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 35.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ“¦ revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ“¦ revu-n-32_V004BE0011_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ğŸ“¦ revu-n-27_V021BE0000_EV9.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m âœ… revu-n-23_V004BE0004_EV6 LONGRANGE.csv: ì™„ë£Œ (7,296í–‰, 8.6ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-35_V016BF0000_GV70.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-39_V004BF0003_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m âœ… revu-n-25_V018BE0000_NIRO2_202401.csv: ì™„ë£Œ (7,959í–‰, 5.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.7% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 33.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-41_V004BF0002_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.0% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 79 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 30.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.3% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 80 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 28.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.7% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 81 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 25.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 82 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 23.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.3% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 20.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.7% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.0% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 15.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-57_V003BG0001_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.3% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 14.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-54_V004BG0000_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m âœ… revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (13,283í–‰, 8.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.7% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 12.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m âœ… revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (50,981í–‰, 23.8ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67303)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-66_V004BH0002_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ“¦ revu-n-64_V004BG0004_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ“¦ revu-n-66_V004BH0002_EV6 LONGRANGE_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-64_V004BG0004_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67593)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m âœ… revu-n-21_V021BE0004_EV9.csv: ì™„ë£Œ (84,832í–‰, 27.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.0% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 12.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.3% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 86 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 9.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_V004BH0000_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-69_V004BH0001_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ğŸ“¦ revu-n-69_V004BH0001_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.7% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 86 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 8.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m âœ… revu-n-27_V021BE0000_EV9.csv: ì™„ë£Œ (39,943í–‰, 23.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-70_V009BH0000_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.0% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 86 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 6.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m âœ… revu-n-32_V004BE0011_EV6 LONGRANGE.csv: ì™„ë£Œ (47,100í–‰, 26.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-8_V016BE0001_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.3% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 87 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-9_V000BE0009_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.7% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 88 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-u-2_V000BE0029_IONIQ5 LONGRANGE_202101.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.0% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 59.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.3% | ì„±ê³µ: 149 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 57.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ğŸ“¦ revu-n-70_V009BH0000_KONA LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.7% | ì„±ê³µ: 150 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 55.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ“¦ revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 151 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 53.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.3% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 51.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m âœ… revu-n-41_V004BF0002_EV6 LONGRANGE.csv: ì™„ë£Œ (40,943í–‰, 25.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: rwww87_V000CB0006_EV6 LONGRANGE_202311.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67770)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… s112661140_V004CA0002_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (225í–‰, 0.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.7% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 49.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ“¦ rwww87_V000CB0006_EV6 LONGRANGE_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.0% | ì„±ê³µ: 154 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 47.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.3% | ì„±ê³µ: 155 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 45.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.7% | ì„±ê³µ: 156 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.0% | ì„±ê³µ: 157 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 41.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (52,478í–‰, 26.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shcs111_V009BL0001_KONA LONGRANGE_201809.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m âœ… revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (9,963í–‰, 9.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m âœ… revu-n-69_V004BH0001_EV6 LONGRANGE.csv: ì™„ë£Œ (29,150í–‰, 18.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.3% | ì„±ê³µ: 158 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 39.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.7% | ì„±ê³µ: 158 | ì‹¤íŒ¨: 90 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 37.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shome_SOUL LONGRANGE_201901.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ğŸ“¦ sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m ğŸ“¦ shcs111_V009BL0001_KONA LONGRANGE_201809.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.0% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 90 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 35.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv: ì™„ë£Œ (12,949í–‰, 9.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.3% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 33.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.7% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 92 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 31.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.0% | ì„±ê³µ: 160 | ì‹¤íŒ¨: 92 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 29.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.3% | ì„±ê³µ: 160 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 26.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: smra1999_V000CB0039_EV9_202401.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m âœ… rlaxo120_V009BL0003_KONA LONGRANGE_201811.csv: ì™„ë£Œ (35,851í–‰, 15.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m âœ… revu-n-70_V009BH0000_KONA LONGRANGE.csv: ì™„ë£Œ (48,341í–‰, 14.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ sl-ev-1_V004BE0009_EV6 LONGRANGE_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sosanamu_V000CC0062_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.7% | ì„±ê³µ: 161 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 25.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m âœ… shcs111_V009BL0001_KONA LONGRANGE_201809.csv: ì™„ë£Œ (28,868í–‰, 12.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 162 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 23.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ssa1011_V022AK0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: stock_V021BI0001_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ“¦ sitestev6_SITESTEV6_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ“¦ ssa1011_V022AK0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.3% | ì„±ê³µ: 163 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 22.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ“¦ stock_V021BI0001_EV9_202307.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m âœ… rwww87_V000CB0006_EV6 LONGRANGE_202311.csv: ì™„ë£Œ (38,584í–‰, 23.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sunghyun_V000CC0066_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.7% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 21.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ“¦ sunghyun_V000CC0066_BONGO3_202412.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m âœ… sosanamu_V000CC0062_NIRO LONGRANGE_201902.csv: ì™„ë£Œ (34,851í–‰, 19.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: taerok_V000CA0020_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.0% | ì„±ê³µ: 165 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 19.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m âœ… ssa1011_V022AK0000_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: ì™„ë£Œ (29,422í–‰, 11.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.3% | ì„±ê³µ: 166 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 17.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ“¦ taerok_V000CA0020_KONA LONGRANGE_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.7% | ì„±ê³µ: 167 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 15.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m âœ… side3150_V000CD0078_IONIQ6 LONGRANGE_202312.csv: ì™„ë£Œ (44,111í–‰, 24.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testbongo_TESTBONGO_BONGO3_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m âœ… sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (67,221í–‰, 29.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.0% | ì„±ê³µ: 168 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 13.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m ğŸ“¦ testbongo_TESTBONGO_BONGO3_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m âœ… testbongo_TESTBONGO_BONGO3_202201.csv: ì™„ë£Œ (8,793í–‰, 3.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.3% | ì„±ê³µ: 169 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 11.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.7% | ì„±ê³µ: 170 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 9.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.0% | ì„±ê³µ: 171 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 7.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.3% | ì„±ê³µ: 172 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 5.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67770)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ“¦ tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m âœ… stock_V021BI0001_EV9_202307.csv: ì™„ë£Œ (40,366í–‰, 22.9ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.7% | ì„±ê³µ: 173 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 4.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ty3951_V000CC0070_EV6 LONGRANGE_202408.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.0% | ì„±ê³µ: 174 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 2.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ“¦ uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ“¦ ty3951_V000CC0070_EV6 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m âœ… test01_TESTNIRO01_NIRO PLUS_202201.csv: ì™„ë£Œ (35,911í–‰, 17.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.3% | ì„±ê³µ: 175 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 0.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.7% | ì„±ê³µ: 176 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 58.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vunyvuny2_V003CE0000_SOUL LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 177 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ğŸ“¦ vunyvuny2_V003CE0000_SOUL LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wce4122_V000CB0008_EV6 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.3% | ì„±ê³µ: 178 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 54.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ğŸ“¦ vitadoice11_V000CC0085_IONIQ5 LONGRANGE_202106.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m âœ… testev9_TESTEV9_EV9_2023.csv: ì™„ë£Œ (29,057í–‰, 15.8ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.7% | ì„±ê³µ: 179 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 52.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m âœ… vunyvuny2_V003CE0000_SOUL LONGRANGE.csv: ì™„ë£Œ (13,170í–‰, 6.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m ğŸ“¦ wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m ğŸ“¦ wce4122_V000CB0008_EV6 LONGRANGE_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ“¦ whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.0% | ì„±ê³µ: 180 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 51.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m âœ… tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv: ì™„ë£Œ (50,013í–‰, 20.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wildseven_V000CD0027_SOUL LONGRANGE_201906.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=68131)\u001b[0m ğŸ“¦ win7102_V000CE0017_EV3 LONGRANGE_202503.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68131)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: win7102_V000CE0017_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.3% | ì„±ê³µ: 181 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 49.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m âœ… wildseven_V000CD0027_SOUL LONGRANGE_201906.csv: ì™„ë£Œ (10,810í–‰, 7.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wjs4156_V000CD0077_EV3 STANDARD_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ğŸ“¦ wjs4156_V000CD0077_EV3 STANDARD_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.7% | ì„±ê³µ: 182 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 48.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.0% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 46.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m âœ… ty3951_V000CC0070_EV6 LONGRANGE_202408.csv: ì™„ë£Œ (36,415í–‰, 28.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m âœ… uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv: ì™„ë£Œ (46,171í–‰, 29.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68212)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.3% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 44.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.7% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 95 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 42.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.0% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 96 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 40.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.3% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 97 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 38.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ“¦ wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.7% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 97 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 36.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m âœ… vitadoice11_V000CC0085_IONIQ5 LONGRANGE_202106.csv: ì™„ë£Œ (35,354í–‰, 28.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.0% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 98 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-10_V03BA0032_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.3% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 99 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 32.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.7% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 100 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 30.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-1_V03BA0023_EV6 LONGRANGE_202209.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-2_V03BA0024_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 101 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 28.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.3% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 102 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 26.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.7% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 103 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 24.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-5_V03BA0027_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.0% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 104 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 22.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-9_V03BA0031_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.3% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 105 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 20.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.7% | ì„±ê³µ: 185 | ì‹¤íŒ¨: 105 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 18.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68212)\u001b[0m ğŸ“¦ xlos20_V004AK0000_EV6 LONGRANGE_202101.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m âœ… wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv: ì™„ë£Œ (48,260í–‰, 31.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.0% | ì„±ê³µ: 186 | ì‹¤íŒ¨: 105 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 16.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67542)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m âœ… wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (19,822í–‰, 8.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m âœ… whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv: ì™„ë£Œ (45,543í–‰, 29.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.3% | ì„±ê³µ: 187 | ì‹¤íŒ¨: 105 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 14.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.7% | ì„±ê³µ: 187 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: zoh71z_V009BL0000_KONA LONGRANGE_201810.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.0% | ì„±ê³µ: 188 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m âœ… wce4122_V000CB0008_EV6 LONGRANGE_202110.csv: ì™„ë£Œ (43,276í–‰, 32.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.3% | ì„±ê³µ: 189 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.7% | ì„±ê³µ: 190 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ğŸ“¦ zoh71z_V009BL0000_KONA LONGRANGE_201810.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ğŸ“¦ yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68131)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m âœ… zoh71z_V009BL0000_KONA LONGRANGE_201810.csv: ì™„ë£Œ (50,678í–‰, 11.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ğŸ“¦ yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.0% | ì„±ê³µ: 191 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.3% | ì„±ê³µ: 192 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.7% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68212)\u001b[0m âœ… xlos20_V004AK0000_EV6 LONGRANGE_202101.csv: ì™„ë£Œ (37,783í–‰, 21.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m âœ… yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (57,775í–‰, 19.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 100.0% | ì„±ê³µ: 194 | ì‹¤íŒ¨: 106 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 0.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m âœ… yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv: ì™„ë£Œ (119,165í–‰, 28.3ì´ˆ)\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 194ê°œ | âŒ ì‹¤íŒ¨: 106ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,626,476í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 9ë¶„ 25.5ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 1.9ì´ˆ\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 9ë¶„ 25.5ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 1.9ì´ˆ\n",
      "   - ì„±ê³µë¥ : 64.7%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,626,476í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 54916570í–‰/ì‹œê°„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68077)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV íŒŒì¼ ë¦¬ìŠ¤íŠ¸ (ì‹¤ì œ íŒŒì¼ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”)\n",
    "    # csv_files = [\n",
    "    #     # \"/path/to/your/file1.csv\",\n",
    "    #     # \"/path/to/your/file2.csv\",\n",
    "    #     # ë˜ëŠ” glob íŒ¨í„´ ì‚¬ìš©:\n",
    "    #     # *glob.glob(\"/path/to/your/data/*.csv\")\n",
    "    # ]\n",
    "    \n",
    "    csv_files = csv_files = glob.glob(\"/Volumes/Data/betterwhy_origin/20250716_0722(300á„ƒá…¢)/**/*.csv\", recursive=True)\n",
    "    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ (CPU ì½”ì–´ ìˆ˜ì˜ 80% ì‚¬ìš©)\n",
    "    results = process_multiple_files_parallel(\n",
    "        csv_files=csv_files,\n",
    "        output_dir=\"/Volumes/Data/betterwhy_processed\",\n",
    "        remove_duplicates=True,\n",
    "        max_workers=None  # Noneì´ë©´ ìë™ìœ¼ë¡œ CPU ì½”ì–´ ìˆ˜ì˜ 80% ì‚¬ìš©\n",
    "    )\n",
    "    \n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    if results:\n",
    "        print(f\"\\nğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\")\n",
    "        print(f\"   - ì´ ì²˜ë¦¬ ì‹œê°„: {format_duration(results['total_duration'])}\")\n",
    "        print(f\"   - íŒŒì¼ë‹¹ í‰ê· : {format_duration(results['avg_duration_per_file'])}\")\n",
    "        print(f\"   - ì„±ê³µë¥ : {(results['successful']/results['total_files']*100):.1f}%\")\n",
    "        print(f\"   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {results['total_rows_processed']:,}í–‰\")\n",
    "        print(f\"   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: {results['total_rows_processed']/(results['total_duration']/3600):.0f}í–‰/ì‹œê°„\")\n",
    "    \n",
    "    # Ray ì¢…ë£Œ\n",
    "    ray.shutdown()\n",
    "    print(\"ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb187ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ 36ê°œì˜ í´ë”ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\n",
      "ì°¾ì€ í´ë” ëª©ë¡:\n",
      "/Volumes/Data/betterwhy_origin/20250514_0520(á„á…®á„€á…¡_20á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250319_0325(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250611_0617(á„á…®á„€á…¡_20á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250514_0520(260á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250226_0304(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250430_0506(á„á…®á„€á…¡_20á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250702_0708(300á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250423_0429(240á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250604_0610(280á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250409_0415(á„á…®á„€á…¡_20á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250618_0624(300á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250326_0401(á„á…®á„€á…¡_20á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250409_0415(220á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250625_0701(300á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250108_0114(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250219_0225(200á„ƒá…¢_2á„ƒá…¢á„‚á…³á†«_á„€á…­á„á…¦)\n",
      "/Volumes/Data/betterwhy_origin/20250528_0603(280á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250416_0422(240á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250430_0506(240á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250521_0527(280á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250326_0401(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250129_0204(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250101_0107(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250507_0513(260á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250212_0218(199á„ƒá…¢_3á„ƒá…¢á„‚á…³á†«_á„€á…­á„á…¦)\n",
      "/Volumes/Data/betterwhy_origin/20250402_0408(220á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250205_0211(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250115_0121(200á„ƒá…¢_62á„ƒá…¢á„‚á…³á†«_á„€á…­á„á…¦)\n",
      "/Volumes/Data/betterwhy_origin/20250312_0318(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250611_0617(280á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250305_0311(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250122_0128(200á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250723_0730(320á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250709_0715(300á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250716_0722(300á„ƒá…¢)\n",
      "/Volumes/Data/betterwhy_origin/20250723(á„á…®á„€á…¡20á„ƒá…¢)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# ê²€ìƒ‰í•  ê¸°ë³¸ ê²½ë¡œ\n",
    "base_path = '/Volumes/Data/betterwhy_origin'\n",
    "\n",
    "# '2025'ë¡œ ì‹œì‘í•˜ëŠ” í´ë”ë¥¼ ì°¾ëŠ” íŒ¨í„´\n",
    "search_pattern = os.path.join(base_path, '2025*')\n",
    "\n",
    "# glob.glob() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ íŒ¨í„´ì— ë§ëŠ” ëª¨ë“  ê²½ë¡œë¥¼ ê°€ì ¸ì˜¨ í›„,\n",
    "# os.path.isdir() í•¨ìˆ˜ë¡œ í´ë”ë§Œ í•„í„°ë§í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŠµë‹ˆë‹¤.\n",
    "folder_list = [f for f in glob.glob(search_pattern) if os.path.isdir(f)]\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "if folder_list:\n",
    "    print(f\"ì´ {len(folder_list)}ê°œì˜ í´ë”ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"ì°¾ì€ í´ë” ëª©ë¡:\")\n",
    "    for folder in folder_list:\n",
    "        print(folder)\n",
    "else:\n",
    "    print(\"í•´ë‹¹í•˜ëŠ” í´ë”ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì´ì œ 'folder_list' ë³€ìˆ˜ì— '2025'ë¡œ ì‹œì‘í•˜ëŠ” í´ë”ë“¤ì˜ ê²½ë¡œê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ë‹´ê²¨ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73542776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:15:24,296\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 20ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: smra1999_EV9_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: day9672_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ğŸ“¦ 9224_ST1_202411.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m ğŸ“¦ day9672_IONIQ5 LONGRANGE 2022_202310.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 9224_ST1_202411.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ğŸ“¦ smra1999_EV9_202401.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 55.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m âœ… 9224_ST1_202411.csv: ì™„ë£Œ (7,794í–‰, 10.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: delpainus_IONIQ5 LONGRANGE 2022_202307.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70097)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ğŸ“¦ delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 55.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m âœ… shcs111_KONA LONGRANGE_201809.csv: ì™„ë£Œ (23,497í–‰, 25.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: c1228kr_IONIQ5 LONGRANGE_202201.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70181)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wer007_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0019): time data \"2025-07-16 11:38:27.141\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 52.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m ğŸ“¦ c1228kr_IONIQ5 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m ğŸ“¦ wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 17.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m âœ… mailhera_PORTER2_202307.csv: ì™„ë£Œ (89,918í–‰, 29.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m âœ… smra1999_EV9_202401.csv: ì™„ë£Œ (83,084í–‰, 33.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: rwww87_EV6 LONGRANGE_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ğŸ“¦ rwww87_EV6 LONGRANGE_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m âœ… delpainus_IONIQ5 LONGRANGE 2022_202307.csv: ì™„ë£Œ (29,586í–‰, 33.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s112661140_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ğŸ“¦ s112661140_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 22.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: nukesub_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m ğŸ“¦ nukesub_EV3 LONGRANGE_202504.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 21.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m âœ… babaliian_ST1_202407.csv: ì™„ë£Œ (37,908í–‰, 59.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: juhwan7455_EV3 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m ğŸ“¦ juhwan7455_EV3 LONGRANGE_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70447)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wjs4156_EV3 STANDARD_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m âœ… korea1736_IONIQ5 LONGRANGE_202203.csv: ì™„ë£Œ (41,350í–‰, 1ë¶„ 7.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: geni8895_BONGO3_202210.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 43.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m âœ… day9672_IONIQ5 LONGRANGE 2022_202310.csv: ì™„ë£Œ (35,277í–‰, 1ë¶„ 7.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m ğŸ“¦ geni8895_BONGO3_202210.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70057)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 27.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: taerok_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ğŸ“¦ taerok_KONA LONGRANGE_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m âœ… s112661140_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (46,324í–‰, 35.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heinzel_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 15.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m âœ… wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: ì™„ë£Œ (28,881í–‰, 47.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70054)\u001b[0m âœ… jdisky_IONIQ5 LONGRANGE_202112.csv: ì™„ë£Œ (44,841í–‰, 1ë¶„ 14.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 2.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70181)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m ğŸ“¦ heinzel_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: side3150_IONIQ6 LONGRANGE_202312.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 53.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m âœ… nukesub_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (20,514í–‰, 30.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 44.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m âœ… c1228kr_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (35,968í–‰, 56.8ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70055)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=70559)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 38.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m ğŸ“¦ side3150_IONIQ6 LONGRANGE_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m âœ… rwww87_EV6 LONGRANGE_202311.csv: ì™„ë£Œ (36,781í–‰, 56.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 32.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m âœ… heinzel_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (41,942í–‰, 22.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 25.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 18.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m âœ… taerok_KONA LONGRANGE_202302.csv: ì™„ë£Œ (49,654í–‰, 30.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m âœ… juhwan7455_EV3 LONGRANGE_202407.csv: ì™„ë£Œ (57,613í–‰, 41.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 20ê°œ | âŒ ì‹¤íŒ¨: 0ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 834,306í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 1ë¶„ 56.1ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 5.8ì´ˆ\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 1ë¶„ 56.1ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 5.8ì´ˆ\n",
      "   - ì„±ê³µë¥ : 100.0%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 834,306í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 25869559í–‰/ì‹œê°„\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70447)\u001b[0m âœ… wjs4156_EV3 STANDARD_202502.csv: ì™„ë£Œ (39,115í–‰, 35.7ì´ˆ)\n",
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:17:25,661\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 200ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: honeybto_GV60_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.5% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 14.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 36.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ“¦ honeybto_GV60_202205.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ emob-1_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: alice2235_PORTER2_202201.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m ğŸ“¦ revu-n-12_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70824)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m âœ… honeybto_GV60_202205.csv: ì™„ë£Œ (5,534í–‰, 9.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ğŸ“¦ revu-n-68_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.5% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 1.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.0% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 19.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-34_GV70.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.5% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 8.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ“¦ revu-n-34_GV70.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.0% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 38.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70782)\u001b[0m âœ… ekfmd3152_KONA LONGRANGE_202004.csv: ì™„ë£Œ (20,791í–‰, 13.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… alice2235_PORTER2_202201.csv: ì™„ë£Œ (59,561í–‰, 16.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70885)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ“¦ cjl-dgds-006_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m âœ… rlaxo120_KONA LONGRANGE_201811.csv: ì™„ë£Œ (20,341í–‰, 23.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.5% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 0.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70916)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.0% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 54.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m âœ… revu-n-68_EV6 LONGRANGE.csv: ì™„ë£Œ (43,281í–‰, 25.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ğŸ“¦ ajutaxi-27_IONIQ 2019_201701.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.5% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 20.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m âœ… revu-n-12_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (62,585í–‰, 28.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70780)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 22.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… emob-1_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (42,507í–‰, 33.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-18_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m ğŸ“¦ ltgdg-14_BONGO3_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m âœ… revu-n-34_GV70.csv: ì™„ë£Œ (45,680í–‰, 21.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m âœ… ajutaxi-27_IONIQ 2019_201701.csv: ì™„ë£Œ (13,913í–‰, 6.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.5% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 55.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.0% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 3.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70783)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m ğŸ“¦ revu-n-32_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ“¦ ltgdg-18_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: man8243_IONIQ5 LONGRANGE_202204.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71048)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.5% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 59.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m ğŸ“¦ man8243_IONIQ5 LONGRANGE_202204.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m âœ… cjl-dgds-006_PORTER2.csv: ì™„ë£Œ (61,642í–‰, 31.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-8_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.0% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 40.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.5% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 51.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ revu-n-48_NIRO LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m ğŸ“¦ pity2002_IONIQ5 LONGRANGE_202111.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… sihehe_NIRO2_202207.csv: ì™„ë£Œ (49,233í–‰, 17.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pity2002_IONIQ5 LONGRANGE_202111.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20173. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.5% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 17.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71018)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ“¦ yitaxi-8_EV6 LONGRANGE_202209.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m âœ… ltgdg-18_PORTER2_2023.csv: ì™„ë£Œ (83,910í–‰, 28.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junghun1155_EV6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.0% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 21.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: stock_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… pgtaxi-15_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (63,209í–‰, 1ë¶„ 0.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.5% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 47.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 17.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.5% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 4.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ caifa0622_IONIQ5 LONGRANGE_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ“¦ j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.0% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 20.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… revu-n-48_NIRO LONGRANGE.csv: ì™„ë£Œ (20,842í–‰, 11.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ cjl-dgea-016_PORTER2.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m âœ… pity2002_IONIQ5 LONGRANGE_202111.csv: ì™„ë£Œ (40,480í–‰, 25.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.5% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 6.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71254)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71254)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-19_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 4.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… caifa0622_IONIQ5 LONGRANGE_202107.csv: ì™„ë£Œ (38,130í–‰, 22.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.5% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 47.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ“¦ cjl-dgss-015_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-015_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jskim_IONIQ5 LONGRANGE_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-14_IONIQ5 STANDARD_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.0% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 57.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.5% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 33.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ cjl-dgss-013_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.0% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 23.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m âœ… revu-n-32_EV6 LONGRANGE.csv: ì™„ë£Œ (80,721í–‰, 1ë¶„ 9.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m âœ… j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: ì™„ë£Œ (60,370í–‰, 40.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.5% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 2.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70775)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ ajutaxi-4_IONIQ 2019_201801.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmmath_IONIQ5 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71430)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ğŸ“¦ jmmath_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.5% | ì„±ê³µ: 22 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 35.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m âœ… junghun1155_EV6 LONGRANGE_202302.csv: ì™„ë£Œ (50,305í–‰, 55.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.0% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 26.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ“¦ lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.5% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 20.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71254)\u001b[0m âœ… lotteglogis-dg-19_BONGO3.csv: ì™„ë£Œ (87,475í–‰, 37.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… ajutaxi-4_IONIQ 2019_201801.csv: ì™„ë£Œ (100,718í–‰, 22.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ revu-n-23_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.0% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 7.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.5% | ì„±ê³µ: 26 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 51.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ“¦ ha8519_EV9_202401.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… cjl-dgss-013_PORTER2.csv: ì™„ë£Œ (84,945í–‰, 35.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ha8519_EV9_202401.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71547)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.0% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 50.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… revu-n-23_EV6 LONGRANGE.csv: ì™„ë£Œ (5,304í–‰, 6.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ testbongo_BONGO3_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.5% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 59.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… cjl-dgea-016_PORTER2.csv: ì™„ë£Œ (143,031í–‰, 1ë¶„ 6.8ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: test01_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.0% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cyberlmk_EV9_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.5% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 37.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 21.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ cyberlmk_EV9_202308.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m âœ… lotteglogis-dg-2_BONGO3.csv: ì™„ë£Œ (70,532í–‰, 16.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m ğŸ“¦ revu-n-15_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: polarbar_IONIQ6 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71509)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.5% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 18.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m âœ… lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (85,002í–‰, 30.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: k2elryu_G80_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.0% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: test01_NIRO PLUS_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: ì™„ë£Œ (16,295í–‰, 16.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.5% | ì„±ê³µ: 31 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 48.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.0% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 34.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… dufdl1025_EV6 LONGRANGE_202404.csv: ì™„ë£Œ (142,456í–‰, 2ë¶„ 7.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.5% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 19.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.0% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 7.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ“¦ ddtaxi-1_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dibidib_EV9_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m âœ… ha8519_EV9_202401.csv: ì™„ë£Œ (24,049í–‰, 21.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m âœ… jmmath_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (33,051í–‰, 49.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ ltgyc-4_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.5% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 22.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ğŸ“¦ dibidib_EV9_202407.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70775)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.0% | ì„±ê³µ: 35 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 17.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-23_BONGO3_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.5% | ì„±ê³µ: 36 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 5.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ğŸ“¦ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m âœ… test01_NIRO PLUS_202201.csv: ì™„ë£Œ (3,243í–‰, 13.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ ltgdg-23_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 12.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: relier_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m âœ… revu-n-15_EV6 LONGRANGE.csv: ì™„ë£Œ (27,629í–‰, 23.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71761)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ“¦ relier_NIRO2_202207.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… ltgyc-4_BONGO3.csv: ì™„ë£Œ (107,527í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.5% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 17.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… sinwootaxi-1_IONIQ5 STANDARD_202110.csv: ì™„ë£Œ (61í–‰, 3.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.0% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ woojukjk_EV6 LONGRANGE_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.5% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 25.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… cyberlmk_EV9_202308.csv: ì™„ë£Œ (59,363í–‰, 45.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.0% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 13.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-13_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.5% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 3.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ ltgdg-13_PORTER2_2024.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ ajutaxi-25_IONIQ 2019_201701.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71900)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… ltgdg-23_BONGO3_2023.csv: ì™„ë£Œ (68,839í–‰, 25.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-25_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.0% | ì„±ê³µ: 42 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 37.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… ltgdg-13_PORTER2_2024.csv: ì™„ë£Œ (80,484í–‰, 18.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.5% | ì„±ê³µ: 43 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 28.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.0% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 16.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jtkim0601_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.5% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 5.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ revu-n-41_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72012)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 60.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.5% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 48.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.0% | ì„±ê³µ: 47 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 38.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ jtkim0601_NIRO LONGRANGE_201808.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m âœ… relier_NIRO2_202207.csv: ì™„ë£Œ (103,886í–‰, 48.8ì´ˆ)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-013_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.5% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 38.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ğŸ“¦ kung417s_EV6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.0% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 29.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ“¦ lotteglogis-dg-28_BONGO3_202309.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70777)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… ddtaxi-1_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (60,474í–‰, 1ë¶„ 5.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ“¦ revu-n-20_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.5% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 25.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m âœ… kyh108_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (43,943í–‰, 57.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 628dani_CASPER LONGRANGE_202410.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ cjl-gbyc-013_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ“¦ 628dani_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71411)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.0% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 34.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ“¦ 48625ff_EV6 LONGRANGE_202210.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m âœ… lotteglogis-dg-28_BONGO3_202309.csv: ì™„ë£Œ (118,590í–‰, 17.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.5% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.0% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 21.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.5% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 13.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72069)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m âœ… 628dani_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (26,037í–‰, 11.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ğŸ“¦ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ“¦ pgtaxi-5_NIRO LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-8_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 10.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.5% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 3.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ bbs001_IONIQ 2019_201710.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… jtkim0601_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (55,720í–‰, 30.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72185)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ pgtaxi-4_IONIQ6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbs001_IONIQ 2019_201710.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72185)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.0% | ì„±ê³µ: 54 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 8.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m âœ… pgtaxi-5_NIRO LONGRANGE.csv: ì™„ë£Œ (30,885í–‰, 12.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-21_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.5% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 1.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… revu-n-41_EV6 LONGRANGE.csv: ì™„ë£Œ (27,780í–‰, 40.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ğŸ“¦ joiltaxi-21_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.0% | ì„±ê³µ: 56 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 8.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m âœ… revu-n-20_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (29,268í–‰, 40.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72027)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-12_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.5% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m âœ… kung417s_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (52,119í–‰, 51.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72329)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ“¦ ltgdg-12_PORTER2.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sitestev6_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ğŸ“¦ sitestev6_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72329)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.0% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 21.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.5% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m âœ… kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (66,543í–‰, 48.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.0% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 8.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… bbs001_IONIQ 2019_201710.csv: ì™„ë£Œ (36,408í–‰, 40.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… pgtaxi-4_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (73,576í–‰, 42.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.5% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 0.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-24_BONGO3_2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ“¦ ajutaxi-1_IONIQ 2019_201701.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72533)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ revu-n-39_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0001): time data \"2025-07-16 09:25:52.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ğŸ“¦ ltgdg-24_BONGO3_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 6.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m âœ… ltgdg-12_PORTER2.csv: ì™„ë£Œ (100,496í–‰, 30.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.5% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 59.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mkj2449_IONIQ5 LONGRANGE_202110.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72533)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ğŸ“¦ mkj2449_IONIQ5 LONGRANGE_202110.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m âœ… ltgdg-24_BONGO3_2022.csv: ì™„ë£Œ (55,733í–‰, 15.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.0% | ì„±ê³µ: 62 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 0.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72629)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-54_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.5% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 58.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.0% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 49.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m ğŸ“¦ revu-n-54_EV6 LONGRANGE_2023.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… 48625ff_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (70,631í–‰, 1ë¶„ 23.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ“¦ aim21c_NIRO LONGRANGE_201801.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.5% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 47.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: aim21c_NIRO LONGRANGE_201801.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m âœ… ajutaxi-1_IONIQ 2019_201701.csv: ì™„ë£Œ (93,562í–‰, 30.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-016_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.0% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 45.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m âœ… mkj2449_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (69,433í–‰, 20.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ“¦ cjl-gbyc-016_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hahakuhyun_EV6 LONGRANGE_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… revu-n-39_EV6 LONGRANGE.csv: ì™„ë£Œ (55,459í–‰, 32.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.5% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 39.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-32_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m âœ… revu-n-54_EV6 LONGRANGE_2023.csv: ì™„ë£Œ (23,047í–‰, 14.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.0% | ì„±ê³µ: 67 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 35.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72629)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ ltgdg-32_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ“¦ yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ“¦ pgtaxi-16_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m âœ… yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: ì™„ë£Œ (13,503í–‰, 11.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.5% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 45.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… ltgdg-32_PORTER2_2023.csv: ì™„ë£Œ (74,459í–‰, 18.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 38.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.5% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 33.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ tsiyhj_EV6 LONGRANGE_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.0% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 27.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.5% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 19.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (70,737í–‰, 1ë¶„ 26.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… aim21c_NIRO LONGRANGE_201801.csv: ì™„ë£Œ (39,657í–‰, 33.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: xlos20_EV6 LONGRANGE_202101.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ğŸ“¦ xlos20_EV6 LONGRANGE_202101.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ“¦ revu-n-64_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m âœ… hahakuhyun_EV6 LONGRANGE_202401.csv: ì™„ë£Œ (40,067í–‰, 30.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.0% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.5% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 13.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23028. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.0% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 8.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m âœ… pgtaxi-16_EV6 LONGRANGE.csv: ì™„ë£Œ (23,028í–‰, 19.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ğŸ“¦ sl-ev-1_EV6 LONGRANGE_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m âœ… cjl-gbyc-016_BONGO3.csv: ì™„ë£Œ (97,428í–‰, 36.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.5% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 3.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m âœ… joiltaxi-21_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (83,952í–‰, 1ë¶„ 41.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.0% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 56.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ“¦ revu-n-63_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72997)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgyc-3_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m ğŸ“¦ revu-n-11_KONA LONGRANGE_202104.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m âœ… sitestev6_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (84,032í–‰, 1ë¶„ 27.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73049)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… tsiyhj_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (37,590í–‰, 32.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ğŸ“¦ ltgyc-3_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-34_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.5% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 5.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ ltgdg-34_BONGO3.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 5.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m âœ… ltgyc-3_PORTER2.csv: ì™„ë£Œ (68,739í–‰, 18.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-011_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.5% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 0.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ cjl-dgds-011_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.0% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 53.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m âœ… lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: ì™„ë£Œ (62,844í–‰, 29.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-22_BONGO3_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72997)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.5% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 49.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.0% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 42.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: maxcom3_EV9_202312.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.5% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 35.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-004_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.0% | ì„±ê³µ: 81 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 30.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m âœ… revu-n-64_EV6 LONGRANGE.csv: ì™„ë£Œ (38,910í–‰, 42.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ“¦ cjl-dgno-004_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.5% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 24.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.0% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 18.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… ltgdg-34_BONGO3.csv: ì™„ë£Œ (57,250í–‰, 15.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-20_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m ğŸ“¦ revu-u-2_IONIQ5 LONGRANGE_202101.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m âœ… cjl-dgno-004_PORTER2.csv: ì™„ë£Œ (59,285í–‰, 11.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.5% | ì„±ê³µ: 83 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 19.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 15.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ“¦ lotteglogis-dg-20_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0021): time data \"2025-07-16 08:30:40.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-17_BONGO3_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.5% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.0% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 3.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ“¦ revu-n-25_NIRO2_202401.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ğŸ“¦ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m âœ… xlos20_EV6 LONGRANGE_202101.csv: ì™„ë£Œ (36,296í–‰, 56.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6572. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.5% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 0.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.0% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 54.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-25_NIRO2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m âœ… revu-n-63_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (46,927í–‰, 50.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: helleus77_EV6 STANDARD_202108.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ğŸ“¦ ltgdg-17_BONGO3_2024.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ğŸ“¦ helleus77_EV6 STANDARD_202108.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m âœ… sl-ev-1_EV6 LONGRANGE_2022.csv: ì™„ë£Œ (37,612í–‰, 52.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.5% | ì„±ê³µ: 89 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 57.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.0% | ì„±ê³µ: 90 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 51.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m ğŸ“¦ cjl-dgss-012_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m âœ… lotteglogis-dg-20_BONGO3.csv: ì™„ë£Œ (115,446í–‰, 25.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.5% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 45.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m ğŸ“¦ revu-n-18_BONGO3.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.0% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 42.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m âœ… ltgdg-17_BONGO3_2024.csv: ì™„ë£Œ (128,926í–‰, 21.9ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.5% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 37.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-8_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ“¦ joiltaxi-3_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ğŸ“¦ joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-21_PORTER2_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-22_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ğŸ“¦ ltgdg-21_PORTER2_2024.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ“¦ lotteglogis-dg-22_PORTER2_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m âœ… helleus77_EV6 STANDARD_202108.csv: ì™„ë£Œ (30,874í–‰, 30.5ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72817)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.5% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 37.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: ì™„ë£Œ (32,992í–‰, 22.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.0% | ì„±ê³µ: 96 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 33.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-66_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m âœ… revu-n-18_BONGO3.csv: ì™„ë£Œ (46,907í–‰, 25.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ revu-n-66_EV6 LONGRANGE_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.5% | ì„±ê³µ: 97 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 28.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m ğŸ“¦ reviewshare-4_KONA LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-7_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.0% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 24.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.5% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 18.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73373)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.0% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 13.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.5% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 7.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.0% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 2.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m âœ… ltgdg-21_PORTER2_2024.csv: ì™„ë£Œ (85,806í–‰, 19.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ğŸ“¦ zoh71z_KONA LONGRANGE_201810.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbotti_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.5% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 59.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 54.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m âœ… yousjun_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (43,461í–‰, 48.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ğŸ“¦ bbotti_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m ğŸ“¦ joiltaxi-7_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m âœ… joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (75,629í–‰, 26.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.5% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 53.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m âœ… reviewshare-4_KONA LONGRANGE.csv: ì™„ë£Œ (32,434í–‰, 13.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.0% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 48.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-005_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73569)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-18_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.5% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 43.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.0% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 38.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mxri13_GV60_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.5% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 33.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.0% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 29.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m âœ… lotteglogis-dg-22_PORTER2_202301.csv: ì™„ë£Œ (37,944í–‰, 24.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ğŸ“¦ heo3252_KONA LONGRANGE_201901.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ“¦ revu-n-49_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73628)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ“¦ pyh8965_EV6 LONGRANGE_202406.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-2_IONIQ 2019.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ“¦ emob-2_IONIQ 2019.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.5% | ì„±ê³µ: 104 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 32.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.0% | ì„±ê³µ: 105 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 28.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m âœ… zoh71z_KONA LONGRANGE_201810.csv: ì™„ë£Œ (46,038í–‰, 31.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.5% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 23.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-008_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73373)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ“¦ lee5957_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 19.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.5% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 16.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m âœ… joiltaxi-7_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (94,766í–‰, 36.0ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m âœ… revu-n-49_EV6 LONGRANGE.csv: ì™„ë£Œ (46,172í–‰, 25.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ“¦ cjl-dgea-008_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73719)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-018_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.0% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 12.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.5% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 8.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.0% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m âœ… emob-2_IONIQ 2019.csv: ì™„ë£Œ (18,282í–‰, 19.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… revu-n-66_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (51,962í–‰, 49.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.5% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 0.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ğŸ“¦ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-1_BONGO3_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73374)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ ltgdg-1_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m âœ… heo3252_KONA LONGRANGE_201901.csv: ì™„ë£Œ (45,859í–‰, 31.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.0% | ì„±ê³µ: 112 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 57.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m âœ… cjl-dgea-008_BONGO3.csv: ì™„ë£Œ (63,959í–‰, 16.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.5% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 54.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-21_EV9.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m âœ… bbotti_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (44,645í–‰, 51.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ“¦ ksy-taxi-p1_EV6 LONGRANGE_202303.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ revu-n-22_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m âœ… joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (5,433í–‰, 5.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ“¦ revu-n-21_EV9.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-1_IONIQ5 LONGRANGE_202110.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.0% | ì„±ê³µ: 114 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 52.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2732 MiB, 70 objects, write throughput 422 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(preprocess_batch_parallel pid=73843)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-4_KONA LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.5% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 50.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ“¦ kepco-1_IONIQ5 LONGRANGE_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… ltgdg-1_BONGO3_2023.csv: ì™„ë£Œ (72,001í–‰, 22.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 45.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.5% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 42.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m âœ… lee5957_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (39,790í–‰, 38.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ğŸ“¦ ddtaxi-4_KONA LONGRANGE_201901.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BE0004): time data \"2025-07-16 01:14:58.627\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m âœ… revu-n-21_EV9.csv: ì™„ë£Œ (100,642í–‰, 25.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.0% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 39.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73541)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.5% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 35.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.0% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 31.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.5% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 27.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-33_PORTER2_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ğŸ“¦ ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ“¦ ltgdg-33_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73995)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.0% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 25.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ joiltaxi-26_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m âœ… ksy-taxi-p1_EV6 LONGRANGE_202303.csv: ì™„ë£Œ (148,647í–‰, 45.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.5% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 21.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… revu-n-22_EV6 LONGRANGE.csv: ì™„ë£Œ (70,077í–‰, 36.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: endy11_PORTER2_202306.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.0% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 18.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ“¦ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.5% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 14.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m âœ… ltgdg-33_PORTER2_2023.csv: ì™„ë£Œ (41,472í–‰, 12.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 10.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.5% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 6.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dlcksgh3595_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73614)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.0% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-5_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-27_EV9.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ“¦ revu-n-27_EV9.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m âœ… 1357rqwe_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (44,144í–‰, 53.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73569)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003BF0002): time data \"2025-07-16 01:17:03.196\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ endy11_PORTER2_202306.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.5% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 0.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.0% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 56.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m âœ… revu-n-38_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (30,170í–‰, 13.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m âœ… kepco-1_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (35,635í–‰, 41.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-5_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ“¦ yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ğŸ“¦ lotteglogis-dg-33_PORTER2_202301.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ“¦ revu-n-4_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.5% | ì„±ê³µ: 125 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 53.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BE0000): time data \"2025-07-16 00:27:35.894\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 5967. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m âœ… revu-n-27_EV9.csv: ì™„ë£Œ (5,967í–‰, 11.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: adreamcar_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ“¦ adreamcar_PORTER2_202301.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.0% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 50.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m âœ… ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: ì™„ë£Œ (47,149í–‰, 31.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m ğŸ“¦ hyisjung_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.5% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 47.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… endy11_PORTER2_202306.csv: ì™„ë£Œ (96,206í–‰, 25.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.0% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 43.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.5% | ì„±ê³µ: 129 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 39.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ ksjksj87_EV3 LONGRANGE_202409.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ğŸ“¦ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m âœ… hyisjung_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (12,579í–‰, 8.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 36.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74147)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.5% | ì„±ê³µ: 131 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 32.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ“¦ revu-n-58_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m âœ… adreamcar_PORTER2_202301.csv: ì™„ë£Œ (10,571í–‰, 11.9ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-3_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-6_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ“¦ ltgdg-3_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m ğŸ“¦ ltgdg-6_PORTER2_2024.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74198)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m âœ… revu-n-4_EV6 LONGRANGE.csv: ì™„ë£Œ (46,655í–‰, 23.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.0% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 30.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.5% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 26.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.0% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 23.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m âœ… yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (112,114í–‰, 35.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73614)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.5% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.0% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 16.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ“¦ js5540810_IONIQ 2019_201607.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: js5540810_IONIQ 2019_201607.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m âœ… ltgdg-6_PORTER2_2024.csv: ì™„ë£Œ (34,055í–‰, 13.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.5% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 13.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74212)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.0% | ì„±ê³µ: 135 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 10.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.5% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 6.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 3.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ yaa7890_PORTER2_202003.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yaa7890_PORTER2_202003.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m âœ… ltgdg-3_PORTER2_2023.csv: ì™„ë£Œ (66,661í–‰, 19.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m âœ… revu-n-58_EV6 LONGRANGE.csv: ì™„ë£Œ (34,017í–‰, 25.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.5% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 59.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74342)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.0% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.5% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 53.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m ğŸ“¦ ntragic_EV6 LONGRANGE_202005.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testev9_EV9_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… ksjksj87_EV3 LONGRANGE_202409.csv: ì™„ë£Œ (48,774í–‰, 30.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ğŸ“¦ testev9_EV9_2023.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-7_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… yaa7890_PORTER2_202003.csv: ì™„ë£Œ (15,131í–‰, 8.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ğŸ“¦ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ lotteglogis-dg-7_PORTER2_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m âœ… ntragic_EV6 LONGRANGE_202005.csv: ì™„ë£Œ (54,951í–‰, 15.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.0% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 50.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74312)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.5% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 47.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.0% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 43.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (1,066í–‰, 1.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ wntjdgml_CASPER LONGRANGE_202408.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m ğŸ“¦ lotteglogis-dg-8_PORTER2_202308.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.5% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 40.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… lotteglogis-dg-1_PORTER2_202306.csv: ì™„ë£Œ (14,411í–‰, 9.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m âœ… testev9_EV9_2023.csv: ì™„ë£Œ (5,246í–‰, 15.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74433)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m ğŸ“¦ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m ğŸ“¦ beston_IONIQ6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74448)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74448)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-35_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.0% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 38.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m âœ… ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: ì™„ë£Œ (31,567í–‰, 54.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.5% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… lotteglogis-dg-7_PORTER2_202311.csv: ì™„ë£Œ (51,246í–‰, 20.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74448)\u001b[0m ğŸ“¦ revu-n-35_GV70.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-010_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 31.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cody8406_IONIQ 2020_202007.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… wntjdgml_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (29,877í–‰, 20.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.5% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 28.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.0% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 25.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ğŸ“¦ cody8406_IONIQ 2020_202007.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m âœ… lotteglogis-dg-8_PORTER2_202308.csv: ì™„ë£Œ (44,518í–‰, 24.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ“¦ joiltaxi-9_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-9_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.5% | ì„±ê³µ: 149 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 22.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74342)\u001b[0m âœ… lotteglogis-dg-10_PORTER2_202310.csv: ì™„ë£Œ (63,984í–‰, 54.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.0% | ì„±ê³µ: 150 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 19.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.5% | ì„±ê³µ: 151 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 16.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.0% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m âœ… cody8406_IONIQ 2020_202007.csv: ì™„ë£Œ (35,915í–‰, 25.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.5% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m âœ… koreataxi-1_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (134,336í–‰, 1ë¶„ 18.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m âœ… joiltaxi-9_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (92,730í–‰, 33.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.0% | ì„±ê³µ: 154 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m âœ… bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (42,757í–‰, 53.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.5% | ì„±ê³µ: 155 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m âœ… beston_IONIQ6 LONGRANGE_202201.csv: ì™„ë£Œ (56,290í–‰, 59.7ì´ˆ)\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 156ê°œ | âŒ ì‹¤íŒ¨: 44ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,761,766í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 10ë¶„ 58.7ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 3.3ì´ˆ\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 10ë¶„ 58.7ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 3.3ì´ˆ\n",
      "   - ì„±ê³µë¥ : 78.0%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,761,766í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 47888991í–‰/ì‹œê°„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:28:28,523\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 20ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lostcity1_PORTER2_202412.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sosanamu_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojoov_CASPER LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ğŸ“¦ woojoov_CASPER LONGRANGE_202503.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m ğŸ“¦ hoya3838_IONIQ 2019_201807.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ğŸ“¦ sosanamu_NIRO LONGRANGE_201902.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 20.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74911)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kkhjust00_EV3 STANDARD_202408.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m âœ… woojoov_CASPER LONGRANGE_202503.csv: ì™„ë£Œ (8,023í–‰, 6.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ğŸ“¦ printo2000_PORTER2_202210.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74955)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 50.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m âœ… hoya3838_IONIQ 2019_201807.csv: ì™„ë£Œ (4,699í–‰, 10.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wce4122_EV6 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m ğŸ“¦ wce4122_EV6 LONGRANGE_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 33.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0100): time data \"2025-07-16 10:05:19.604\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m âœ… printo2000_PORTER2_202210.csv: ì™„ë£Œ (52,500í–‰, 9.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75009)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m ğŸ“¦ car0365_EV6 LONGRANGE_202109.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: car0365_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 39.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m âœ… bjgjw2579_EV6 LONGRANGE_202109.csv: ì™„ë£Œ (19,581í–‰, 23.5ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74897)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sunghyun_BONGO3_202412.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m ğŸ“¦ win7102_EV3 LONGRANGE_202503.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m ğŸ“¦ sunghyun_BONGO3_202412.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 14.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m âœ… lostcity1_PORTER2_202412.csv: ì™„ë£Œ (55,772í–‰, 24.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: win7102_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74911)\u001b[0m âœ… kkhjust00_EV3 STANDARD_202408.csv: ì™„ë£Œ (21,219í–‰, 29.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75086)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: go051s_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75086)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 3.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m âœ… sosanamu_NIRO LONGRANGE_201902.csv: ì™„ë£Œ (48,012í–‰, 32.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vunyvuny2_SOUL LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ğŸ“¦ vunyvuny2_SOUL LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75086)\u001b[0m ğŸ“¦ go051s_BONGO3_202412.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m âœ… car0365_EV6 LONGRANGE_202109.csv: ì™„ë£Œ (41,210í–‰, 33.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 19.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75009)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75247)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tlsqjatjq628_EV3 LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75216)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75247)\u001b[0m ğŸ“¦ tlsqjatjq628_EV3 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ehdghans1_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75366)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltj1937_EV3 LONGRANGE_202412.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 29.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m ğŸ“¦ ehdghans1_IONIQ5 LONGRANGE_202206.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m âœ… ty3951_EV6 LONGRANGE_202408.csv: ì™„ë£Œ (45,811í–‰, 1ë¶„ 11.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: janko7_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m ğŸ“¦ janko7_EV3 LONGRANGE_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 17.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m âœ… vunyvuny2_SOUL LONGRANGE.csv: ì™„ë£Œ (41,694í–‰, 43.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: thdwlsdn000_CASPER LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75455)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m ğŸ“¦ thdwlsdn000_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 22.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m âœ… wce4122_EV6 LONGRANGE_202110.csv: ì™„ë£Œ (38,945í–‰, 1ë¶„ 28.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 7.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75572)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 49.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m âœ… win7102_EV3 LONGRANGE_202503.csv: ì™„ë£Œ (29,808í–‰, 1ë¶„ 19.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 38.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 29.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 21.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m âœ… thdwlsdn000_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (15,088í–‰, 38.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 13.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6.6ì´ˆ\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 20ê°œ | âŒ ì‹¤íŒ¨: 0ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 873,132í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 2ë¶„ 11.3ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 6.6ì´ˆ\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 2ë¶„ 11.3ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 6.6ì´ˆ\n",
      "   - ì„±ê³µë¥ : 100.0%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 873,132í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 23936157í–‰/ì‹œê°„\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75366)\u001b[0m âœ… ltj1937_EV3 LONGRANGE_202412.csv: ì™„ë£Œ (104,856í–‰, 57.0ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75572)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:30:44,645\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 260ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: honeybto_GV60_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-1_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.4% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 58.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.8% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 31.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.2% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.5% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 18.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m ğŸ“¦ pgtaxi-15_IONIQ6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m ğŸ“¦ ekfmd3152_KONA LONGRANGE_202004.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ“¦ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-12_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15937. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m âœ… ekfmd3152_KONA LONGRANGE_202004.csv: ì™„ë£Œ (15,937í–‰, 6.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m ğŸ“¦ emob-1_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ğŸ“¦ sepira_ST1_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.9% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 35.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.3% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 48.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75819)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-34_GV70.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.7% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 23.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m âœ… revu-n-68_EV6 LONGRANGE.csv: ì™„ë£Œ (12,645í–‰, 11.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m âœ… rlaxo120_KONA LONGRANGE_201811.csv: ì™„ë£Œ (43,413í–‰, 11.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m ğŸ“¦ revu-n-34_GV70.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.1% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 9.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V015BL0000): time data \"2025-07-16 10:11:33.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.5% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 56.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… honeybto_GV60_202205.csv: ì™„ë£Œ (30,473í–‰, 13.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.8% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 26.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75789)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ğŸ“¦ cjl-dgds-006_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m âœ… pgtaxi-15_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (9,649í–‰, 16.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.2% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 21.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BD0002): time data \"2025-07-16 08:00:34.338\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m âœ… emob-1_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (37,071í–‰, 20.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.6% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 32.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 11.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-14_BONGO3_2022.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m âœ… sepira_ST1_202407.csv: ì™„ë£Œ (56,469í–‰, 21.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75787)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m ğŸ“¦ iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m ğŸ“¦ dufdl1025_EV6 LONGRANGE_202404.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0096): time data \"2025-07-16 00:00:02.159\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-18_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m ğŸ“¦ revu-n-32_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m âœ… cjl-dgds-006_PORTER2.csv: ì™„ë£Œ (54,532í–‰, 17.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.4% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 2.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ğŸ“¦ ltgdg-18_PORTER2_2023.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.8% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 37.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.2% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 5.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: deeps7011_EV6 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m ğŸ“¦ sihehe_NIRO2_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… ltgdg-14_BONGO3_2022.csv: ì™„ë£Œ (42,486í–‰, 12.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75791)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=75791)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 11537. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: man8243_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ man8243_IONIQ5 LONGRANGE_202204.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… man8243_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (11,537í–‰, 13.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.5% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 31.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m âœ… sihehe_NIRO2_202207.csv: ì™„ë£Œ (44,401í–‰, 17.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.9% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 15.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jct4589_SOUL LONGRANGE_201903.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m ğŸ“¦ jct4589_SOUL LONGRANGE_201903.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m âœ… ltgdg-18_PORTER2_2023.csv: ì™„ë£Œ (91,560í–‰, 32.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.3% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 46.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ yitaxi-8_EV6 LONGRANGE_202209.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.7% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 33.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m âœ… uk22da_IONIQ5 LONGRANGE 2022_202312.csv: ì™„ë£Œ (30,327í–‰, 56.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.1% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 1.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ“¦ revu-n-48_NIRO LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.5% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 56.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junghun1155_EV6 LONGRANGE_202302.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m âœ… jct4589_SOUL LONGRANGE_201903.csv: ì™„ë£Œ (13,984í–‰, 10.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75785)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ğŸ“¦ junghun1155_EV6 LONGRANGE_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ“¦ jog5064_EV6 LONGRANGE_202307.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jog5064_EV6 LONGRANGE_202307.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76174)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: stock_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0011): time data \"2025-07-16 04:35:21.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.8% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 34.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m âœ… revu-n-32_EV6 LONGRANGE.csv: ì™„ë£Œ (65,859í–‰, 50.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.2% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 36.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m âœ… iamme77_IONIQ5 LONGRANGE 2022_202310.csv: ì™„ë£Œ (30,605í–‰, 54.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.6% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 5.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m ğŸ“¦ stock_EV9_202307.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ableautos_EV6 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m âœ… revu-n-48_NIRO LONGRANGE.csv: ì™„ë£Œ (31,961í–‰, 19.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 55.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jinsu7426_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BJ0000): time data \"2025-07-16 00:00:00.136\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.4% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 50.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m âœ… dufdl1025_EV6 LONGRANGE_202404.csv: ì™„ë£Œ (87,412í–‰, 1ë¶„ 9.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ“¦ ableautos_EV6 LONGRANGE_202206.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75789)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75790)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… yitaxi-8_EV6 LONGRANGE_202209.csv: ì™„ë£Œ (67,823í–‰, 45.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.8% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 54.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.2% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 25.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AL0000): time data \"2025-07-16 07:30:40.451\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m âœ… junghun1155_EV6 LONGRANGE_202302.csv: ì™„ë£Œ (43,041í–‰, 43.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.5% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 57.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.9% | ì„±ê³µ: 22 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 37.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: ì™„ë£Œ (19,475í–‰, 14.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pmkp37_IONIQ5 LONGRANGE 2022_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ cjl-dgea-016_PORTER2.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-19_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.3% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 45.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V022BL0000): time data \"2025-07-16 01:17:05.000\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19475. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… deeps7011_EV6 LONGRANGE_202411.csv: ì™„ë£Œ (33,211í–‰, 1ë¶„ 15.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ğŸ“¦ lotteglogis-dg-19_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-015_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ“¦ cjl-dgss-015_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.7% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 14ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m âœ… jinsu7426_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (14,069í–‰, 43.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jskim_IONIQ5 LONGRANGE_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.1% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 13ë¶„ 41.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-14_IONIQ5 STANDARD_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.5% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 13ë¶„ 14.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.8% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 58.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.2% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 36.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.6% | ì„±ê³µ: 26 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 25.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m âœ… jog5064_EV6 LONGRANGE_202307.csv: ì™„ë£Œ (29,132í–‰, 1ë¶„ 0.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… cjl-dgea-016_PORTER2.csv: ì™„ë£Œ (139,461í–‰, 34.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ“¦ jmmath_IONIQ5 LONGRANGE_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmmath_IONIQ5 LONGRANGE_202207.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 9.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.4% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12ë¶„ 5.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ğŸ“¦ revu-n-23_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BD0018): time data \"2025-07-16 00:00:02.589\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m âœ… lotteglogis-dg-19_BONGO3.csv: ì™„ë£Œ (88,946í–‰, 23.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ğŸ“¦ cjl-dgss-013_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.8% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 58.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m âœ… stock_EV9_202307.csv: ì™„ë£Œ (42,521í–‰, 1ë¶„ 2.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.2% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 41.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: ì™„ë£Œ (39,445í–‰, 31.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10298. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m âœ… revu-n-23_EV6 LONGRANGE.csv: ì™„ë£Œ (10,298í–‰, 6.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.5% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 40.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.9% | ì„±ê³µ: 31 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 22.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ lotteglogis-dg-2_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… cjl-dgss-015_BONGO3.csv: ì™„ë£Œ (63,439í–‰, 24.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: naeibbo_BONGO3_202406.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.3% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m âœ… cjl-dgss-013_PORTER2.csv: ì™„ë£Œ (85,141í–‰, 18.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0014): time data \"2025-07-16 00:19:12.266\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m ğŸ“¦ naeibbo_BONGO3_202406.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluesky8571_EV3 LONGRANGE_202504.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76675)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.7% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 29.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m âœ… jmmath_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (25,097í–‰, 22.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.1% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 16.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.5% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11ë¶„ 0.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ“¦ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.8% | ì„±ê³µ: 35 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 56.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m ğŸ“¦ testbongo_BONGO3_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… lotteglogis-dg-2_BONGO3.csv: ì™„ë£Œ (77,227í–‰, 17.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: polarbar_IONIQ6 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m âœ… s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: ì™„ë£Œ (15,846í–‰, 7.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.2% | ì„±ê³µ: 36 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 53.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.6% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 39.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 27.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BI0003): time data \"2025-07-16 02:32:32.953\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ“¦ test01_NIRO PLUS_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ğŸ“¦ revu-n-15_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.4% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 26.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… ha8519_EV9_202401.csv: ì™„ë£Œ (59,959í–‰, 16.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: test01_NIRO PLUS_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m âœ… bluesky8571_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (26,812í–‰, 18.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.8% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 12.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.2% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 60.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.5% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 46.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76766)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0025): time data \"2025-07-16 00:02:13.084\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.9% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 46.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ ltgyc-4_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-1_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m âœ… naeibbo_BONGO3_202406.csv: ì™„ë£Œ (93,783í–‰, 25.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTNIRO01): time data \"2025-07-16 11:29:15.204\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 18068. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.3% | ì„±ê³µ: 42 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 47.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.7% | ì„±ê³µ: 43 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 37.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (92,674í–‰, 38.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.1% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 26.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.5% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 15.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… revu-n-15_EV6 LONGRANGE.csv: ì™„ë£Œ (28,964í–‰, 13.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ğŸ“¦ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m ğŸ“¦ dibidib_EV9_202407.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-16_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m âœ… cyberlmk_EV9_202308.csv: ì™„ë£Œ (59,212í–‰, 20.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0002): time data \"2025-07-16 02:29:06.309\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28964. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76826)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ“¦ esm3100_BONGO3_202304.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… ltgyc-4_BONGO3.csv: ì™„ë£Œ (113,653í–‰, 25.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.8% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 57.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wwweee_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V018AL0000): time data \"2025-07-16 01:03:37.076\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21105. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.2% | ì„±ê³µ: 47 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 52.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.6% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 41.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ wwweee_BONGO3_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… lotteglogis-dg-16_PORTER2.csv: ì™„ë£Œ (74í–‰, 19.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76957)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ“¦ leejh824_GV70_202211.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m âœ… ltgdg-23_BONGO3_2023.csv: ì™„ë£Œ (93,515í–‰, 32.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 7.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76957)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.4% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 10ë¶„ 6.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.8% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 55.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee1174_EV6 LONGRANGE_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003BL0001): time data \"2025-07-16 00:00:01.651\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.2% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 51.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m âœ… kyh108_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (32,955í–‰, 39.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.5% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 41.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m âœ… ddtaxi-1_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (63,962í–‰, 47.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.9% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 31.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.3% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 20.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-25_IONIQ 2019_201701.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.7% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 12.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m ğŸ“¦ lee1174_EV6 LONGRANGE_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ“¦ revu-n-70_KONA LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.1% | ì„±ê³µ: 54 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 7.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BJ0002): time data \"2025-07-16 00:00:00.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77118)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… wwweee_BONGO3_202304.csv: ì™„ë£Œ (35,332í–‰, 25.4ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-70_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jtkim0601_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kung417s_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ jtkim0601_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ“¦ revu-n-41_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77118)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BH0000): time data \"2025-07-16 02:56:13.968\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ“¦ kung417s_EV6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.5% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 23.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m âœ… revu-n-70_KONA LONGRANGE.csv: ì™„ë£Œ (31,416í–‰, 13.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.8% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 14.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dnwjdals1_IONIQ5 LONGRANGE_202107.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77137)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ“¦ dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.2% | ì„±ê³µ: 56 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 11.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m âœ… leejh824_GV70_202211.csv: ì™„ë£Œ (42,763í–‰, 37.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AL0000): time data \"2025-07-16 09:05:43.025\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28046. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.6% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 6.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-28_BONGO3_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… jtkim0601_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (28,046í–‰, 12.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 2.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m âœ… ltgdg-13_PORTER2_2024.csv: ì™„ë£Œ (82,041í–‰, 23.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77137)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ğŸ“¦ lotteglogis-dg-28_BONGO3_202309.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-013_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.4% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.8% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 44.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.2% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 38.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.5% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 34.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.9% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 25.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m âœ… revu-n-41_EV6 LONGRANGE.csv: ì™„ë£Œ (32,157í–‰, 26.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ğŸ“¦ revu-n-20_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m âœ… lee1174_EV6 LONGRANGE_202312.csv: ì™„ë£Œ (47,213í–‰, 30.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ lijingice007_ST1_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 48625ff_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ 48625ff_EV6 LONGRANGE_202210.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: azking_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 628dani_CASPER LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.3% | ì„±ê³µ: 62 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 36.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ğŸ“¦ 628dani_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m âœ… lotteglogis-dg-28_BONGO3_202309.csv: ì™„ë£Œ (71,168í–‰, 19.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.7% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 32.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.1% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 24.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kimzizone2_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ azking_IONIQ5 LONGRANGE 2022_202207.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ“¦ kimzizone2_IONIQ5 LONGRANGE_202203.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m âœ… kung417s_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (51,921í–‰, 31.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.5% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 28.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m âœ… 628dani_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (29,591í–‰, 13.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77367)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.8% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 23.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m âœ… revu-n-20_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (34,356í–‰, 24.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m ğŸ“¦ pgtaxi-5_NIRO LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-8_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.2% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 25.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ“¦ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m âœ… pgtaxi-5_NIRO LONGRANGE.csv: ì™„ë£Œ (36,481í–‰, 12.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.6% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 30.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ“¦ pgtaxi-4_IONIQ6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 67 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 25.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m âœ… dnwjdals1_IONIQ5 LONGRANGE_202107.csv: ì™„ë£Œ (29,540í–‰, 47.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76826)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.4% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ“¦ bbs001_IONIQ 2019_201710.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.8% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 14.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… azking_IONIQ5 LONGRANGE 2022_202207.csv: ì™„ë£Œ (67,435í–‰, 33.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77367)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… 48625ff_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (56,986í–‰, 37.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-21_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m ğŸ“¦ joiltaxi-21_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.2% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 21.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m âœ… kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (107,320í–‰, 32.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-12_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.5% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m âœ… bbs001_IONIQ 2019_201710.csv: ì™„ë£Œ (32,023í–‰, 15.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V020CA0000): time data \"2025-07-16 07:02:00.351\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ“¦ ltgdg-12_PORTER2.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sitestev6_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.9% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 16.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77123)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.3% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 8.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.7% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 1.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.1% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 53.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.5% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 45.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ wildseven_SOUL LONGRANGE_201906.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… lijingice007_ST1_202411.csv: ì™„ë£Œ (52,239í–‰, 57.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ“¦ ltgdg-24_BONGO3_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-24_BONGO3_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ clausewitx_GV70_202210.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77611)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… wildseven_SOUL LONGRANGE_201906.csv: ì™„ë£Œ (9,073í–‰, 12.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.8% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 54.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ğŸ“¦ sitestev6_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.2% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 49.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mkj2449_IONIQ5 LONGRANGE_202110.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77611)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m âœ… ltgdg-24_BONGO3_2022.csv: ì™„ë£Œ (60,213í–‰, 18.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.6% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 52.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 48.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ mkj2449_IONIQ5 LONGRANGE_202110.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.4% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 42.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m âœ… pgtaxi-4_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (79,619í–‰, 50.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junhyuk0413_NIRO2_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.8% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 35.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.2% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 28.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m âœ… ltgdg-12_PORTER2.csv: ì™„ë£Œ (109,105í–‰, 28.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77762)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ“¦ aim21c_NIRO LONGRANGE_201801.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: aim21c_NIRO LONGRANGE_201801.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003CA0001): time data \"2025-07-16 00:00:02.491\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.5% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 33.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (75,169í–‰, 48.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ğŸ“¦ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0027): time data \"2025-07-16 03:20:48.641\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-016_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m âœ… joiltaxi-21_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (67,888í–‰, 52.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.9% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 32.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m ğŸ“¦ cjl-gbyc-016_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.3% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 27.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hahakuhyun_EV6 LONGRANGE_202401.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.7% | ì„±ê³µ: 81 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 21.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m âœ… junhyuk0413_NIRO2_202209.csv: ì™„ë£Œ (13,135í–‰, 15.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.1% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77495)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ“¦ ltgdg-32_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.5% | ì„±ê³µ: 83 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m âœ… aim21c_NIRO LONGRANGE_201801.csv: ì™„ë£Œ (43,124í–‰, 19.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… jinjinjw_IONIQ5 LONGRANGE_202202.csv: ì™„ë£Œ (6,657í–‰, 9.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client SITESTEV6): time data \"2025-07-16 00:00:03.423\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.8% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 15.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.2% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 9.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ocs7777_ST1_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kate3070kr_GV70_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m âœ… hahakuhyun_EV6 LONGRANGE_202401.csv: ì™„ë£Œ (17,146í–‰, 12.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.6% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 7.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m ğŸ“¦ yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77764)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ kate3070kr_GV70_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0139): time data \"2025-07-16 00:19:12.336\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 3.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ pgtaxi-16_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… clausewitx_GV70_202210.csv: ì™„ë£Œ (30,539í–‰, 55.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ“¦ ehman486_EV3 LONGRANGE_202408.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.4% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 5.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ehman486_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… ehman486_EV3 LONGRANGE_202408.csv: ì™„ë£Œ (8,539í–‰, 4.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.8% | ì„±ê³µ: 89 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 0.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m âœ… ltgdg-32_PORTER2_2023.csv: ì™„ë£Œ (79,293í–‰, 25.5ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: xlos20_EV6 LONGRANGE_202101.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ“¦ revu-n-64_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ“¦ tsiyhj_EV6 LONGRANGE_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.2% | ì„±ê³µ: 90 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 57.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… pgtaxi-16_EV6 LONGRANGE.csv: ì™„ë£Œ (1,006í–‰, 11.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ“¦ xlos20_EV6 LONGRANGE_202101.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 1006. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sl-ev-1_EV6 LONGRANGE_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78030)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0001): time data \"2025-07-16 06:42:06.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ sl-ev-1_EV6 LONGRANGE_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m âœ… tsiyhj_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (32,308í–‰, 19.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.5% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 2.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m âœ… revu-n-64_EV6 LONGRANGE.csv: ì™„ë£Œ (26,666í–‰, 17.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.9% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 57.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-63_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78030)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.3% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m âœ… yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: ì™„ë£Œ (73,331í–‰, 35.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ“¦ revu-n-63_IONIQ5 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BG0004): time data \"2025-07-16 07:46:12.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26666. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m ğŸ“¦ revu-n-11_KONA LONGRANGE_202104.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0039): time data \"2025-07-16 00:00:01.556\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ“¦ lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.7% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 57.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… ocs7777_ST1_202407.csv: ì™„ë£Œ (61,131í–‰, 42.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.1% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 51.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m âœ… whote564_IONIQ5 LONGRANGE 2022_202311.csv: ì™„ë£Œ (50,650í–‰, 1ë¶„ 4.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: legojeon_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgyc-3_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ğŸ“¦ legojeon_NIRO LONGRANGE_201910.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m âœ… legojeon_NIRO LONGRANGE_201910.csv: ì™„ë£Œ (5,708í–‰, 2.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.5% | ì„±ê³µ: 96 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 48.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AK0000): time data \"2025-07-16 00:00:02.983\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.8% | ì„±ê³µ: 97 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 44.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… xlos20_EV6 LONGRANGE_202101.csv: ì™„ë£Œ (34,058í–‰, 31.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ ltgyc-3_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0009): time data \"2025-07-16 06:46:29.745\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78103)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-34_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.2% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 40.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-011_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… sl-ev-1_EV6 LONGRANGE_2022.csv: ì™„ë£Œ (44,723í–‰, 30.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ airme_EV6 LONGRANGE_202403.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: airme_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-34_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m âœ… revu-n-11_KONA LONGRANGE_202104.csv: ì™„ë£Œ (64,097í–‰, 26.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.6% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 42.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 39.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m ğŸ“¦ lotteglogis-dg-34_PORTER2_202301.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-22_BONGO3_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… ltgyc-3_PORTER2.csv: ì™„ë£Œ (60,177í–‰, 17.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.4% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 38.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78103)\u001b[0m âœ… ltgdg-34_BONGO3.csv: ì™„ë£Œ (66,088í–‰, 21.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m âœ… revu-n-63_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (65,280í–‰, 35.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.8% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 32.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BG0012): time data \"2025-07-16 00:21:41.216\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.2% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 26.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.5% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 21.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.9% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 16.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.3% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 11.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ ltgdg-22_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78244)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.7% | ì„±ê³µ: 104 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 6.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ“¦ leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.1% | ì„±ê³µ: 105 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 1.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m âœ… lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: ì™„ë£Œ (78,994í–‰, 40.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-004_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78244)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ğŸ“¦ parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ğŸ“¦ dmcdimo_EV6 LONGRANGE_202211.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: needman_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0010): time data \"2025-07-16 19:24:24.666\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.5% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 6.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m âœ… lotteglogis-dg-34_PORTER2_202301.csv: ì™„ë£Œ (69,096í–‰, 23.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.8% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 0.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.2% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 55.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.6% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 51.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m ğŸ“¦ needman_EV6 LONGRANGE_202403.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-20_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 46.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.4% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 42.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0021): time data \"2025-07-16 08:30:40.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… cjl-dgno-004_PORTER2.csv: ì™„ë£Œ (32,953í–‰, 17.2ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ lotteglogis-dg-20_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ“¦ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ğŸ“¦ ltgdg-17_BONGO3_2024.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78401)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24182. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.8% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 46.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… revu-n-25_NIRO2_202401.csv: ì™„ë£Œ (24,182í–‰, 11.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: helleus77_EV6 STANDARD_202108.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78401)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.2% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ğŸ“¦ helleus77_EV6 STANDARD_202108.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.5% | ì„±ê³µ: 112 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 40.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 27019. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m âœ… needman_EV6 LONGRANGE_202403.csv: ì™„ë£Œ (27,019í–‰, 22.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… lotteglogis-dg-20_BONGO3.csv: ì™„ë£Œ (89,424í–‰, 22.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78282)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m âœ… leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (38,502í–‰, 39.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.9% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 36.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0011): time data \"2025-07-16 00:00:03.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.3% | ì„±ê³µ: 114 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 32.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m âœ… parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (51,240í–‰, 36.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.7% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 28.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m âœ… ltgdg-17_BONGO3_2024.csv: ì™„ë£Œ (107,697í–‰, 23.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ cjl-dgss-012_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hmp4522_EV3 LONGRANGE_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78502)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.1% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 25.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.5% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 22.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ğŸ“¦ hmp4522_EV3 LONGRANGE_202502.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m âœ… helleus77_EV6 STANDARD_202108.csv: ì™„ë£Œ (33,318í–‰, 17.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ“¦ revu-n-18_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77925)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.8% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 19.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… yousjun_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (46,285í–‰, 31.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-8_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m ğŸ“¦ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.2% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 15.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-21_PORTER2_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.6% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 10.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-22_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003BA0012): time data \"2025-07-16 00:00:01.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77925)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ jmjang2_ST1_202405.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmjang2_ST1_202405.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0013): time data \"2025-07-16 08:14:23.270\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 11.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m âœ… cjl-dgss-012_PORTER2.csv: ì™„ë£Œ (71,699í–‰, 23.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78465)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-66_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.4% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 6.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.8% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.2% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 58.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.5% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ revu-n-66_EV6 LONGRANGE_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0008): time data \"2025-07-16 00:16:14.729\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… lotteglogis-dg-22_PORTER2_202301.csv: ì™„ë£Œ (31,080í–‰, 12.1ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parksw7022_IONIQ6 STANDARD_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (40,270í–‰, 29.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.9% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 50.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.3% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 46.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-4_KONA LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ“¦ reviewshare-4_KONA LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ mamon_ST1_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24775. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junsuck86_EV6 LONGRANGE_202304.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.7% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 44.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m âœ… parksw7022_IONIQ6 STANDARD_202502.csv: ì™„ë£Œ (24,775í–‰, 10.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m âœ… reviewshare-4_KONA LONGRANGE.csv: ì™„ë£Œ (13,310í–‰, 4.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.1% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 40.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.5% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 35.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ğŸ“¦ giugi_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ“¦ zoh71z_KONA LONGRANGE_201810.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbotti_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.8% | ì„±ê³µ: 125 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 34.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m âœ… giugi_EV6 LONGRANGE.csv: ì™„ë£Œ (6,401í–‰, 5.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m âœ… cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: ì™„ë£Œ (60,242í–‰, 35.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.2% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 30.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ“¦ bbotti_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BH0002): time data \"2025-07-16 01:08:28.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.6% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 28.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m âœ… revu-n-66_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (47,240í–‰, 22.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78731)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 24.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.4% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.8% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ“¦ mxri13_GV60_202307.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.2% | ì„±ê³µ: 129 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 12.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.5% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 9.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0000): time data \"2025-07-16 00:00:02.657\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m âœ… hmp4522_EV3 LONGRANGE_202502.csv: ì™„ë£Œ (74,081í–‰, 50.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mxri13_GV60_202307.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.9% | ì„±ê³µ: 131 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 5.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: fojokr_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ daegitaxi-2_IONIQ5 LONGRANGE_202207.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… junsuck86_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (20,326í–‰, 22.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hmc1006_ST1_202504.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m ğŸ“¦ fojokr_CASPER LONGRANGE_202410.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ runmanzzang_ST1_202507.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.3% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 5.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V015BK0000): time data \"2025-07-16 00:00:02.714\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 7999. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.7% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 1.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.1% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 57.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m âœ… mxri13_GV60_202307.csv: ì™„ë£Œ (7,999í–‰, 13.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pyh8965_EV6 LONGRANGE_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m âœ… bbotti_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (47,967í–‰, 24.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.5% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heo3252_KONA LONGRANGE_201901.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78634)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ“¦ heo3252_KONA LONGRANGE_201901.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0017): time data \"2025-07-16 00:00:01.186\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ pyh8965_EV6 LONGRANGE_202406.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.8% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 52.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… jmjang2_ST1_202405.csv: ì™„ë£Œ (58,327í–‰, 54.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-2_IONIQ 2019.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ emob-2_IONIQ 2019.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.2% | ì„±ê³µ: 135 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 51.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m âœ… heo3252_KONA LONGRANGE_201901.csv: ì™„ë£Œ (47,872í–‰, 13.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.6% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 47.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-008_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 43.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 1357rqwe_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.4% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 39.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ğŸ“¦ lee5957_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78947)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.8% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 38.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V020BD0000): time data \"2025-07-16 17:13:12.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28250. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… emob-2_IONIQ 2019.csv: ì™„ë£Œ (28,250í–‰, 7.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddongkolip_ST1_202405.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m âœ… fojokr_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (60,311í–‰, 32.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ ddongkolip_ST1_202405.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78947)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.2% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 35.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-018_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.5% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 47 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 31.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksy-taxi-p1_EV6 LONGRANGE_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.9% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 48 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 27.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-21_EV9.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.3% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 48 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.7% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ revu-n-22_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… pyh8965_EV6 LONGRANGE_202406.csv: ì™„ë£Œ (38,361í–‰, 26.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.1% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 18.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m âœ… hmc1006_ST1_202504.csv: ì™„ë£Œ (24,105í–‰, 42.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ“¦ ltgdg-1_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.5% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 16.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (4,527í–‰, 10.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ ddtaxi-4_KONA LONGRANGE_201901.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-4_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.8% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 13.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m âœ… lee5957_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (37,134í–‰, 24.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79021)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.2% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 10.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ“¦ eha031_PORTER2_202211.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m âœ… eha031_PORTER2_202211.csv: ì™„ë£Œ (9,515í–‰, 4.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.6% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 7.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 3.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.4% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 0.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.8% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 56.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.2% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 53.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.5% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 49.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78731)\u001b[0m âœ… ldw8482_EV6 LONGRANGE_202204.csv: ì™„ë£Œ (35,215í–‰, 1ë¶„ 2.2ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-31_PORTER2_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78731)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ“¦ lotteglogis-dg-31_PORTER2_202401.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79135)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ myhkk1797_EV3 LONGRANGE_202402.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.9% | ì„±ê³µ: 149 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 50.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m âœ… kepco-1_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (31,243í–‰, 24.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-33_PORTER2_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2140 MiB, 54 objects, write throughput 436 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ğŸ“¦ ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ğŸ“¦ ltgdg-33_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79200)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m ğŸ“¦ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m âœ… revu-n-38_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (18,047í–‰, 18.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.3% | ì„±ê³µ: 150 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 52.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.7% | ì„±ê³µ: 151 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 48.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m âœ… lotteglogis-dg-31_PORTER2_202401.csv: ì™„ë£Œ (73,558í–‰, 33.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ky80901_ST1_202406.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.1% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 45.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… revu-n-22_EV6 LONGRANGE.csv: ì™„ë£Œ (58,747í–‰, 55.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.5% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 41.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.8% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 38.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.2% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 34.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dlcksgh3595_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.6% | ì„±ê³µ: 154 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 31.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ğŸ“¦ hophip5677_CASPER LONGRANGE_202408.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m âœ… ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: ì™„ë£Œ (44,011í–‰, 23.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m âœ… ltgdg-33_PORTER2_2023.csv: ì™„ë£Œ (37,026í–‰, 23.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hophip5677_CASPER LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ ddtaxi-5_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ“¦ ky80901_ST1_202406.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ignatius9107_IONIQ5 N NE_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 155 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 31.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m âœ… hophip5677_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (26,141í–‰, 16.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0030): time data \"2025-07-16 00:00:00.965\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m ğŸ“¦ ignatius9107_IONIQ5 N NE_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.4% | ì„±ê³µ: 156 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 28.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-27_EV9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79135)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m ğŸ“¦ revu-n-27_EV9.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m âœ… joiltaxi-26_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (116,046í–‰, 57.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ“¦ yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79450)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=79487)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.8% | ì„±ê³µ: 157 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 30.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: ì™„ë£Œ (52,762í–‰, 1ë¶„ 18.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kgs0002_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ kgs0002_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.2% | ì„±ê³µ: 158 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 28.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… ddongkolip_ST1_202405.csv: ì™„ë£Œ (105,559í–‰, 1ë¶„ 57.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-5_PORTER2_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BE0000): time data \"2025-07-16 00:27:35.894\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.5% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 25.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ ltgdg-5_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.9% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 22.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-4_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79612)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m âœ… ignatius9107_IONIQ5 N NE_202502.csv: ì™„ë£Œ (42,337í–‰, 46.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m âœ… revu-n-27_EV9.csv: ì™„ë£Œ (44,570í–‰, 32.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-33_PORTER2_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.3% | ì„±ê³µ: 160 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 19.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ“¦ revu-n-4_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79650)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: adreamcar_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… ltgdg-5_PORTER2_2023.csv: ì™„ë£Œ (42,482í–‰, 13.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.7% | ì„±ê³µ: 161 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 16.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m ğŸ“¦ adreamcar_PORTER2_202301.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ hyisjung_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.1% | ì„±ê³µ: 162 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 13.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m âœ… yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (94,679í–‰, 49.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.5% | ì„±ê³µ: 163 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 10.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011AI0001): time data \"2025-07-16 00:55:01.025\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19216. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m âœ… adreamcar_PORTER2_202301.csv: ì™„ë£Œ (19,216í–‰, 5.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79676)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ“¦ ksjksj87_EV3 LONGRANGE_202409.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… hyisjung_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (13,350í–‰, 7.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.8% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.2% | ì„±ê³µ: 165 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 3.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jhs3101_PORTER2_202002.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ğŸ“¦ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ jhs3101_PORTER2_202002.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13350. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m âœ… myhkk1797_EV3 LONGRANGE_202402.csv: ì™„ë£Œ (135,275í–‰, 1ë¶„ 49.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ğŸ“¦ revu-n-58_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79738)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.6% | ì„±ê³µ: 166 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m âœ… ksjksj87_EV3 LONGRANGE_202409.csv: ì™„ë£Œ (39,752í–‰, 14.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-3_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 167 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 58.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m âœ… revu-n-4_EV6 LONGRANGE.csv: ì™„ë£Œ (50,873í–‰, 28.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79738)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.4% | ì„±ê³µ: 168 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 55.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ“¦ ltgdg-3_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… ddtaxi-5_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (78,401í–‰, 1ë¶„ 25.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-6_PORTER2_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-1_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.8% | ì„±ê³µ: 168 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 52.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-u-5_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ revu-u-5_IONIQ5 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m âœ… ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: ì™„ë£Œ (30,521í–‰, 28.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.2% | ì„±ê³µ: 169 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 50.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79676)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vitadoice11_IONIQ5 LONGRANGE_202106.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ğŸ“¦ vitadoice11_IONIQ5 LONGRANGE_202106.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.5% | ì„±ê³µ: 170 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 47.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m âœ… revu-n-58_EV6 LONGRANGE.csv: ì™„ë£Œ (38,846í–‰, 30.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.9% | ì„±ê³µ: 171 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 44.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m âœ… ltgdg-6_PORTER2_2024.csv: ì™„ë£Œ (80,996í–‰, 21.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79853)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.3% | ì„±ê³µ: 171 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 40.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.7% | ì„±ê³µ: 171 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 37.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ğŸ“¦ js5540810_IONIQ 2019_201607.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.1% | ì„±ê³µ: 172 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 34.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0025): time data \"2025-07-16 19:03:40.895\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 3966. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.5% | ì„±ê³µ: 173 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 31.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ğŸ“¦ ntragic_EV6 LONGRANGE_202005.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… kgs0002_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (51,054í–‰, 1ë¶„ 8.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ntragic_EV6 LONGRANGE_202005.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.8% | ì„±ê³µ: 174 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 27.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.2% | ì„±ê³µ: 175 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 24.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78465)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ“¦ yaa7890_PORTER2_202003.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0032): time data \"2025-07-18 08:44:22.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.6% | ì„±ê³µ: 176 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 21.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… revu-u-5_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (50,362í–‰, 23.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 177 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 18.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ lotteglogis-dg-10_PORTER2_202310.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0085): time data \"2025-07-16 00:19:02.185\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.4% | ì„±ê³µ: 178 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 15.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79977)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.8% | ì„±ê³µ: 179 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 12.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m âœ… vitadoice11_IONIQ5 LONGRANGE_202106.csv: ì™„ë£Œ (38,330í–‰, 23.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: norchia_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ“¦ norchia_IONIQ5 LONGRANGE_202203.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.2% | ì„±ê³µ: 180 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 9.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.5% | ì„±ê³µ: 181 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 6.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=79978)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.9% | ì„±ê³µ: 182 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 3.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6954. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m âœ… lotteglogis-dg-1_PORTER2_202306.csv: ì™„ë£Œ (6,954í–‰, 3.2ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjosooo_ST1_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79977)\u001b[0m ğŸ“¦ cjawl74_PORTER2_202412.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m âœ… norchia_IONIQ5 LONGRANGE_202203.csv: ì™„ë£Œ (15,081í–‰, 11.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-7_PORTER2_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ğŸ“¦ lotteglogis-dg-7_PORTER2_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80131)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0005): time data \"2025-07-16 08:49:29.144\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ğŸ“¦ testev9_EV9_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.3% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 1.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… lotteglogis-dg-10_PORTER2_202310.csv: ì™„ë£Œ (59,777í–‰, 34.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: gildagray_EV3 LONGRANGE_202411.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ğŸ“¦ gildagray_EV3 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ“¦ yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.7% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 59.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m âœ… testev9_EV9_2023.csv: ì™„ë£Œ (60,096í–‰, 28.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78946)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.1% | ì„±ê³µ: 185 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kor87_NIRO PLUS_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.5% | ì„±ê³µ: 186 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 53.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ğŸ“¦ kor87_NIRO PLUS_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m âœ… lotteglogis-dg-7_PORTER2_202311.csv: ì™„ë£Œ (56,141í–‰, 32.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m âœ… yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (8,599í–‰, 11.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.8% | ì„±ê³µ: 187 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 49.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wntjdgml_CASPER LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.2% | ì„±ê³µ: 188 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 46.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ“¦ wntjdgml_CASPER LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-8_PORTER2_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ğŸ“¦ emr4540_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m âœ… gildagray_EV3 LONGRANGE_202411.csv: ì™„ë£Œ (38,865í–‰, 23.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m âœ… emr4540_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (14,724í–‰, 9.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.6% | ì„±ê³µ: 189 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 43.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79978)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 190 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 40.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m âœ… yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: ì™„ë£Œ (108,798í–‰, 1ë¶„ 8.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m ğŸ“¦ lotteglogis-dg-8_PORTER2_202308.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.4% | ì„±ê³µ: 191 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 37.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… jsmtnaud_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (35,498í–‰, 1ë¶„ 8.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ğŸ“¦ beston_IONIQ6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ğŸ“¦ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: musein_EV9_202404.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.8% | ì„±ê³µ: 192 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m âœ… kor87_NIRO PLUS_202207.csv: ì™„ë£Œ (17,267í–‰, 17.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.2% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 31.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0008): time data \"2025-07-16 06:32:03.805\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m âœ… wntjdgml_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (32,987í–‰, 14.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-010_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ğŸ“¦ cjl-gbyc-010_BONGO3.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.5% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 58 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 27.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.9% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 59 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 24.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.3% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 21.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80375)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.7% | ì„±ê³µ: 194 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 18.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m âœ… cjl-gbyc-010_BONGO3.csv: ì™„ë£Œ (68í–‰, 1.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80374)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m ğŸ“¦ musein_EV9_202404.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.1% | ì„±ê³µ: 195 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 15.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m âœ… lotteglogis-dg-8_PORTER2_202308.csv: ì™„ë£Œ (84,620í–‰, 23.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.5% | ì„±ê³µ: 196 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m âœ… bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (49,756í–‰, 20.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.8% | ì„±ê³µ: 197 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79977)\u001b[0m âœ… cjawl74_PORTER2_202412.csv: ì™„ë£Œ (135,761í–‰, 1ë¶„ 14.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m âœ… musein_EV9_202404.csv: ì™„ë£Œ (47,696í–‰, 18.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.2% | ì„±ê³µ: 198 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.6% | ì„±ê³µ: 199 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3.1ì´ˆ\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 200ê°œ | âŒ ì‹¤íŒ¨: 60ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 9,688,061í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 13ë¶„ 17.4ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 3.1ì´ˆ\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 13ë¶„ 17.4ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 3.1ì´ˆ\n",
      "   - ì„±ê³µë¥ : 76.9%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 9,688,061í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 43739129í–‰/ì‹œê°„\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013AK0001): time data \"2025-07-16 00:00:02.935\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m âœ… beston_IONIQ6 LONGRANGE_202201.csv: ì™„ë£Œ (40,009í–‰, 22.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80388)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:44:06,463\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 200ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ekfmd3152_KONA LONGRANGE_202004.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.5% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 35.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 49.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.5% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 16.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 2.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ rlaxo120_KONA LONGRANGE_201811.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ğŸ“¦ emob-1_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-34_GV70.csv\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m ğŸ“¦ revu-n-34_GV70.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13550. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m âœ… ekfmd3152_KONA LONGRANGE_202004.csv: ì™„ë£Œ (13,550í–‰, 7.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.5% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 40.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m ğŸ“¦ pgtaxi-15_IONIQ6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.0% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ cjl-dgds-006_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80574)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.5% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 2.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… rlaxo120_KONA LONGRANGE_201811.csv: ì™„ë£Œ (38,620í–‰, 9.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80519)\u001b[0m âœ… ajutaxi-9_IONIQ 2019_201701.csv: ì™„ë£Œ (71,425í–‰, 18.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.0% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 4.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80525)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BD0002): time data \"2025-07-16 08:00:34.338\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.5% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 25.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m âœ… emob-1_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (43,419í–‰, 19.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ ltgdg-14_BONGO3_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… alice2235_PORTER2_202201.csv: ì™„ë£Œ (69,458í–‰, 19.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 4.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-14_BONGO3_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80663)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.5% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 45.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013BL0002): time data \"2025-07-16 10:31:35.120\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m âœ… pgtaxi-15_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (58,846í–‰, 24.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m âœ… revu-n-68_EV6 LONGRANGE.csv: ì™„ë£Œ (37,780í–‰, 25.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.0% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m ğŸ“¦ ajutaxi-27_IONIQ 2019_201701.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… cjl-dgds-006_PORTER2.csv: ì™„ë£Œ (69,957í–‰, 17.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ğŸ“¦ revu-n-32_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.5% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 13.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80523)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ sihehe_NIRO2_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m âœ… revu-n-34_GV70.csv: ì™„ë£Œ (81,578í–‰, 28.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80663)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-8_EV6 LONGRANGE_202209.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… ltgdg-14_BONGO3_2022.csv: ì™„ë£Œ (30,281í–‰, 14.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.0% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 41.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.5% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 8.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ jct4589_SOUL LONGRANGE_201903.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jct4589_SOUL LONGRANGE_201903.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m âœ… ajutaxi-27_IONIQ 2019_201701.csv: ì™„ë£Œ (80,948í–‰, 19.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ“¦ revu-n-48_NIRO LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 10.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… sihehe_NIRO2_202207.csv: ì™„ë£Œ (53,601í–‰, 14.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pity2002_IONIQ5 LONGRANGE_202111.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.5% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 2.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ pity2002_IONIQ5 LONGRANGE_202111.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… pity2002_IONIQ5 LONGRANGE_202111.csv: ì™„ë£Œ (667í–‰, 2.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junghun1155_EV6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.0% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 34.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: stock_EV9_202307.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.5% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… jct4589_SOUL LONGRANGE_201903.csv: ì™„ë£Œ (26,020í–‰, 11.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 9.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m âœ… ltgdg-18_PORTER2_2023.csv: ì™„ë£Œ (56,124í–‰, 19.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.5% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 2.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ caifa0622_IONIQ5 LONGRANGE_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80528)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.0% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 7.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m âœ… man8243_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (34,286í–‰, 16.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… revu-n-48_NIRO LONGRANGE.csv: ì™„ë£Œ (32,613í–‰, 12.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.5% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 48.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0011): time data \"2025-07-16 04:35:21.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ stock_EV9_202307.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 46.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.5% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 28.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80663)\u001b[0m âœ… yitaxi-8_EV6 LONGRANGE_202209.csv: ì™„ë£Œ (29,325í–‰, 21.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ“¦ j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.0% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 16.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.5% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 1.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80663)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ğŸ“¦ ajutaxi-14_IONIQ5 STANDARD_202202.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m âœ… revu-n-32_EV6 LONGRANGE.csv: ì™„ë£Œ (89,842í–‰, 34.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-14_IONIQ5 STANDARD_202202.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80893)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ğŸ“¦ cjl-dgss-013_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… caifa0622_IONIQ5 LONGRANGE_202107.csv: ì™„ë£Œ (46,816í–‰, 23.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.0% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 10.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V022BL0000): time data \"2025-07-16 01:17:05.000\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.5% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 1.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m âœ… j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: ì™„ë£Œ (63,987í–‰, 19.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 22 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 51.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.5% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 37.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.0% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.5% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 11.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.0% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 58.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.5% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 48.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ“¦ jmmath_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ revu-n-23_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m âœ… ajutaxi-14_IONIQ5 STANDARD_202202.csv: ì™„ë£Œ (27,931í–‰, 17.5ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ha8519_EV9_202401.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BI0001): time data \"2025-07-16 00:06:47.085\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ğŸ“¦ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-23_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81007)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m ğŸ“¦ ha8519_EV9_202401.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0014): time data \"2025-07-16 00:19:12.266\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.0% | ì„±ê³µ: 26 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 17.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m âœ… cjl-dgss-013_PORTER2.csv: ì™„ë£Œ (60,030í–‰, 19.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21002. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.5% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 14.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… revu-n-23_EV6 LONGRANGE.csv: ì™„ë£Œ (21,002í–‰, 11.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.0% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 3.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m âœ… s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: ì™„ë£Œ (3,076í–‰, 7.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.5% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 57.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ğŸ“¦ testbongo_BONGO3_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… cjl-dgea-016_PORTER2.csv: ì™„ë£Œ (124,755í–‰, 33.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cyberlmk_EV9_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 59.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.5% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 52.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.0% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 41.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m âœ… ha8519_EV9_202401.csv: ì™„ë£Œ (55,813í–‰, 15.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.5% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 32.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ğŸ“¦ cyberlmk_EV9_202308.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: test01_NIRO PLUS_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.0% | ì„±ê³µ: 31 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 34.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.5% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 27.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m âœ… lotteglogis-dg-2_BONGO3.csv: ì™„ë£Œ (64,872í–‰, 21.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.0% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 23.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.5% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 19.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ“¦ ddtaxi-1_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgyc-4_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTNIRO01): time data \"2025-07-16 11:29:15.204\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 524. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ğŸ“¦ ltgyc-4_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ğŸ“¦ revu-n-57_IONIQ5 LONGRANGE 2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.0% | ì„±ê³µ: 35 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 20.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m âœ… testbongo_BONGO3_202201.csv: ì™„ë£Œ (97,387í–‰, 18.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client HANIONIQ5): time data \"2025-07-17 09:06:39.046\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19006. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.5% | ì„±ê³µ: 36 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 15.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81162)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-23_BONGO3_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ“¦ dibidib_EV9_202407.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m ğŸ“¦ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m âœ… test01_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (19,006í–‰, 17.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ ltgdg-23_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BJ0001): time data \"2025-07-16 00:00:02.685\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 30.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m âœ… cyberlmk_EV9_202308.csv: ì™„ë£Œ (74,944í–‰, 22.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.5% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 39.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ğŸ“¦ relier_NIRO2_202207.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m âœ… ltgyc-4_BONGO3.csv: ì™„ë£Œ (81,156í–‰, 20.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BJ0002): time data \"2025-07-16 00:00:00.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 4366. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.0% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 32.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ esm3100_BONGO3_202304.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m âœ… dibidib_EV9_202407.csv: ì™„ë£Œ (4,366í–‰, 14.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81256)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ“¦ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.5% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 39.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… ddtaxi-1_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (60,172í–‰, 28.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81256)\u001b[0m ğŸ“¦ woojukjk_EV6 LONGRANGE_202304.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.0% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 33.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-13_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m ğŸ“¦ boxing0217_IONIQ5 N NE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.5% | ì„±ê³µ: 42 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 32.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.0% | ì„±ê³µ: 43 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m âœ… revu-n-57_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (76,839í–‰, 31.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V018AL0000): time data \"2025-07-16 01:03:37.076\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m âœ… relier_NIRO2_202207.csv: ì™„ë£Œ (110,300í–‰, 23.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ“¦ ltgdg-13_PORTER2_2024.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.5% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 22.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ jtkim0601_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jtkim0601_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.0% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 16.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-41_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.5% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 14.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m âœ… kyh108_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (33,383í–‰, 27.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ“¦ revu-n-41_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 11.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003BL0001): time data \"2025-07-16 00:00:01.651\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… esm3100_BONGO3_202304.csv: ì™„ë£Œ (82,853í–‰, 17.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.5% | ì„±ê³µ: 47 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 7.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ“¦ ajutaxi-25_IONIQ 2019_201701.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-28_BONGO3_202309.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ğŸ“¦ kung417s_EV6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.0% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 5.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80525)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.5% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 0.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.0% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 54.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m âœ… ltgdg-13_PORTER2_2024.csv: ì™„ë£Œ (58,321í–‰, 15.0ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ“¦ revu-n-20_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 48625ff_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ lotteglogis-dg-28_BONGO3_202309.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ cjl-gbyc-013_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.5% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 58.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… ajutaxi-25_IONIQ 2019_201701.csv: ì™„ë£Œ (71,948í–‰, 16.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 628dani_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m âœ… revu-n-41_EV6 LONGRANGE.csv: ì™„ë£Œ (47,455í–‰, 16.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.0% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 56.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.5% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 50.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.0% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 45.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m âœ… boxing0217_IONIQ5 N NE_202410.csv: ì™„ë£Œ (46,180í–‰, 25.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.5% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 43.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ“¦ 628dani_CASPER LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… lotteglogis-dg-28_BONGO3_202309.csv: ì™„ë£Œ (64,149í–‰, 15.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 37.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ pgtaxi-5_NIRO LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-8_GV70.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.5% | ì„±ê³µ: 54 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 39.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.0% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 37.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m âœ… kung417s_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (51,495í–‰, 21.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m âœ… revu-n-20_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (26,489í–‰, 17.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ“¦ pgtaxi-4_IONIQ6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… cjl-gbyc-013_BONGO3.csv: ì™„ë£Œ (95,109í–‰, 20.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.5% | ì„±ê³µ: 56 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 34.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.0% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 30.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26489. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ğŸ“¦ bbs001_IONIQ 2019_201710.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.5% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 27.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ“¦ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… pgtaxi-5_NIRO LONGRANGE.csv: ì™„ë£Œ (39,827í–‰, 11.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81500)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sitestev6_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… 628dani_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (44,948í–‰, 13.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ ltgdg-12_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ğŸ“¦ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ joiltaxi-21_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.0% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 42.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V020CA0000): time data \"2025-07-16 07:02:00.351\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m âœ… bbs001_IONIQ 2019_201710.csv: ì™„ë£Œ (37,427í–‰, 15.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ“¦ sitestev6_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m âœ… 48625ff_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (65,905í–‰, 39.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.5% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 45.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ“¦ cjl-dgwe-005_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81363)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ğŸ“¦ ajutaxi-1_IONIQ 2019_201701.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.0% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 55.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m âœ… kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (132,781í–‰, 42.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.5% | ì„±ê³µ: 62 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 51.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… ltgdg-12_PORTER2.csv: ì™„ë£Œ (84,821í–‰, 29.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m ğŸ“¦ revu-n-39_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 48.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-24_BONGO3_2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.5% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 44.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0001): time data \"2025-07-16 09:25:52.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ“¦ ltgdg-24_BONGO3_2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m âœ… cjl-dgwe-005_PORTER2.csv: ì™„ë£Œ (51,481í–‰, 15.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mkj2449_IONIQ5 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.0% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 47.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m âœ… pgtaxi-4_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (69,877í–‰, 50.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ revu-n-54_EV6 LONGRANGE_2023.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.5% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 47.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-54_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m âœ… ltgdg-24_BONGO3_2022.csv: ì™„ë£Œ (45,327í–‰, 11.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.0% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: aim21c_NIRO LONGRANGE_201801.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81722)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.5% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 38.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003CA0001): time data \"2025-07-16 00:00:02.491\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m âœ… sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (82,565í–‰, 47.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.0% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 33.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ“¦ aim21c_NIRO LONGRANGE_201801.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.5% | ì„±ê³µ: 67 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 30.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.0% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 25.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.5% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 20.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… revu-n-54_EV6 LONGRANGE_2023.csv: ì™„ë£Œ (7,593í–‰, 8.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-16_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ğŸ“¦ ltgdg-32_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ“¦ hahakuhyun_EV6 LONGRANGE_202401.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 22.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m âœ… mkj2449_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (50,553í–‰, 21.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.5% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 22.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.0% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 17.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.5% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 12.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ pgtaxi-16_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m âœ… sitestev6_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (97,301í–‰, 58.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.0% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 9.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.5% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 6.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m âœ… revu-n-39_EV6 LONGRANGE.csv: ì™„ë£Œ (69,658í–‰, 40.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ tsiyhj_EV6 LONGRANGE_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sl-ev-1_EV6 LONGRANGE_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ“¦ revu-n-64_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m âœ… aim21c_NIRO LONGRANGE_201801.csv: ì™„ë£Œ (30,452í–‰, 16.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0000): time data \"2025-07-16 06:37:08.097\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ“¦ sl-ev-1_EV6 LONGRANGE_2022.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.0% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 8.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m âœ… hahakuhyun_EV6 LONGRANGE_202401.csv: ì™„ë£Œ (52,104í–‰, 23.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ“¦ revu-n-63_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81931)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.5% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 14.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m âœ… ltgdg-32_PORTER2_2023.csv: ì™„ë£Œ (37,855í–‰, 30.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81931)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.0% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 14.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… pgtaxi-16_EV6 LONGRANGE.csv: ì™„ë£Œ (67,811í–‰, 35.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… tsiyhj_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (48,953í–‰, 26.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.5% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 10.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BG0004): time data \"2025-07-16 07:46:12.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m âœ… revu-n-64_EV6 LONGRANGE.csv: ì™„ë£Œ (43,765í–‰, 31.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-34_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 10.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ revu-n-11_KONA LONGRANGE_202104.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81544)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.5% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 11.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ ltgyc-3_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0009): time data \"2025-07-16 06:46:29.745\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23043. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m âœ… sl-ev-1_EV6 LONGRANGE_2022.csv: ì™„ë£Œ (23,043í–‰, 35.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-22_BONGO3_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82160)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.0% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 10.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.5% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 6.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ğŸ“¦ cjl-dgds-011_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AK0000): time data \"2025-07-16 00:00:02.983\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m âœ… xlos20_EV6 LONGRANGE_202101.csv: ì™„ë£Œ (31,584í–‰, 41.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.0% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 1.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: maxcom3_EV9_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BG0012): time data \"2025-07-16 00:21:41.216\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 25199. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m âœ… revu-n-63_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (25,199í–‰, 35.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.5% | ì„±ê³µ: 81 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 59.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.0% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 57.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ğŸ“¦ maxcom3_EV9_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m âœ… ltgdg-34_BONGO3.csv: ì™„ë£Œ (44,161í–‰, 21.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-004_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.5% | ì„±ê³µ: 83 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 53.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.0% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 49.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.5% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 45.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 40.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.5% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 36.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.0% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 33.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ“¦ cjl-dgno-004_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.5% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 29.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m âœ… cjl-dgds-011_PORTER2.csv: ì™„ë£Œ (47,445í–‰, 17.4ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81308)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.0% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 27.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.5% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 23.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ cjl-dgss-012_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… revu-n-25_NIRO2_202401.csv: ì™„ë£Œ (23,982í–‰, 9.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: helleus77_EV6 STANDARD_202108.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.0% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 22.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82327)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.5% | ì„±ê³µ: 89 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 22.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23982. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ“¦ ltgdg-17_BONGO3_2024.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m âœ… cjl-dgno-004_PORTER2.csv: ì™„ë£Œ (59,190í–‰, 16.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.0% | ì„±ê³µ: 90 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 18.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ“¦ joiltaxi-3_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82072)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21146. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m âœ… maxcom3_EV9_202312.csv: ì™„ë£Œ (43,505í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.5% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 17.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m âœ… helleus77_EV6 STANDARD_202108.csv: ì™„ë£Œ (21,146í–‰, 14.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 13.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ“¦ revu-n-18_BONGO3.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ğŸ“¦ lotteglogis-dg-22_PORTER2_202301.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.5% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 12.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-22_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.0% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 8.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82455)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… needman_EV6 LONGRANGE_202403.csv: ì™„ë£Œ (31,768í–‰, 26.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.5% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 5.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.0% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 1.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ğŸ“¦ reviewshare-4_KONA LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ eric_IONIQ5 LONGRANGE_202205.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82475)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.5% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 1.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: eric_IONIQ5 LONGRANGE_202205.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m âœ… ltgdg-17_BONGO3_2024.csv: ì™„ë£Œ (124,788í–‰, 26.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0008): time data \"2025-07-16 00:16:14.729\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28652. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m âœ… lotteglogis-dg-22_PORTER2_202301.csv: ì™„ë£Œ (28,652í–‰, 11.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.0% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 57.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.5% | ì„±ê³µ: 96 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 54.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m ğŸ“¦ giugi_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ“¦ zoh71z_KONA LONGRANGE_201810.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.0% | ì„±ê³µ: 97 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 51.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m âœ… giugi_EV6 LONGRANGE.csv: ì™„ë£Œ (4,834í–‰, 2.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.5% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 49.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0040): time data \"2025-07-16 06:01:20.518\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m âœ… revu-n-18_BONGO3.csv: ì™„ë£Œ (51,055í–‰, 14.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbotti_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82475)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ bbotti_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 48.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m âœ… reviewshare-4_KONA LONGRANGE.csv: ì™„ë£Œ (27,455í–‰, 11.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m âœ… eric_IONIQ5 LONGRANGE_202205.csv: ì™„ë£Œ (26,443í–‰, 15.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.5% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 44.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-005_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: ì™„ë£Œ (70,838í–‰, 33.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.0% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 41.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.5% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 37.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0000): time data \"2025-07-16 00:00:02.657\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.0% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 34.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ ajutaxi-18_IONIQ 2019_201801.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81934)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ğŸ“¦ shome_SOUL LONGRANGE_201901.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m âœ… zoh71z_KONA LONGRANGE_201810.csv: ì™„ë£Œ (38,664í–‰, 10.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mxri13_GV60_202307.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BH0002): time data \"2025-07-16 01:08:28.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.5% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 34.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.0% | ì„±ê³µ: 104 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 30.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ heo3252_KONA LONGRANGE_201901.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82586)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ revu-n-49_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (71,479í–‰, 30.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0017): time data \"2025-07-16 00:00:01.186\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m ğŸ“¦ pyh8965_EV6 LONGRANGE_202406.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… bbotti_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (48,990í–‰, 20.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.5% | ì„±ê³µ: 105 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 30.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V015BK0000): time data \"2025-07-16 00:00:02.714\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9676. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.0% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 27.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.5% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 24.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ğŸ“¦ emob-2_IONIQ 2019.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 21.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ“¦ lee5957_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… ajutaxi-18_IONIQ 2019_201801.csv: ì™„ë£Œ (36,931í–‰, 17.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 1357rqwe_IONIQ5 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82646)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.5% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 19.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m âœ… shome_SOUL LONGRANGE_201901.csv: ì™„ë£Œ (84,721í–‰, 18.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.0% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.5% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 12.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20598. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ cjl-dgea-008_BONGO3.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ“¦ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V020BD0000): time data \"2025-07-16 17:13:12.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.0% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 10.5ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82705)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m âœ… emob-2_IONIQ 2019.csv: ì™„ë£Œ (32,969í–‰, 9.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-21_EV9.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m âœ… daegitaxi-2_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (70,019í–‰, 30.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.5% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 8.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ“¦ revu-n-21_EV9.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m âœ… lee5957_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (52,974í–‰, 16.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.0% | ì„±ê³µ: 112 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 7.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-22_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82734)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.5% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… cjl-dgea-008_BONGO3.csv: ì™„ë£Œ (51,105í–‰, 13.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.0% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 1.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.5% | ì„±ê³µ: 114 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 58.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 55.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.5% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 52.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.0% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 49.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ kepco-1_IONIQ5 LONGRANGE_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m âœ… revu-n-49_EV6 LONGRANGE.csv: ì™„ë£Œ (42,100í–‰, 26.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m âœ… pyh8965_EV6 LONGRANGE_202406.csv: ì™„ë£Œ (32,252í–‰, 27.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ“¦ revu-n-22_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.5% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 48.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ“¦ ddtaxi-4_KONA LONGRANGE_201901.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: myhkk1797_EV3 LONGRANGE_202402.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.0% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 46.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m âœ… 1357rqwe_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (39,937í–‰, 25.8ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82799)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ yitaxi-3_EV6 LONGRANGE_202209.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.5% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 44.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-31_PORTER2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ“¦ ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BE0004): time data \"2025-07-16 01:14:58.627\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… revu-n-21_EV9.csv: ì™„ë£Œ (92,884í–‰, 24.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… kepco-1_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (58,040í–‰, 21.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ğŸ“¦ myhkk1797_EV3 LONGRANGE_202402.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-33_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.0% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 43.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82420)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.5% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 41.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82918)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: endy11_PORTER2_202306.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m âœ… ddtaxi-4_KONA LONGRANGE_201901.csv: ì™„ë£Œ (117,328í–‰, 24.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.0% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 39.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dlcksgh3595_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.5% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 36.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 33.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m âœ… ltgdg-33_PORTER2_2023.csv: ì™„ë£Œ (42,696í–‰, 16.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.5% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 31.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m ğŸ“¦ endy11_PORTER2_202306.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… revu-n-38_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (40,151í–‰, 12.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-27_EV9.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.0% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 29.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82420)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.5% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 26.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V022AK0000): time data \"2025-07-16 07:36:20.441\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ğŸ“¦ ltgdg-5_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m âœ… ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: ì™„ë£Œ (41,527í–‰, 20.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-33_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m âœ… lotteglogis-dg-31_PORTER2_202401.csv: ì™„ë£Œ (60,149í–‰, 26.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.0% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 25.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.5% | ì„±ê³µ: 125 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 22.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ğŸ“¦ lotteglogis-dg-33_PORTER2_202301.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.0% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 19.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m âœ… revu-n-22_EV6 LONGRANGE.csv: ì™„ë£Œ (76,389í–‰, 44.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ“¦ hyisjung_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: adreamcar_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m âœ… yitaxi-3_EV6 LONGRANGE_202209.csv: ì™„ë£Œ (100,213í–‰, 40.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m âœ… endy11_PORTER2_202306.csv: ì™„ë£Œ (61,859í–‰, 19.3ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.5% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 17.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ğŸ“¦ revu-n-4_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ adreamcar_PORTER2_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83036)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.0% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m âœ… ltgdg-5_PORTER2_2023.csv: ì™„ë£Œ (43,304í–‰, 17.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.5% | ì„±ê³µ: 129 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 13.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m ğŸ“¦ ksjksj87_EV3 LONGRANGE_202409.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 10.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.5% | ì„±ê³µ: 131 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 7.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82799)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-6_PORTER2_2024.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.0% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 5.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.5% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m âœ… hyisjung_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (17,591í–‰, 11.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ“¦ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17591. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m âœ… myhkk1797_EV3 LONGRANGE_202402.csv: ì™„ë£Œ (120,791í–‰, 47.2ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.0% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 0.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ğŸ“¦ revu-n-58_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ğŸ“¦ ltgdg-6_PORTER2_2024.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.5% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 58.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m âœ… ksjksj87_EV3 LONGRANGE_202409.csv: ì™„ë£Œ (60,054í–‰, 12.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.0% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 55.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.5% | ì„±ê³µ: 135 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 53.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0025): time data \"2025-07-16 19:03:40.895\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 4088. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ğŸ“¦ ntragic_EV6 LONGRANGE_202005.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ntragic_EV6 LONGRANGE_202005.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m âœ… js5540810_IONIQ 2019_201607.csv: ì™„ë£Œ (4,088í–‰, 2.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.0% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 51.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m âœ… revu-n-4_EV6 LONGRANGE.csv: ì™„ë£Œ (57,548í–‰, 28.4ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83203)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.5% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 49.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… ltgdg-3_PORTER2_2023.csv: ì™„ë£Œ (49,563í–‰, 18.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 46.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ğŸ“¦ yaa7890_PORTER2_202003.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83227)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.5% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 44.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.0% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 41.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m âœ… ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: ì™„ë£Œ (51,682í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.5% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 39.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m âœ… cjl-dgds-007_PORTER2.csv: ì™„ë£Œ (68,132í–‰, 15.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83203)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ğŸ“¦ lotteglogis-dg-1_PORTER2_202306.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.0% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 37.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m âœ… revu-n-58_EV6 LONGRANGE.csv: ì™„ë£Œ (43,837í–‰, 26.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-7_PORTER2_202311.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.5% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 3053. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.0% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 32.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m âœ… ntragic_EV6 LONGRANGE_202005.csv: ì™„ë£Œ (51,191í–‰, 18.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.5% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 29.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ“¦ testev9_EV9_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ğŸ“¦ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ğŸ“¦ wntjdgml_CASPER LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.0% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 27.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BB0000): time data \"2025-07-16 00:25:46.182\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82734)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m âœ… koreataxi-1_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (71,960í–‰, 33.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ğŸ“¦ lotteglogis-dg-8_PORTER2_202308.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m ğŸ“¦ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.5% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 25.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m âœ… testev9_EV9_2023.csv: ì™„ë£Œ (61,460í–‰, 14.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ğŸ“¦ revu-n-35_GV70.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-010_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 23.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.5% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 20.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m âœ… wntjdgml_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (36,282í–‰, 12.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83227)\u001b[0m âœ… lotteglogis-dg-10_PORTER2_202310.csv: ì™„ë£Œ (66,333í–‰, 21.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m ğŸ“¦ beston_IONIQ6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.0% | ì„±ê³µ: 149 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 18.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m âœ… lotteglogis-dg-7_PORTER2_202311.csv: ì™„ë£Œ (63,646í–‰, 18.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.5% | ì„±ê³µ: 150 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 16.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83227)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=83351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V019CA0000): time data \"2025-07-16 07:45:30.007\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m ğŸ“¦ cody8406_IONIQ 2020_202007.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m âœ… cody8406_IONIQ 2020_202007.csv: ì™„ë£Œ (47,422í–‰, 10.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.0% | ì„±ê³µ: 151 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 14.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ğŸ“¦ joiltaxi-9_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.5% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.0% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m âœ… revu-n-35_GV70.csv: ì™„ë£Œ (24,186í–‰, 20.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.5% | ì„±ê³µ: 154 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m âœ… bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (53,476í–‰, 28.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.0% | ì„±ê³µ: 155 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013AK0001): time data \"2025-07-16 00:00:02.935\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.5% | ì„±ê³µ: 156 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m âœ… yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: ì™„ë£Œ (132,336í–‰, 48.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 100.0% | ì„±ê³µ: 157 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 0.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m âœ… beston_IONIQ6 LONGRANGE_202201.csv: ì™„ë£Œ (47,385í–‰, 30.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m âœ… joiltaxi-9_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (85,968í–‰, 22.2ì´ˆ)\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 157ê°œ | âŒ ì‹¤íŒ¨: 43ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,414,617í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 7ë¶„ 48.5ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 2.3ì´ˆ\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 7ë¶„ 48.5ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 2.3ì´ˆ\n",
      "   - ì„±ê³µë¥ : 78.5%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 8,414,617í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 64659699í–‰/ì‹œê°„\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:51:58,717\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 20ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jinsu7426_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ğŸ“¦ sepira_ST1_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m ğŸ“¦ wildseven_SOUL LONGRANGE_201906.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ğŸ“¦ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junhyuk0413_NIRO2_202209.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 20.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0027): time data \"2025-07-16 07:39:24.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6608. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m âœ… wildseven_SOUL LONGRANGE_201906.csv: ì™„ë£Œ (6,608í–‰, 6.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m ğŸ“¦ wwweee_BONGO3_202304.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83595)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 42x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m ğŸ“¦ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jinjinjw_IONIQ5 LONGRANGE_202202.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0029): time data \"2025-07-16 06:03:10.847\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24340. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 58.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m âœ… junhyuk0413_NIRO2_202209.csv: ì™„ë£Œ (24,340í–‰, 11.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m ğŸ“¦ jinjinjw_IONIQ5 LONGRANGE_202202.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0059): time data \"2025-07-16 00:00:09.733\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28872. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 27.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 3.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmjang2_ST1_202405.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83560)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ğŸ“¦ jmjang2_ST1_202405.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m âœ… sepira_ST1_202407.csv: ì™„ë£Œ (31,165í–‰, 14.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0041): time data \"2025-07-16 00:00:00.342\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parksw7022_IONIQ6 STANDARD_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 4.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83679)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mamon_ST1_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83552)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ğŸ“¦ parksw7022_IONIQ6 STANDARD_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83551)\u001b[0m âœ… naeibbo_BONGO3_202406.csv: ì™„ë£Œ (95,964í–‰, 22.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m âœ… uk22da_IONIQ5 LONGRANGE 2022_202312.csv: ì™„ë£Œ (35,942í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 47.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m ğŸ“¦ hmc1006_ST1_202504.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 39.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0037): time data \"2025-07-16 00:00:00.484\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: eha031_PORTER2_202211.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m âœ… jinjinjw_IONIQ5 LONGRANGE_202202.csv: ì™„ë£Œ (25,080í–‰, 17.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 30.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m âœ… whote564_IONIQ5 LONGRANGE 2022_202311.csv: ì™„ë£Œ (41,557í–‰, 21.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ğŸ“¦ eha031_PORTER2_202211.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 26.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vitadoice11_IONIQ5 LONGRANGE_202106.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m ğŸ“¦ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m âœ… parksw7022_IONIQ6 STANDARD_202502.csv: ì™„ë£Œ (34,112í–‰, 14.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m âœ… jmjang2_ST1_202405.csv: ì™„ë£Œ (41,861í–‰, 20.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ğŸ“¦ vitadoice11_IONIQ5 LONGRANGE_202106.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 24.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0036): time data \"2025-07-16 02:06:04.534\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20066. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjosooo_ST1_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 21.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 16.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83764)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 14.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m âœ… eha031_PORTER2_202211.csv: ì™„ë£Œ (23,743í–‰, 13.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m ğŸ“¦ cjosooo_ST1_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0065): time data \"2025-07-16 00:00:00.107\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 12.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m âœ… vitadoice11_IONIQ5 LONGRANGE_202106.csv: ì™„ë£Œ (23,791í–‰, 17.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0085): time data \"2025-07-16 00:19:02.185\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23791. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0032): time data \"2025-07-16 00:00:03.689\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m âœ… jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: ì™„ë£Œ (70,718í–‰, 23.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 0 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m âœ… cjosooo_ST1_202407.csv: ì™„ë£Œ (50,843í–‰, 17.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0024): time data \"2025-07-16 00:59:23.925\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 20ê°œ | âŒ ì‹¤íŒ¨: 0ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 948,634í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 57.9ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 2.9ì´ˆ\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 57.9ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 2.9ì´ˆ\n",
      "   - ì„±ê³µë¥ : 100.0%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 948,634í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 58999003í–‰/ì‹œê°„\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83552)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:52:59,948\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 300ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emob-1_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 34.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 28.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.0% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 32.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.3% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 7.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ“¦ ekfmd3152_KONA LONGRANGE_202004.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m ğŸ“¦ emob-1_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 10.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17804. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… ekfmd3152_KONA LONGRANGE_202004.csv: ì™„ë£Œ (17,804í–‰, 4.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.0% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.3% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sepira_ST1_202407.csv\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m ğŸ“¦ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ“¦ lostcity1_PORTER2_202412.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ğŸ“¦ pgtaxi-15_IONIQ6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.7% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 23.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0001): time data \"2025-07-16 07:29:00.303\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m âœ… shcs111_KONA LONGRANGE_201809.csv: ì™„ë£Œ (31,481í–‰, 9.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.0% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V015BL0000): time data \"2025-07-16 10:11:33.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 22460. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m âœ… honeybto_GV60_202205.csv: ì™„ë£Œ (22,460í–‰, 10.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.3% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 45.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.7% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 13.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-11_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jdisky_IONIQ5 LONGRANGE_202112.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.0% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 12.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.3% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 8 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 0.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ“¦ jdisky_IONIQ5 LONGRANGE_202112.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.7% | ì„±ê³µ: 5 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 23.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m âœ… rlaxo120_KONA LONGRANGE_201811.csv: ì™„ë£Œ (32,241í–‰, 12.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-27_IONIQ 2019_201701.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ“¦ cjl-dgds-006_PORTER2.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.0% | ì„±ê³µ: 6 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 43.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m âœ… emob-1_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (36,771í–‰, 20.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.3% | ì„±ê³µ: 7 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 26.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0037): time data \"2025-07-16 00:00:00.484\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 25601. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… sepira_ST1_202407.csv: ì™„ë£Œ (77,329í–‰, 16.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-14_BONGO3_2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 5.7% | ì„±ê³µ: 8 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 55.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m âœ… uk22da_IONIQ5 LONGRANGE 2022_202312.csv: ì™„ë£Œ (25,601í–‰, 17.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ“¦ dufdl1025_EV6 LONGRANGE_202404.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ“¦ revu-n-32_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ“¦ iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.0% | ì„±ê³µ: 9 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 17.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m âœ… pgtaxi-15_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (53,531í–‰, 26.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-18_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ğŸ“¦ ltgdg-14_BONGO3_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.3% | ì„±ê³µ: 10 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 46.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m âœ… cjl-dgds-006_PORTER2.csv: ì™„ë£Œ (59,767í–‰, 18.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ deeps7011_EV6 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: deeps7011_EV6 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 6.7% | ì„±ê³µ: 11 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 29.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m âœ… ltgdg-14_BONGO3_2022.csv: ì™„ë£Œ (67,301í–‰, 14.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ğŸ“¦ man8243_IONIQ5 LONGRANGE_202204.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: man8243_IONIQ5 LONGRANGE_202204.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.0% | ì„±ê³µ: 12 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 11.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m âœ… sihehe_NIRO2_202207.csv: ì™„ë£Œ (14,340í–‰, 6.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0010): time data \"2025-07-16 00:00:00.248\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.3% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 9 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 11.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-8_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 7.7% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 10 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 47.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jct4589_SOUL LONGRANGE_201903.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84202)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.0% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 11 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 26.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.3% | ì„±ê³µ: 13 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 5.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sosanamu_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 8.7% | ì„±ê³µ: 14 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 6.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ğŸ“¦ jct4589_SOUL LONGRANGE_201903.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… iamme77_IONIQ5 LONGRANGE 2022_202310.csv: ì™„ë£Œ (39,525í–‰, 24.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.0% | ì„±ê³µ: 15 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 51.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m âœ… jdisky_IONIQ5 LONGRANGE_202112.csv: ì™„ë£Œ (38,572í–‰, 31.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m âœ… jct4589_SOUL LONGRANGE_201903.csv: ì™„ë£Œ (1,682í–‰, 2.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ“¦ sosanamu_NIRO LONGRANGE_201902.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m ğŸ“¦ junghun1155_EV6 LONGRANGE_202302.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0058): time data \"2025-07-16 07:40:10.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: stock_EV9_202307.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83923)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ“¦ stock_EV9_202307.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ“¦ jog5064_EV6 LONGRANGE_202307.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.3% | ì„±ê³µ: 16 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 40.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m âœ… man8243_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (34,473í–‰, 23.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 9.7% | ì„±ê³µ: 17 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 32.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.0% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 12 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m âœ… sosanamu_NIRO LONGRANGE_201902.csv: ì™„ë£Œ (42,717í–‰, 17.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ableautos_EV6 LONGRANGE_202206.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.3% | ì„±ê³µ: 18 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 59.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 10.7% | ì„±ê³µ: 19 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 43.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m âœ… revu-n-32_EV6 LONGRANGE.csv: ì™„ë£Œ (43,133í–‰, 40.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.0% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 13 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 29.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.3% | ì„±ê³µ: 20 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 13.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ“¦ j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ ableautos_EV6 LONGRANGE_202206.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m âœ… ltgdg-18_PORTER2_2023.csv: ì™„ë£Œ (94,032í–‰, 34.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 11.7% | ì„±ê³µ: 21 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 19.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84204)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hoya3838_IONIQ 2019_201807.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ“¦ jinsu7426_EV6 LONGRANGE_202407.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AL0000): time data \"2025-07-16 07:30:40.451\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10776. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m âœ… junghun1155_EV6 LONGRANGE_202302.csv: ì™„ë£Œ (10,776í–‰, 19.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ğŸ“¦ cjl-dgea-016_PORTER2.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84342)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pmkp37_IONIQ5 LONGRANGE 2022_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m ğŸ“¦ pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m ğŸ“¦ hoya3838_IONIQ 2019_201807.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V020BH0001): time data \"2025-07-16 09:01:45.580\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13118. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.0% | ì„±ê³µ: 22 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 49.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m âœ… hoya3838_IONIQ 2019_201807.csv: ì™„ë£Œ (13,118í–‰, 8.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.3% | ì„±ê³µ: 23 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 39.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 12.7% | ì„±ê³µ: 24 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 22.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m âœ… j227_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202311.csv: ì™„ë£Œ (26,953í–‰, 19.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-19_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83928)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.0% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 14 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.3% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 15 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 4.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 13.7% | ì„±ê³µ: 25 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 50.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84335)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ğŸ“¦ cjl-dgss-015_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BI0001): time data \"2025-07-16 00:06:47.085\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… stock_EV9_202307.csv: ì™„ë£Œ (49,322í–‰, 34.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-013_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.0% | ì„±ê³µ: 26 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 41.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ“¦ cjl-dgss-013_PORTER2.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BJ0000): time data \"2025-07-16 00:00:00.136\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m âœ… jinsu7426_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (36,324í–‰, 32.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m âœ… dufdl1025_EV6 LONGRANGE_202404.csv: ì™„ë£Œ (132,857í–‰, 1ë¶„ 24.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.3% | ì„±ê³µ: 27 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 34.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 14.7% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 16 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 23.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.0% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 17 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 9.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmmath_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.3% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 18 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 5.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 15.7% | ì„±ê³µ: 28 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 52.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ“¦ revu-n-23_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84534)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ jmmath_IONIQ5 LONGRANGE_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… ableautos_EV6 LONGRANGE_202206.csv: ì™„ë£Œ (37,944í–‰, 34.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.0% | ì„±ê³µ: 29 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 18.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m âœ… cjl-dgea-016_PORTER2.csv: ì™„ë£Œ (138,978í–‰, 43.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.3% | ì„±ê³µ: 30 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 5.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m âœ… revu-n-23_EV6 LONGRANGE.csv: ì™„ë£Œ (12,353í–‰, 7.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ğŸ“¦ lotteglogis-dg-2_BONGO3.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ha8519_EV9_202401.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 16.7% | ì„±ê³µ: 31 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 21.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12353. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ğŸ“¦ ha8519_EV9_202401.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: naeibbo_BONGO3_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m âœ… pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: ì™„ë£Œ (39,332í–‰, 37.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mailhera_PORTER2_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ğŸ“¦ naeibbo_BONGO3_202406.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BI0003): time data \"2025-07-16 02:32:32.953\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17090. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m âœ… ha8519_EV9_202401.csv: ì™„ë£Œ (17,090í–‰, 10.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.0% | ì„±ê³µ: 32 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 31.3ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.3% | ì„±ê³µ: 33 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 20.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluesky8571_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 17.7% | ì„±ê³µ: 34 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 16.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.0% | ì„±ê³µ: 35 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 6.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.3% | ì„±ê³µ: 36 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: test01_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ“¦ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BD0000): time data \"2025-07-16 04:53:27.276\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24622. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… jmmath_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (24,622í–‰, 24.8ì´ˆ)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m ğŸ“¦ mailhera_PORTER2_202307.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 18.7% | ì„±ê³µ: 37 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 54.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: polarbar_IONIQ6 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0069): time data \"2025-07-16 07:20:25.466\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13393. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m âœ… lotteglogis-dg-2_BONGO3.csv: ì™„ë£Œ (74,821í–‰, 23.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ test01_IONIQ5 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.0% | ì„±ê³µ: 38 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 5.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m âœ… s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: ì™„ë£Œ (13,393í–‰, 7.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.3% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 19 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 9ë¶„ 3.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… bluesky8571_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (44,135í–‰, 12.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 19.7% | ì„±ê³µ: 39 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 52.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-15_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12347. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.0% | ì„±ê³µ: 40 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 50.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: babaliian_ST1_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0059): time data \"2025-07-16 00:00:09.733\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ğŸ“¦ test01_NIRO PLUS_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ“¦ revu-n-15_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.3% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 20 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 47.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V013BL0000): time data \"2025-07-17 15:18:16.078\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 16584. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 20.7% | ì„±ê³µ: 41 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 38.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84798)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m âœ… polarbar_IONIQ6 LONGRANGE_202207.csv: ì™„ë£Œ (16,584í–‰, 8.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ty3951_EV6 LONGRANGE_202408.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ğŸ“¦ babaliian_ST1_202407.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0019): time data \"2025-07-16 11:38:27.141\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.0% | ì„±ê³µ: 42 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 47.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0025): time data \"2025-07-16 00:02:13.084\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.3% | ì„±ê³µ: 43 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 42.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 21.7% | ì„±ê³µ: 44 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 32.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ“¦ ty3951_EV6 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.0% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 21 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 33.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m âœ… test01_NIRO PLUS_202201.csv: ì™„ë£Œ (36,221í–‰, 11.3ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m âœ… revu-n-15_EV6 LONGRANGE.csv: ì™„ë£Œ (19,309í–‰, 12.5ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.3% | ì„±ê³µ: 45 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 24.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgyc-4_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dibidib_EV9_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V021BJ0001): time data \"2025-07-16 00:00:02.685\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ“¦ ddtaxi-1_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 22.7% | ì„±ê³µ: 46 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 24.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.0% | ì„±ê³µ: 47 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 19.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… test01_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (47,372í–‰, 27.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-23_BONGO3_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.3% | ì„±ê³µ: 48 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 14.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ“¦ relier_NIRO2_202207.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ğŸ“¦ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0076): time data \"2025-07-16 00:00:03.051\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 8650. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m âœ… babaliian_ST1_202407.csv: ì™„ë£Œ (8,650í–‰, 17.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-16_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84899)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ“¦ dibidib_EV9_202407.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ“¦ esm3100_BONGO3_202304.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0070): time data \"2025-07-16 22:11:44.444\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 23.7% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 22 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 51.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m âœ… ty3951_EV6 LONGRANGE_202408.csv: ì™„ë£Œ (40,203í–‰, 27.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wwweee_BONGO3_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.0% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 23 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 51.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: leejh824_GV70_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.3% | ì„±ê³µ: 49 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 41.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ğŸ“¦ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 24.7% | ì„±ê³µ: 50 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 53.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m âœ… ltgdg-23_BONGO3_2023.csv: ì™„ë£Œ (88,326í–‰, 28.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.0% | ì„±ê³µ: 51 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 44.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.3% | ì„±ê³µ: 52 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 35.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 25.7% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 24 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 26.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.0% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 25 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 17.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.3% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 26 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 9.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84848)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 26.7% | ì„±ê³µ: 53 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 2.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-70_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ“¦ lee1174_EV6 LONGRANGE_202312.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ“¦ revu-n-70_KONA LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85058)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m âœ… ddtaxi-1_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (63,688í–‰, 39.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-25_IONIQ 2019_201701.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.0% | ì„±ê³µ: 54 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 12.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ ltgdg-13_PORTER2_2024.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.3% | ì„±ê³µ: 55 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8ë¶„ 5.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 27.7% | ì„±ê³µ: 56 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 57.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m âœ… kyh108_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (45,237í–‰, 31.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ğŸ“¦ revu-n-41_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.0% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 27 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 57.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.3% | ì„±ê³µ: 57 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 50.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0089): time data \"2025-07-16 05:32:26.702\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m âœ… esm3100_BONGO3_202304.csv: ì™„ë£Œ (95,221í–‰, 28.6ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kimdajo_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ“¦ dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m âœ… revu-n-70_KONA LONGRANGE.csv: ì™„ë£Œ (37,620í–‰, 15.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 28.7% | ì„±ê³µ: 58 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 53.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BH0000): time data \"2025-07-16 02:56:13.968\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m âœ… sinwootaxi-1_IONIQ5 STANDARD_202110.csv: ì™„ë£Œ (58,787í–‰, 27.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-28_BONGO3_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ğŸ“¦ lotteglogis-dg-28_BONGO3_202309.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.0% | ì„±ê³µ: 59 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 59.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.3% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 28 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 52.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… ltgdg-13_PORTER2_2024.csv: ì™„ë£Œ (80,230í–‰, 21.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-gbyc-013_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgwe-001_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 29.7% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 29 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 46.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.0% | ì„±ê³µ: 60 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 39.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.3% | ì„±ê³µ: 61 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 32.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 30.7% | ì„±ê³µ: 62 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 26.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m âœ… revu-n-41_EV6 LONGRANGE.csv: ì™„ë£Œ (15,634í–‰, 18.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ“¦ kimdajo_EV6 LONGRANGE_202210.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.0% | ì„±ê³µ: 63 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 25.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ revu-n-20_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15634. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m âœ… lotteglogis-dg-28_BONGO3_202309.csv: ì™„ë£Œ (14,188í–‰, 9.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: 628dani_CASPER LONGRANGE_202410.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ğŸ“¦ 48625ff_EV6 LONGRANGE_202210.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.3% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 30 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 30.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: azking_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 31.7% | ì„±ê³µ: 64 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m ğŸ“¦ azking_IONIQ5 LONGRANGE 2022_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0016): time data \"2025-07-16 00:36:24.196\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26858. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.0% | ì„±ê³µ: 65 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m âœ… dnwjdals1_IONIQ5 LONGRANGE_202107.csv: ì™„ë£Œ (26,858í–‰, 19.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kimzizone2_IONIQ5 LONGRANGE_202203.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m âœ… 628dani_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (15,485í–‰, 11.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.3% | ì„±ê³µ: 66 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 24.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ“¦ korea1736_IONIQ5 LONGRANGE_202203.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m âœ… azking_IONIQ5 LONGRANGE 2022_202207.csv: ì™„ë£Œ (8,729í–‰, 7.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m ğŸ“¦ kimzizone2_IONIQ5 LONGRANGE_202203.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 32.7% | ì„±ê³µ: 67 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 18.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m âœ… kung417s_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (42,750í–‰, 29.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ“¦ pgtaxi-5_NIRO LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.0% | ì„±ê³µ: 68 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 30.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… revu-n-20_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (45,130í–‰, 25.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.3% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 31 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 32.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85314)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-8_GV70.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28335. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m âœ… pgtaxi-5_NIRO LONGRANGE.csv: ì™„ë£Œ (28,335í–‰, 10.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 33.7% | ì„±ê³µ: 69 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 28.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ“¦ pgtaxi-4_IONIQ6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0038): time data \"2025-07-16 00:00:06.904\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m âœ… lijingice007_ST1_202411.csv: ì™„ë£Œ (62,311í–‰, 34.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.0% | ì„±ê³µ: 70 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 28.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ“¦ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 5ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bjgjw2579_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ bjgjw2579_EV6 LONGRANGE_202109.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.3% | ì„±ê³µ: 71 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 26.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 34.7% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 32 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 20.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.0% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 33 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 14.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.3% | ì„±ê³µ: 72 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 8.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0007): time data \"2025-07-16 00:07:43.773\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m âœ… kimdajo_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (90,937í–‰, 47.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 35.7% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 34 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 6.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: woojoov_CASPER LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.0% | ì„±ê³µ: 73 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 0.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ“¦ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-12_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m âœ… korea1736_IONIQ5 LONGRANGE_202203.csv: ì™„ë£Œ (38,001í–‰, 30.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ğŸ“¦ ltgdg-12_PORTER2.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.3% | ì„±ê³µ: 74 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 13.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m âœ… 48625ff_EV6 LONGRANGE_202210.csv: ì™„ë£Œ (79,907í–‰, 50.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 36.7% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 35 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 7.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85535)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ“¦ sitestev6_EV6 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.0% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 36 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 6.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.3% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 37 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 0.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 37.7% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 38 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 54.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: day9672_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ğŸ“¦ wildseven_SOUL LONGRANGE_201906.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.0% | ì„±ê³µ: 75 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 49.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: clausewitx_GV70_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m âœ… wildseven_SOUL LONGRANGE_201906.csv: ì™„ë£Œ (13,040í–‰, 4.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0027): time data \"2025-07-16 07:39:24.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13040. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… bjgjw2579_EV6 LONGRANGE_202109.csv: ì™„ë£Œ (38,446í–‰, 20.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.3% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 39 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 49.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 38.7% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 40 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 43.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ clausewitx_GV70_202210.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-24_BONGO3_2022.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.0% | ì„±ê³µ: 76 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 45.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ğŸ“¦ ltgdg-24_BONGO3_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85616)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m âœ… kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (127,935í–‰, 53.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.3% | ì„±ê³µ: 77 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 52.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mkj2449_IONIQ5 LONGRANGE_202110.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 39.7% | ì„±ê³µ: 78 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 47.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m âœ… ltgdg-24_BONGO3_2022.csv: ì™„ë£Œ (62,736í–‰, 13.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ğŸ“¦ junhyuk0413_NIRO2_202209.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m âœ… pgtaxi-4_IONIQ6 LONGRANGE.csv: ì™„ë£Œ (14,337í–‰, 42.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.0% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 41 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 45.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.3% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 42 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 40.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 40.7% | ì„±ê³µ: 79 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 35.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.0% | ì„±ê³µ: 80 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 30.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0063): time data \"2025-07-16 03:44:01.670\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29473. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: aim21c_NIRO LONGRANGE_201801.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.3% | ì„±ê³µ: 81 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 26.9ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85691)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… clausewitx_GV70_202210.csv: ì™„ë£Œ (29,473í–‰, 21.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ğŸ“¦ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ğŸ“¦ aim21c_NIRO LONGRANGE_201801.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 41.7% | ì„±ê³µ: 82 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 27.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85692)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0029): time data \"2025-07-16 06:03:10.847\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10476. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hahakuhyun_EV6 LONGRANGE_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m âœ… junhyuk0413_NIRO2_202209.csv: ì™„ë£Œ (10,476í–‰, 8.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ“¦ cjl-gbyc-016_BONGO3.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15242. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m âœ… mkj2449_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (15,242í–‰, 14.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.0% | ì„±ê³µ: 83 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 28.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ jinjinjw_IONIQ5 LONGRANGE_202202.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.3% | ì„±ê³µ: 84 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 23.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m âœ… sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: ì™„ë£Œ (73,116í–‰, 47.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 42.7% | ì„±ê³µ: 85 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 20.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.0% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 43 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 17.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 18842. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m âœ… jinjinjw_IONIQ5 LONGRANGE_202202.csv: ì™„ë£Œ (4,906í–‰, 3.8ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ“¦ hahakuhyun_EV6 LONGRANGE_202401.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.3% | ì„±ê³µ: 86 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 17.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ“¦ ltgdg-32_PORTER2_2023.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kate3070kr_GV70_202107.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 43.7% | ì„±ê³µ: 87 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 15.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0027): time data \"2025-07-16 03:20:48.641\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m âœ… joiltaxi-21_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (101,245í–‰, 59.4ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.0% | ì„±ê³µ: 88 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 13.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.3% | ì„±ê³µ: 89 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 8.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85691)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ğŸ“¦ kate3070kr_GV70_202107.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 44.7% | ì„±ê³µ: 90 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 8.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: printo2000_PORTER2_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: c1228kr_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: delpainus_IONIQ5 LONGRANGE 2022_202307.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.0% | ì„±ê³µ: 91 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 4.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.3% | ì„±ê³µ: 92 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 60.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m âœ… whote564_IONIQ5 LONGRANGE 2022_202311.csv: ì™„ë£Œ (28,877í–‰, 27.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ“¦ delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0095): time data \"2025-07-16 08:14:02.568\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28877. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m âœ… printo2000_PORTER2_202210.csv: ì™„ë£Œ (12,501í–‰, 6.9ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ“¦ pgtaxi-16_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85851)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wer007_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ“¦ tsiyhj_EV6 LONGRANGE_202407.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m ğŸ“¦ wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 45.7% | ì„±ê³µ: 93 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 2.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m âœ… ltgdg-32_PORTER2_2023.csv: ì™„ë£Œ (90,094í–‰, 22.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85922)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ehman486_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ“¦ c1228kr_IONIQ5 LONGRANGE_202201.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… delpainus_IONIQ5 LONGRANGE 2022_202307.csv: ì™„ë£Œ (14,450í–‰, 10.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.0% | ì„±ê³µ: 94 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 1.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ“¦ ehman486_EV3 LONGRANGE_202408.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ“¦ revu-n-64_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0022): time data \"2025-07-16 09:00:54.200\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 14450. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: rwww87_EV6 LONGRANGE_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.3% | ì„±ê³µ: 95 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 4.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BI0001): time data \"2025-07-16 06:42:06.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21690. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m âœ… tsiyhj_EV6 LONGRANGE_202407.csv: ì™„ë£Œ (21,690í–‰, 16.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 46.7% | ì„±ê³µ: 96 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 2.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m âœ… pgtaxi-16_EV6 LONGRANGE.csv: ì™„ë£Œ (34,543í–‰, 21.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: xlos20_EV6 LONGRANGE_202101.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ“¦ rwww87_EV6 LONGRANGE_202311.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.0% | ì„±ê³µ: 97 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 58.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.3% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 44 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 53.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 47.7% | ì„±ê³µ: 98 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 51.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0001): time data \"2025-07-16 00:52:26.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m âœ… ehman486_EV3 LONGRANGE_202408.csv: ì™„ë£Œ (26,078í–‰, 11.0ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ“¦ sl-ev-1_EV6 LONGRANGE_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0039): time data \"2025-07-16 00:00:01.556\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.0% | ì„±ê³µ: 99 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 54.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m âœ… ocs7777_ST1_202407.csv: ì™„ë£Œ (49,291í–‰, 38.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.3% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 45 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 50.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… revu-n-64_EV6 LONGRANGE.csv: ì™„ë£Œ (23,987í–‰, 19.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: legojeon_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 48.7% | ì„±ê³µ: 100 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 45.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m âœ… wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: ì™„ë£Œ (36,497í–‰, 27.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.0% | ì„±ê³µ: 101 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 41.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.3% | ì„±ê³µ: 102 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 38.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ“¦ revu-n-63_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-34_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ğŸ“¦ revu-n-11_KONA LONGRANGE_202104.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0084): time data \"2025-07-16 00:00:00.608\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m âœ… c1228kr_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (61,141í–‰, 32.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85692)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 49.7% | ì„±ê³µ: 103 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: airme_EV6 LONGRANGE_202403.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0006): time data \"2025-07-16 08:00:25.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29483. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m âœ… rwww87_EV6 LONGRANGE_202311.csv: ì™„ë£Œ (29,483í–‰, 24.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ğŸ“¦ airme_EV6 LONGRANGE_202403.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.0% | ì„±ê³µ: 104 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 42.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-34_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m âœ… xlos20_EV6 LONGRANGE_202101.csv: ì™„ë£Œ (31,384í–‰, 25.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ cjl-dgds-011_PORTER2.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… ltgyc-3_PORTER2.csv: ì™„ë£Œ (50,124í–‰, 17.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.3% | ì„±ê³µ: 105 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 40.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 50.7% | ì„±ê³µ: 106 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 36.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-22_BONGO3_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ğŸ“¦ lotteglogis-dg-34_PORTER2_202301.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.0% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 46 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 34.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85922)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.3% | ì„±ê³µ: 107 | ì‹¤íŒ¨: 47 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 30.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 51.7% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 47 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 27.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.0% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 48 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 23.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m âœ… revu-n-11_KONA LONGRANGE_202104.csv: ì™„ë£Œ (85,233í–‰, 22.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.3% | ì„±ê³µ: 108 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 19.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: maxcom3_EV9_202312.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 52.7% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 49 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 15.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.0% | ì„±ê³µ: 109 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 11.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… revu-n-63_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (41,976í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ“¦ leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ğŸ“¦ ltgdg-22_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ğŸ“¦ dmcdimo_EV6 LONGRANGE_202211.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.3% | ì„±ê³µ: 110 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 9.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86199)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 53.7% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 50 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 7.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.0% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 51 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 3.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.3% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 52 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 59.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 54.7% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 53 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 55.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.0% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 54 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 51.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… cjl-dgds-011_PORTER2.csv: ì™„ë£Œ (62,235í–‰, 21.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ğŸ“¦ parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ“¦ needman_EV6 LONGRANGE_202403.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.3% | ì„±ê³µ: 111 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 50.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86199)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15280. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: s112661140_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… revu-n-25_NIRO2_202401.csv: ì™„ë£Œ (15,280í–‰, 7.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0010): time data \"2025-07-16 19:24:24.666\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 55.7% | ì„±ê³µ: 112 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 49.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: helleus77_EV6 STANDARD_202108.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.0% | ì„±ê³µ: 113 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 46.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ“¦ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86000)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ helleus77_EV6 STANDARD_202108.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.3% | ì„±ê³µ: 114 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 44.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 56.7% | ì„±ê³µ: 115 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m âœ… ltgdg-22_BONGO3_2023.csv: ì™„ë£Œ (89,775í–‰, 21.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0032): time data \"2025-07-16 00:24:45.845\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (31,434í–‰, 19.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ“¦ lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ğŸ“¦ wce4122_EV6 LONGRANGE_202110.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wce4122_EV6 LONGRANGE_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0005): time data \"2025-07-16 00:42:28.778\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 27301. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.0% | ì„±ê³µ: 116 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 42.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m âœ… dmcdimo_EV6 LONGRANGE_202211.csv: ì™„ë£Œ (27,301í–‰, 24.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hmp4522_EV3 LONGRANGE_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.3% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 55 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 41.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 57.7% | ì„±ê³µ: 117 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 38.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.0% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 56 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 34.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.3% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 57 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 30.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 58.7% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 58 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 27.2ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.0% | ì„±ê³µ: 118 | ì‹¤íŒ¨: 59 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 23.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ“¦ revu-n-18_BONGO3.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26770. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… helleus77_EV6 STANDARD_202108.csv: ì™„ë£Œ (26,770í–‰, 15.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: sunghyun_BONGO3_202412.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.3% | ì„±ê³µ: 119 | ì‹¤íŒ¨: 59 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 21.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m âœ… parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (56,504í–‰, 30.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 59.7% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 59 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 20.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.0% | ì„±ê³µ: 120 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 16.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ sunghyun_BONGO3_202412.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0013): time data \"2025-07-16 08:14:23.270\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… cjl-dgss-012_PORTER2.csv: ì™„ë£Œ (49,002í–‰, 16.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86351)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-22_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.3% | ì„±ê³µ: 121 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 15.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m âœ… yousjun_IONIQ5 LONGRANGE 2022_202302.csv: ì™„ë£Œ (52,329í–‰, 28.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 60.7% | ì„±ê³µ: 122 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 12.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m âœ… revu-n-18_BONGO3.csv: ì™„ë£Œ (8,174í–‰, 10.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86351)\u001b[0m ğŸ“¦ lotteglogis-dg-22_PORTER2_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0067): time data \"2025-07-16 02:37:56.272\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.0% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 60 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 9.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: ì™„ë£Œ (35,649í–‰, 25.3ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ğŸ“¦ jmjang2_ST1_202405.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.3% | ì„±ê³µ: 123 | ì‹¤íŒ¨: 61 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 6.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 61.7% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 61 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 4.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.0% | ì„±ê³µ: 124 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4ë¶„ 0.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ“¦ reviewshare-4_KONA LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: mamon_ST1_202408.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m âœ… wce4122_EV6 LONGRANGE_202110.csv: ì™„ë£Œ (47,855í–‰, 23.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0085): time data \"2025-07-16 00:00:00.667\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ“¦ revu-n-66_EV6 LONGRANGE_202304.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.3% | ì„±ê³µ: 125 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 59.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m âœ… hmp4522_EV3 LONGRANGE_202502.csv: ì™„ë£Œ (49,566í–‰, 21.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… reviewshare-4_KONA LONGRANGE.csv: ì™„ë£Œ (15,031í–‰, 6.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 62.7% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 62 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 57.1ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86186)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: junsuck86_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hwa9183_EV3 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.0% | ì„±ê³µ: 126 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 54.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: win7102_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.3% | ì„±ê³µ: 127 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 50.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 63.7% | ì„±ê³µ: 128 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 47.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ“¦ giugi_EV6 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24784. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ğŸ“¦ win7102_EV3 LONGRANGE_202503.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m âœ… parksw7022_IONIQ6 STANDARD_202502.csv: ì™„ë£Œ (24,784í–‰, 11.7ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.0% | ì„±ê³µ: 129 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 46.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: go051s_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: zoh71z_KONA LONGRANGE_201810.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0034): time data \"2025-07-16 00:00:03.402\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ“¦ zoh71z_KONA LONGRANGE_201810.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.3% | ì„±ê³µ: 130 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 47.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m âœ… jmjang2_ST1_202405.csv: ì™„ë£Œ (65,327í–‰, 24.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 64.7% | ì„±ê³µ: 131 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 44.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: nukesub_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0027): time data \"2025-07-16 12:44:07.662\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21534. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bbotti_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.0% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 63 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 42.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.3% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 64 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 38.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m âœ… giugi_EV6 LONGRANGE.csv: ì™„ë£Œ (16,342í–‰, 13.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgno-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 65.7% | ì„±ê³µ: 132 | ì‹¤íŒ¨: 65 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 35.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldw8482_EV6 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ“¦ bbotti_IONIQ5 LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ğŸ“¦ nukesub_EV3 LONGRANGE_202504.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… junsuck86_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (21,534í–‰, 12.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.0% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 65 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 33.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m âœ… revu-n-66_EV6 LONGRANGE_202304.csv: ì™„ë£Œ (37,526í–‰, 24.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.3% | ì„±ê³µ: 133 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 30.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 66.7% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 66 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 27.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.0% | ì„±ê³µ: 134 | ì‹¤íŒ¨: 67 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 24.6ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86537)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0017): time data \"2025-07-16 00:12:44.626\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.3% | ì„±ê³µ: 135 | ì‹¤íŒ¨: 67 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 21.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ğŸ“¦ ldw8482_EV6 LONGRANGE_202204.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 67.7% | ì„±ê³µ: 136 | ì‹¤íŒ¨: 67 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 19.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: fojokr_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ğŸ“¦ fojokr_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.0% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 67 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 16.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.3% | ì„±ê³µ: 137 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 13.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hmc1006_ST1_202504.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vunyvuny2_SOUL LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 68.7% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 68 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 10.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.0% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 69 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 7.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.3% | ì„±ê³µ: 138 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 5.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ“¦ vunyvuny2_SOUL LONGRANGE.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m âœ… nukesub_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (10,232í–‰, 8.4ì´ˆ)\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86564)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0014): time data \"2025-07-16 10:41:47.477\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10232. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ğŸ“¦ heo3252_KONA LONGRANGE_201901.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lee5957_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 69.7% | ì„±ê³µ: 139 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 5.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ“¦ lee5957_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0029): time data \"2025-07-16 01:07:52.143\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9499. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m âœ… fojokr_CASPER LONGRANGE_202410.csv: ì™„ë£Œ (9,499í–‰, 10.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.0% | ì„±ê³µ: 140 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 3.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.3% | ì„±ê³µ: 141 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 0.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m âœ… mxri13_GV60_202307.csv: ì™„ë£Œ (19,982í–‰, 12.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86469)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 70.7% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 70 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 57.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.0% | ì„±ê³µ: 142 | ì‹¤íŒ¨: 71 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 54.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m âœ… vunyvuny2_SOUL LONGRANGE.csv: ì™„ë£Œ (17,652í–‰, 9.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ğŸ“¦ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: juhwan7455_EV3 LONGRANGE_202407.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0034): time data \"2025-07-16 08:22:40.033\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m âœ… emob-2_IONIQ 2019.csv: ì™„ë£Œ (26,301í–‰, 8.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.3% | ì„±ê³µ: 143 | ì‹¤íŒ¨: 71 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 53.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m âœ… ldw8482_EV6 LONGRANGE_202204.csv: ì™„ë£Œ (37,779í–‰, 20.0ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86277)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 71.7% | ì„±ê³µ: 144 | ì‹¤íŒ¨: 71 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 52.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.0% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 71 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 49.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… bbotti_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (24,633í–‰, 24.6ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.3% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 72 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 46.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 72.7% | ì„±ê³µ: 145 | ì‹¤íŒ¨: 73 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 43.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.0% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 73 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 41.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.3% | ì„±ê³µ: 146 | ì‹¤íŒ¨: 74 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 38.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m âœ… heo3252_KONA LONGRANGE_201901.csv: ì™„ë£Œ (35,974í–‰, 15.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86694)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ğŸ“¦ revu-n-22_EV6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m âœ… lee5957_IONIQ5 LONGRANGE.csv: ì™„ë£Œ (38,821í–‰, 22.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 73.7% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 74 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 38.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.0% | ì„±ê³µ: 147 | ì‹¤íŒ¨: 75 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 35.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ğŸ“¦ ltgdg-1_BONGO3_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-4_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86695)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CE0018): time data \"2025-07-16 15:53:51.106\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m âœ… juhwan7455_EV3 LONGRANGE_202407.csv: ì™„ë£Œ (64,329í–‰, 21.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ“¦ eha031_PORTER2_202211.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: eha031_PORTER2_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.3% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 75 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 35.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-3_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 74.7% | ì„±ê³µ: 148 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 32.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: tlsqjatjq628_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.0% | ì„±ê³µ: 149 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 30.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m âœ… ltgdg-1_BONGO3_2023.csv: ì™„ë£Œ (73,566í–‰, 16.4ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ğŸ“¦ tlsqjatjq628_EV3 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-26_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.3% | ì„±ê³µ: 150 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 29.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m âœ… 1357rqwe_IONIQ5 LONGRANGE_202207.csv: ì™„ë£Œ (36,613í–‰, 27.9ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 75.7% | ì„±ê³µ: 151 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 26.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.0% | ì„±ê³µ: 152 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 24.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ revu-n-69_EV6 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m âœ… eha031_PORTER2_202211.csv: ì™„ë£Œ (36,731í–‰, 14.9ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m ğŸ“¦ joiltaxi-26_EV6 LONGRANGE_202201.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ğŸ“¦ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: myhkk1797_EV3 LONGRANGE_202402.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0081): time data \"2025-07-16 02:51:49.699\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.3% | ì„±ê³µ: 153 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 25.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m âœ… tlsqjatjq628_EV3 LONGRANGE_202408.csv: ì™„ë£Œ (57,177í–‰, 19.2ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 76.7% | ì„±ê³µ: 154 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 22.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m ğŸ“¦ lotteglogis-dg-31_PORTER2_202401.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-31_PORTER2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m âœ… kepco-1_IONIQ5 LONGRANGE_202110.csv: ì™„ë£Œ (40,668í–‰, 27.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0035): time data \"2025-07-16 00:00:02.003\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.0% | ì„±ê³µ: 155 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 23.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m âœ… ddongkolip_ST1_202405.csv: ì™„ë£Œ (107,571í–‰, 52.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wjs4156_EV3 STANDARD_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m ğŸ“¦ myhkk1797_EV3 LONGRANGE_202402.csv: 6ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.3% | ì„±ê³µ: 156 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 21.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… revu-n-69_EV6 LONGRANGE.csv: ì™„ë£Œ (34,991í–‰, 26.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ“¦ wjs4156_EV3 STANDARD_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ğŸ“¦ ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BH0001): time data \"2025-07-16 07:04:21.113\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-33_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 77.7% | ì„±ê³µ: 157 | ì‹¤íŒ¨: 76 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 20.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m âœ… revu-n-22_EV6 LONGRANGE.csv: ì™„ë£Œ (68,474í–‰, 51.7ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ“¦ ltgdg-33_PORTER2_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86970)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ehdghans1_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.0% | ì„±ê³µ: 157 | ì‹¤íŒ¨: 77 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 19.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ky80901_ST1_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m âœ… lotteglogis-dg-31_PORTER2_202401.csv: ì™„ë£Œ (63,974í–‰, 25.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.3% | ì„±ê³µ: 158 | ì‹¤íŒ¨: 77 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 16.8ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 78.7% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 77 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 14.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m âœ… jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: ì™„ë£Œ (38,182í–‰, 36.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87015)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.0% | ì„±ê³µ: 159 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 11.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.3% | ì„±ê³µ: 160 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 9.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 79.7% | ì„±ê³µ: 161 | ì‹¤íŒ¨: 78 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 7.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: dlcksgh3595_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ddtaxi-5_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.0% | ì„±ê³µ: 161 | ì‹¤íŒ¨: 79 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 4.6ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.3% | ì„±ê³µ: 162 | ì‹¤íŒ¨: 79 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 2.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… revu-n-38_IONIQ5 LONGRANGE 2022.csv: ì™„ë£Œ (17,052í–‰, 11.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ignatius9107_IONIQ5 N NE_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V022AK0000): time data \"2025-07-16 07:36:20.441\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m âœ… wjs4156_EV3 STANDARD_202502.csv: ì™„ë£Œ (36,161í–‰, 18.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 80.7% | ì„±ê³µ: 163 | ì‹¤íŒ¨: 79 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 59.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m ğŸ“¦ hophip5677_CASPER LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.0% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 79 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 57.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.3% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 80 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 55.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ ignatius9107_IONIQ5 N NE_202502.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kgs0002_EV6 LONGRANGE_202205.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m âœ… ssa1011_KONA LONGRANGE 2á„‰á…¦á„ƒá…¢_202301.csv: ì™„ë£Œ (52,995í–‰, 19.9ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m âœ… ltgdg-33_PORTER2_2023.csv: ì™„ë£Œ (54,002í–‰, 15.8ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ“¦ kgs0002_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltj1937_EV3 LONGRANGE_202412.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 81.7% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 81 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 54.8ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ“¦ ltgdg-5_PORTER2_2023.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.0% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 82 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 52.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.3% | ì„±ê³µ: 164 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 50.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m âœ… hophip5677_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (30,073í–‰, 17.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 82.7% | ì„±ê³µ: 165 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 48.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: adreamcar_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87139)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19707. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m ğŸ“¦ adreamcar_PORTER2_202301.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.0% | ì„±ê³µ: 166 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 46.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… ltgdg-5_PORTER2_2023.csv: ì™„ë£Œ (19,707í–‰, 10.5ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.3% | ì„±ê³µ: 167 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 44.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ“¦ hyisjung_NIRO LONGRANGE_201808.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m ğŸ“¦ ksjksj87_EV3 LONGRANGE_202409.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 83.7% | ì„±ê³µ: 168 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 42.7ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87293)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0094): time data \"2025-07-19 00:51:14.209\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m âœ… adreamcar_PORTER2_202301.csv: ì™„ë£Œ (40,718í–‰, 11.7ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… ignatius9107_IONIQ5 N NE_202502.csv: ì™„ë£Œ (37,884í–‰, 30.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.0% | ì„±ê³µ: 169 | ì‹¤íŒ¨: 83 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 40.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.3% | ì„±ê³µ: 169 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 38.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: jhs3101_PORTER2_202002.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 84.7% | ì„±ê³µ: 170 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 36.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.0% | ì„±ê³µ: 171 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 33.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… hyisjung_NIRO LONGRANGE_201808.csv: ì™„ë£Œ (9,951í–‰, 8.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ“¦ jhs3101_PORTER2_202002.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9951. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m âœ… revu-n-27_EV9.csv: ì™„ë£Œ (33,177í–‰, 26.0ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-3_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ“¦ ltgdg-3_PORTER2_2023.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0010): time data \"2025-07-16 06:49:12.111\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.3% | ì„±ê³µ: 172 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 33.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m âœ… kgs0002_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (41,563í–‰, 41.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 85.7% | ì„±ê³µ: 173 | ì‹¤íŒ¨: 84 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 31.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-6_PORTER2_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.0% | ì„±ê³µ: 173 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 28.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.3% | ì„±ê³µ: 174 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 26.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ“¦ revu-u-5_IONIQ5 LONGRANGE_202201.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87396)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m âœ… ddtaxi-5_EV6 LONGRANGE_202201.csv: ì™„ë£Œ (89,880í–‰, 47.1ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004BA0003): time data \"2025-07-16 00:00:00.749\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: vitadoice11_IONIQ5 LONGRANGE_202106.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0024): time data \"2025-07-16 00:59:23.925\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ“¦ vitadoice11_IONIQ5 LONGRANGE_202106.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 86.7% | ì„±ê³µ: 175 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 25.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.0% | ì„±ê³µ: 176 | ì‹¤íŒ¨: 85 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 23.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m âœ… ky80901_ST1_202406.csv: ì™„ë£Œ (103,991í–‰, 1ë¶„ 1.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m âœ… jhs3101_PORTER2_202002.csv: ì™„ë£Œ (31,122í–‰, 26.1ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-007_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.3% | ì„±ê³µ: 176 | ì‹¤íŒ¨: 86 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 20.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 87.7% | ì„±ê³µ: 176 | ì‹¤íŒ¨: 87 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 18.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ys062789_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: js5540810_IONIQ 2019_201607.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.0% | ì„±ê³µ: 177 | ì‹¤íŒ¨: 87 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 16.1ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.3% | ì„±ê³µ: 178 | ì‹¤íŒ¨: 87 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 13.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 88.7% | ì„±ê³µ: 179 | ì‹¤íŒ¨: 87 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 12.0ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0081): time data \"2025-07-16 00:08:12.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ğŸ“¦ js5540810_IONIQ 2019_201607.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m âœ… geni8895_BONGO3_202210.csv: ì™„ë£Œ (60,279í–‰, 29.3ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ntragic_EV6 LONGRANGE_202005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86969)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ğŸ“¦ ntragic_EV6 LONGRANGE_202005.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yaa7890_PORTER2_202003.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.0% | ì„±ê³µ: 179 | ì‹¤íŒ¨: 88 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 9.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.3% | ì„±ê³µ: 180 | ì‹¤íŒ¨: 88 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 7.4ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 89.7% | ì„±ê³µ: 181 | ì‹¤íŒ¨: 88 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 5.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.0% | ì„±ê³µ: 181 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 3.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86833)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… ltgdg-3_PORTER2_2023.csv: ì™„ë£Œ (79,420í–‰, 35.8ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ“¦ lotteglogis-dg-1_PORTER2_202306.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.3% | ì„±ê³µ: 182 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 1.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: ì™„ë£Œ (44,214í–‰, 41.7ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 90.7% | ì„±ê³µ: 183 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 59.0ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86924)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.0% | ì„±ê³µ: 184 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 56.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26291. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… lotteglogis-dg-1_PORTER2_202306.csv: ì™„ë£Œ (26,291í–‰, 8.2ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ğŸ“¦ lotteglogis-dg-10_PORTER2_202310.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: testev9_EV9_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ğŸ“¦ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 4ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.3% | ì„±ê³µ: 185 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 54.9ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ testev9_EV9_2023.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m âœ… ntragic_EV6 LONGRANGE_202005.csv: ì™„ë£Œ (33,787í–‰, 18.7ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87079)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=87654)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-7_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ğŸ“¦ cjawl74_PORTER2_202412.csv: 6ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0041): time data \"2025-07-16 00:00:00.124\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29233. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 91.7% | ì„±ê³µ: 186 | ì‹¤íŒ¨: 89 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 53.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m âœ… jsmtnaud_IONIQ5 LONGRANGE_202201.csv: ì™„ë£Œ (29,233í–‰, 27.1ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2853 MiB, 74 objects, write throughput 220 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(preprocess_batch_parallel pid=87653)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ğŸ“¦ lotteglogis-dg-7_PORTER2_202311.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: gildagray_EV3 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.0% | ì„±ê³µ: 186 | ì‹¤íŒ¨: 90 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 51.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.3% | ì„±ê³µ: 186 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 49.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: kor87_NIRO PLUS_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ“¦ kor87_NIRO PLUS_202207.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 92.7% | ì„±ê³µ: 187 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 47.3ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m âœ… testev9_EV9_2023.csv: ì™„ë£Œ (49,163í–‰, 22.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87739)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: emr4540_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ğŸ“¦ emr4540_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.0% | ì„±ê³µ: 188 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 45.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000BB0000): time data \"2025-07-16 00:25:46.182\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m âœ… lotteglogis-dg-10_PORTER2_202310.csv: ì™„ë£Œ (116,157í–‰, 35.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.3% | ì„±ê³µ: 189 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 43.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m âœ… koreataxi-1_IONIQ5 LONGRANGE_202204.csv: ì™„ë£Œ (90,471í–‰, 50.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 93.7% | ì„±ê³µ: 190 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 41.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.0% | ì„±ê³µ: 191 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 38.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ“¦ wntjdgml_CASPER LONGRANGE_202408.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: janko7_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ğŸ“¦ janko7_EV3 LONGRANGE_202504.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.3% | ì„±ê³µ: 192 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 36.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: taerok_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m âœ… lotteglogis-dg-7_PORTER2_202311.csv: ì™„ë£Œ (82,676í–‰, 22.5ì´ˆ)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ğŸ“¦ taerok_KONA LONGRANGE_202302.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87815)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: thdwlsdn000_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ğŸ“¦ lotteglogis-dg-8_PORTER2_202308.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ğŸ“¦ thdwlsdn000_CASPER LONGRANGE_202410.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CC0007): time data \"2025-07-16 00:00:02.643\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 94.7% | ì„±ê³µ: 193 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 34.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m âœ… cjawl74_PORTER2_202412.csv: ì™„ë£Œ (158,984í–‰, 43.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m ğŸ“¦ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.0% | ì„±ê³µ: 194 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 32.7ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m âœ… wntjdgml_CASPER LONGRANGE_202408.csv: ì™„ë£Œ (30,879í–‰, 15.9ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87653)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0008): time data \"2025-07-16 06:32:03.805\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0023): time data \"2025-07-16 01:32:19.376\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.3% | ì„±ê³µ: 195 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 30.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… cjosooo_ST1_202407.csv: ì™„ë£Œ (74,386í–‰, 49.0ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 95.7% | ì„±ê³µ: 196 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 28.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: musein_EV9_202404.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.0% | ì„±ê³µ: 197 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 26.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ğŸ“¦ beston_IONIQ6 LONGRANGE_202201.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m âœ… taerok_KONA LONGRANGE_202302.csv: ì™„ë£Œ (40,146í–‰, 18.1ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.3% | ì„±ê³µ: 198 | ì‹¤íŒ¨: 91 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 23.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 96.7% | ì„±ê³µ: 198 | ì‹¤íŒ¨: 92 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 21.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.0% | ì„±ê³µ: 198 | ì‹¤íŒ¨: 93 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 19.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CA0020): time data \"2025-07-16 01:00:11.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m âœ… janko7_EV3 LONGRANGE_202504.csv: ì™„ë£Œ (49,586í–‰, 22.5ì´ˆ)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87917)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ğŸ“¦ heinzel_EV6 LONGRANGE_202205.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.3% | ì„±ê³µ: 198 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 17.4ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87917)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ğŸ“¦ musein_EV9_202404.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 97.7% | ì„±ê³µ: 199 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 15.2ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m âœ… yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: ì™„ë£Œ (100,983í–‰, 1ë¶„ 12.2ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cody8406_IONIQ 2020_202007.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.0% | ì„±ê³µ: 200 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 13.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m âœ… lotteglogis-dg-8_PORTER2_202308.csv: ì™„ë£Œ (85,178í–‰, 36.8ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87563)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ğŸ“¦ side3150_IONIQ6 LONGRANGE_202312.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m âœ… bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: ì™„ë£Œ (48,937í–‰, 35.4ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.3% | ì„±ê³µ: 201 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 11.0ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 98.7% | ì„±ê³µ: 202 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 8.8ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m âœ… cody8406_IONIQ 2020_202007.csv: ì™„ë£Œ (22,273í–‰, 17.2ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.0% | ì„±ê³µ: 203 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6.6ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V019CA0000): time data \"2025-07-16 07:45:30.007\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 22273. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CB0096): time data \"2025-07-16 00:00:02.639\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m âœ… musein_EV9_202404.csv: ì™„ë£Œ (57,045í–‰, 27.5ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.3% | ì„±ê³µ: 204 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 4.4ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m âœ… beston_IONIQ6 LONGRANGE_202201.csv: ì™„ë£Œ (37,923í–‰, 33.8ì´ˆ)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 99.7% | ì„±ê³µ: 205 | ì‹¤íŒ¨: 94 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2.2ì´ˆ\n",
      "\n",
      "================================================================================\n",
      "ğŸ‰ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ!\n",
      "ğŸ“ˆ ì„±ê³µ: 206ê°œ | âŒ ì‹¤íŒ¨: 94ê°œ\n",
      "ğŸ“Š ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 9,670,662í–‰\n",
      "â±ï¸  ì´ ì†Œìš”ì‹œê°„: 10ë¶„ 58.4ì´ˆ\n",
      "âš¡ í‰ê·  íŒŒì¼ë‹¹: 2.2ì´ˆ\n",
      "\n",
      "âŒ ì‹¤íŒ¨í•œ íŒŒì¼ë“¤:\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "   - Unknown: ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\n",
      "   - ì´ ì²˜ë¦¬ ì‹œê°„: 10ë¶„ 58.4ì´ˆ\n",
      "   - íŒŒì¼ë‹¹ í‰ê· : 2.2ì´ˆ\n",
      "   - ì„±ê³µë¥ : 68.7%\n",
      "   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: 9,670,662í–‰\n",
      "   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: 52878566í–‰/ì‹œê°„\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V000CD0078): time data \"2025-07-16 05:34:57.584\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m âœ… heinzel_EV6 LONGRANGE_202205.csv: ì™„ë£Œ (35,736í–‰, 33.3ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86969)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 03:04:02,470\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Ray ì´ˆê¸°í™” ì™„ë£Œ (ì›Œì»¤ ìˆ˜: 8)\n",
      "ğŸ“ ì´ 240ê°œ íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘\n",
      "ğŸ“‚ ì¶œë ¥ ë””ë ‰í† ë¦¬: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "â³ ëª¨ë“  íŒŒì¼ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88141)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgss-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88137)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.4% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 1 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 32.5ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 0.8% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 2 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 3ë¶„ 22.3ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.2% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 3 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 2ë¶„ 14.9ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 1.7% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 4 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 42.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.1% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 5 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 23.7ì´ˆ\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.5% | ì„±ê³µ: 0 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 1ë¶„ 14.5ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m ğŸ“¦ ekfmd3152_KONA LONGRANGE_202004.csv: 1ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88136)\u001b[0m ğŸ“¦ emob-1_IONIQ5 LONGRANGE.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88155)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88141)\u001b[0m ğŸ“¦ revu-n-34_GV70.csv: 2ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24902. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88137)\u001b[0m ğŸ“¦ pgtaxi-15_IONIQ6 LONGRANGE.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 2.9% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 6 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 5ë¶„ 43.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m âœ… ekfmd3152_KONA LONGRANGE_202004.csv: ì™„ë£Œ (24,902í–‰, 8.6ì´ˆ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88187)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88140)\u001b[0m ğŸ“¦ dufdl1025_EV6 LONGRANGE_202404.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.3% | ì„±ê³µ: 1 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 23.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: ltgdg-14_BONGO3_2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m íŒŒì¼ ë³‘í•© ì¤‘ ì˜¤ë¥˜ (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12006. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 3.8% | ì„±ê³µ: 2 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 4.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m ì›”ë³„ ì €ì¥ ì¤‘ ì˜¤ë¥˜: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m âœ… cjl-dgds-006_PORTER2.csv: ì™„ë£Œ (12,006í–‰, 14.6ì´ˆ)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.2% | ì„±ê³µ: 3 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 6ë¶„ 28.2ì´ˆ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88134)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m ğŸ“¦ ltgdg-14_BONGO3_2022.csv: 3ê°œ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ, ê²°í•© ì¤‘...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88134)\u001b[0m ğŸ”„ ì²˜ë¦¬ ì‹œì‘: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m ğŸ“Š ì§„í–‰ë¥ : 4.6% | ì„±ê³µ: 4 | ì‹¤íŒ¨: 7 | ì˜ˆìƒ ë‚¨ì€ ì‹œê°„: 7ë¶„ 1.1ì´ˆ\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88155)\u001b[0m âœ… revu-n-68_EV6 LONGRANGE.csv: ì™„ë£Œ (18,800í–‰, 17.6ì´ˆ)\n"
     ]
    }
   ],
   "source": [
    "for folder in folder_list:\n",
    "    csv_files = glob.glob(f\"{folder}/**/*.csv\", recursive=True)\n",
    "    \n",
    "    \n",
    "    # ë³‘ë ¬ ì²˜ë¦¬ ì‹¤í–‰ (CPU ì½”ì–´ ìˆ˜ì˜ 80% ì‚¬ìš©)\n",
    "    results = process_multiple_files_parallel(\n",
    "        csv_files=csv_files,\n",
    "        output_dir=\"/Volumes/Data/betterwhy_processed\",\n",
    "        remove_duplicates=True,\n",
    "        max_workers=None  # Noneì´ë©´ ìë™ìœ¼ë¡œ CPU ì½”ì–´ ìˆ˜ì˜ 80% ì‚¬ìš©\n",
    "    )\n",
    "\n",
    "    # ê²°ê³¼ ë¶„ì„\n",
    "    if results:\n",
    "        print(f\"\\nğŸ“Š ìµœì¢… ì²˜ë¦¬ í†µê³„:\")\n",
    "        print(f\"   - ì´ ì²˜ë¦¬ ì‹œê°„: {format_duration(results['total_duration'])}\")\n",
    "        print(f\"   - íŒŒì¼ë‹¹ í‰ê· : {format_duration(results['avg_duration_per_file'])}\")\n",
    "        print(f\"   - ì„±ê³µë¥ : {(results['successful']/results['total_files']*100):.1f}%\")\n",
    "        print(f\"   - ì´ ì²˜ë¦¬ í–‰ ìˆ˜: {results['total_rows_processed']:,}í–‰\")\n",
    "        print(f\"   - ì‹œê°„ë‹¹ ì²˜ë¦¬ëŸ‰: {results['total_rows_processed']/(results['total_duration']/3600):.0f}í–‰/ì‹œê°„\")\n",
    "\n",
    "    # Ray ì¢…ë£Œ\n",
    "    ray.shutdown()\n",
    "    print(\"ğŸ”š Ray ì¢…ë£Œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# â­â­ 1. ëŒ€ìƒ í´ë” ê²½ë¡œë¥¼ ì„¤ì •í•˜ì„¸ìš”. â­â­\n",
    "# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ê°€ ì‹¤í–‰ë˜ëŠ” í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "# ë§Œì•½ '/Volumes/Data/betterwhy_origin/' í´ë” ë‚´ì˜ íŒŒì¼ì„ ëŒ€ìƒìœ¼ë¡œ í•œë‹¤ë©´:\n",
    "file_path_pattern = '/Volumes/Data/betterwhy_processed/**/*.csv'\n",
    "\n",
    "# glob.glob() í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë“  CSV íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\n",
    "# recursive=Trueë¥¼ ì‚¬ìš©í•˜ë©´ í•˜ìœ„ í´ë”ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤.\n",
    "csv_files = glob.glob(file_path_pattern, recursive=True)\n",
    "\n",
    "# ë³€ê²½ëœ íŒŒì¼ ê°œìˆ˜ ì¹´ìš´íŠ¸\n",
    "renamed_count = 0\n",
    "\n",
    "print(f\"ì´ {len(csv_files)}ê°œì˜ CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# 2. ê° íŒŒì¼ì— ëŒ€í•´ ë°˜ë³µë¬¸ ì‹¤í–‰\n",
    "for old_file_path in csv_files:\n",
    "    # íŒŒì¼ëª…ì—ì„œ 'clientid_' ì ‘ë‘ì‚¬ë¥¼ í™•ì¸í•˜ê³  ì œê±°í•©ë‹ˆë‹¤.\n",
    "    # os.path.basename()ì€ ê²½ë¡œì—ì„œ íŒŒì¼ ì´ë¦„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "    old_filename = os.path.basename(old_file_path)\n",
    "\n",
    "    # íŒŒì¼ ì´ë¦„ì´ 'clientid_'ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸\n",
    "    if old_filename.startswith('clientid_'):\n",
    "        # 'clientid_'ë¥¼ ì œê±°í•œ ìƒˆë¡œìš´ íŒŒì¼ ì´ë¦„ ìƒì„±\n",
    "        new_filename = old_filename.replace('clientid_', '', 1)\n",
    "\n",
    "        # ìƒˆë¡œìš´ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ ìƒì„±\n",
    "        # os.path.dirname()ì€ íŒŒì¼ ê²½ë¡œì—ì„œ ë””ë ‰í† ë¦¬ ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "        directory = os.path.dirname(old_file_path)\n",
    "        new_file_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        # íŒŒì¼ ì´ë¦„ ë³€ê²½ (rename)\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"ì´ë¦„ ë³€ê²½ ì„±ê³µ: '{old_filename}' -> '{new_filename}'\")\n",
    "            renamed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"ì´ë¦„ ë³€ê²½ ì‹¤íŒ¨: '{old_filename}' -> '{new_filename}' - ì˜¤ë¥˜: {e}\")\n",
    "            \n",
    "print(\"\\n--- ì‘ì—… ì™„ë£Œ ---\")\n",
    "print(f\"ì´ {renamed_count}ê°œì˜ íŒŒì¼ ì´ë¦„ì„ ë³€ê²½í–ˆìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
