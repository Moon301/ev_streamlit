{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade74c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import ray\n",
    "import time\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "class ProgressTracker:\n",
    "    \"\"\"진행률 추적을 위한 Ray Actor\"\"\"\n",
    "    def __init__(self, total_files: int):\n",
    "        self.total_files = total_files\n",
    "        self.completed_files = 0\n",
    "        self.failed_files = 0\n",
    "        self.start_time = time.time()\n",
    "        \n",
    "    def update_progress(self, success: bool = True):\n",
    "        if success:\n",
    "            self.completed_files += 1\n",
    "        else:\n",
    "            self.failed_files += 1\n",
    "            \n",
    "        progress = (self.completed_files + self.failed_files) / self.total_files * 100\n",
    "        elapsed = time.time() - self.start_time\n",
    "        \n",
    "        if (self.completed_files + self.failed_files) > 0:\n",
    "            avg_time = elapsed / (self.completed_files + self.failed_files)\n",
    "            remaining = (self.total_files - self.completed_files - self.failed_files) * avg_time\n",
    "            \n",
    "            print(f\"📊 진행률: {progress:.1f}% | 성공: {self.completed_files} | 실패: {self.failed_files} | \"\n",
    "                  f\"예상 남은 시간: {format_duration(remaining)}\")\n",
    "    \n",
    "    def get_stats(self):\n",
    "        return {\n",
    "            'total_files': self.total_files,\n",
    "            'completed': self.completed_files,\n",
    "            'failed': self.failed_files,\n",
    "            'total_duration': time.time() - self.start_time\n",
    "        }\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def preprocess_batch_parallel(batch_data: pd.DataFrame, car_info: Dict[str, Any]) -> pd.DataFrame:\n",
    "    \"\"\"배치 데이터 병렬 전처리\"\"\"\n",
    "    df = batch_data.copy()\n",
    "    \n",
    "    # 필드명에서 공백 제거\n",
    "    df.columns = df.columns.str.replace(' ', '')\n",
    "    cols = list(df.columns)\n",
    "    \n",
    "    # 필드 순서를 알파벳 순으로 재정렬 (clientid, timestamp는 앞에 유지)\n",
    "    cols_sorted = cols[0:2] + sorted(cols[2:])\n",
    "    df = df[cols_sorted]\n",
    "    \n",
    "    # ' None' 또는 'None'을 NaN으로 변경\n",
    "    df.replace([' None', 'None'], np.nan, inplace=True)\n",
    "    \n",
    "    # 오류 값 처리 (clientid, timestamp 제외)\n",
    "    target_cols = cols_sorted[2:]\n",
    "    \n",
    "    # 숫자 값을 float 타입으로 변경\n",
    "    for field in target_cols:\n",
    "        try:\n",
    "            df[field] = df[field].astype(float)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    # SOC, SOH 필드 검증 (0~100 범위)\n",
    "    soc_soh_cols = [col for col in target_cols if 'soc' in col or 'soh' in col]\n",
    "    for col in soc_soh_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < 0 or val > 100)) else val)\n",
    "    \n",
    "    # 전압 필드 검증 (3000 이하)\n",
    "    voltage_cols = [col for col in target_cols if '_v' in col]\n",
    "    for col in voltage_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and val > 3000) else val)\n",
    "    \n",
    "    # 온도 필드 검증 (-35 ~ 80도)\n",
    "    temp_cols = [col for col in target_cols if 'temperature' in col]\n",
    "    for col in temp_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < -35 or val > 80)) else val)\n",
    "    \n",
    "    # 전류 필드 검증 (-500 ~ 500)\n",
    "    current_cols = [col for col in target_cols if 'curr' in col or col.startswith('cell')]\n",
    "    for col in current_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < -500 or val > 500)) else val)\n",
    "    \n",
    "    # 속도 필드 검증 (0 ~ 180)\n",
    "    speed_cols = [col for col in target_cols if 'speed' in col]\n",
    "    for col in speed_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val < 0 or val > 180)) else val)\n",
    "    \n",
    "    # 누적주행거리 필드 검증 (0 초과 ~ 2,000,000 이하)\n",
    "    mileage_cols = [col for col in target_cols if 'mileage' in col]\n",
    "    for col in mileage_cols:\n",
    "        df[col] = df[col].map(lambda val: np.nan if (isinstance(val, (int, float)) and (val <= 0 or val > 2000000)) else val)\n",
    "    \n",
    "    # 차종 정보 추가\n",
    "    df['car_type'] = car_info.get('car_type', np.nan)\n",
    "    df['model_year'] = car_info.get('model_year', np.nan)\n",
    "    df['model_month'] = car_info.get('model_month', np.nan)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def preproc_betterwhy_parallel(csv_file: str, output_dir: str, remove_duplicates: bool = True, \n",
    "                              progress_tracker=None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    단일 CSV 파일을 병렬로 전처리\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"🔄 처리 시작: {os.path.basename(csv_file)}\")\n",
    "        file_start_time = time.time()\n",
    "        \n",
    "        # 출력 디렉토리 생성\n",
    "        Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # 배치 처리 설정\n",
    "        batch_size = 30000  # 병렬처리시 메모리 효율을 위해 조금 줄임\n",
    "        skip_rows = 0\n",
    "        batch_futures = []\n",
    "        car_info = {}\n",
    "        \n",
    "        # 첫 번째 배치에서 차량 정보 가져오기\n",
    "        first_batch = pd.read_csv(csv_file, nrows=1000, low_memory=False)\n",
    "        if not first_batch.empty:\n",
    "            carid = first_batch.iloc[0][\"clientid\"]\n",
    "            \n",
    "            # 차량 타입 정보 로드\n",
    "            try:\n",
    "                carid_df = pd.read_csv(\"/Users/moon/ev_streamlit/preproc/betterwhy_cartype_list.csv\")\n",
    "                result = carid_df[carid_df['client_id'] == carid]\n",
    "                \n",
    "                if len(result) > 0:\n",
    "                    row = result.iloc[0]\n",
    "                    car_info = {\n",
    "                        'car_type': row['car_type'],\n",
    "                        'model_year': row['model_year'],\n",
    "                        'model_month': row['model_month']\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"{os.path.basename(csv_file)}: clientid로 car_type을 찾을 수 없습니다.\")\n",
    "                    car_info = {'car_type': np.nan, 'model_year': np.nan, 'model_month': np.nan}\n",
    "            except Exception as e:\n",
    "                print(f\"차량 타입 정보 로드 실패: {e}\")\n",
    "                car_info = {'car_type': np.nan, 'model_year': np.nan, 'model_month': np.nan}\n",
    "        \n",
    "        # CSV 파일을 배치로 읽어서 병렬 처리\n",
    "        while True:\n",
    "            try:\n",
    "                df = pd.read_csv(csv_file, skiprows=skip_rows, nrows=batch_size, low_memory=False)\n",
    "                \n",
    "                if df.empty:\n",
    "                    break\n",
    "                \n",
    "                # 배치를 병렬로 전처리\n",
    "                batch_future = preprocess_batch_parallel.remote(df, car_info)\n",
    "                batch_futures.append(batch_future)\n",
    "                \n",
    "                skip_rows += batch_size\n",
    "                \n",
    "            except Exception as e:\n",
    "                if 'No columns to parse from file' in str(e):\n",
    "                    break\n",
    "                else:\n",
    "                    raise e\n",
    "        \n",
    "        if not batch_futures:\n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(False)\n",
    "            return {'success': False, 'error': '처리할 데이터가 없습니다.'}\n",
    "        \n",
    "        # 모든 배치 처리 결과 수집\n",
    "        print(f\"📦 {os.path.basename(csv_file)}: {len(batch_futures)}개 배치 병렬 처리 완료, 결합 중...\")\n",
    "        processed_batches = ray.get(batch_futures)\n",
    "        \n",
    "        # 모든 배치 데이터 결합\n",
    "        final_df = pd.concat(processed_batches, ignore_index=True)\n",
    "        \n",
    "        # 시간순 정렬\n",
    "        final_df.sort_values(by='timestamp', inplace=True)\n",
    "        final_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Client ID별로 그룹화하여 저장\n",
    "        saved_files = save_by_client_id_parallel(final_df, output_dir, remove_duplicates)\n",
    "        \n",
    "        processing_time = time.time() - file_start_time\n",
    "        \n",
    "        if saved_files:\n",
    "            # 저장 성공 시 원본 파일 삭제\n",
    "            os.remove(csv_file)\n",
    "            \n",
    "            # 원본 파일이 있던 디렉토리가 비어있으면 삭제\n",
    "            original_dir = os.path.dirname(csv_file)\n",
    "            if original_dir and not os.listdir(original_dir):\n",
    "                os.rmdir(original_dir)\n",
    "            \n",
    "            result = {\n",
    "                'success': True,\n",
    "                'file': csv_file,\n",
    "                'saved_files': len(saved_files),\n",
    "                'rows_processed': len(final_df),\n",
    "                'processing_time': processing_time\n",
    "            }\n",
    "            \n",
    "            print(f\"✅ {os.path.basename(csv_file)}: 완료 ({len(final_df):,}행, {format_duration(processing_time)})\")\n",
    "            \n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(True)\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            if progress_tracker:\n",
    "                progress_tracker.update_progress.remote(False)\n",
    "            return {'success': False, 'error': '파일 저장 실패'}\n",
    "            \n",
    "    except Exception as e:\n",
    "        if progress_tracker:\n",
    "            progress_tracker.update_progress.remote(False)\n",
    "        return {'success': False, 'error': str(e), 'file': csv_file}\n",
    "\n",
    "\n",
    "def save_by_client_id_parallel(df: pd.DataFrame, output_dir: str, remove_duplicates: bool = True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Client ID별로 CSV 파일 저장 (병렬처리 버전)\n",
    "    \"\"\"\n",
    "    saved_files = []\n",
    "    \n",
    "    try:\n",
    "        # Client ID별로 그룹화\n",
    "        grouped = df.groupby('clientid')\n",
    "        \n",
    "        for client_id, new_data in grouped:\n",
    "            # 시작 날짜 추출\n",
    "            try:\n",
    "                new_data_copy = new_data.copy()\n",
    "                new_data_copy['timestamp'] = pd.to_datetime(new_data_copy['timestamp'])\n",
    "                start_date = new_data_copy['timestamp'].min()\n",
    "                \n",
    "                year_month = start_date.strftime('%y%m')\n",
    "                start_date_str = start_date.strftime('%y%m%d')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"날짜 변환 오류 (Client {client_id}): {e}\")\n",
    "                now = datetime.now()\n",
    "                year_month = now.strftime('%y%m')\n",
    "                start_date_str = now.strftime('%y%m%d')\n",
    "            \n",
    "            # 월별 폴더 경로 생성\n",
    "            monthly_dir = os.path.join(output_dir, year_month)\n",
    "            os.makedirs(monthly_dir, exist_ok=True)\n",
    "            \n",
    "            # 파일명 생성\n",
    "            safe_client_id = str(client_id).replace('/', '_').replace('\\\\', '_')\n",
    "            filename = f\"{safe_client_id}_{start_date_str}.csv\"\n",
    "            filepath = os.path.join(monthly_dir, filename)\n",
    "            \n",
    "            # 기존 파일들 확인\n",
    "            existing_files = find_existing_client_files(output_dir, safe_client_id)\n",
    "            \n",
    "            if existing_files:\n",
    "                # 기존 파일들과 병합\n",
    "                combined_data = merge_with_existing_files(existing_files, new_data, client_id, remove_duplicates)\n",
    "                save_data_by_month(combined_data, output_dir, safe_client_id)\n",
    "            else:\n",
    "                # 새 파일 생성\n",
    "                if remove_duplicates:\n",
    "                    new_data = remove_duplicate_records(new_data, client_id)\n",
    "                \n",
    "                new_data.to_csv(filepath, index=False, encoding='utf-8')\n",
    "            \n",
    "            saved_files.append(filepath)\n",
    "        \n",
    "        return saved_files\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"파일 저장 중 오류: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def find_existing_client_files(output_dir: str, safe_client_id: str) -> List[str]:\n",
    "    \"\"\"특정 클라이언트의 기존 파일들을 모두 찾기\"\"\"\n",
    "    existing_files = []\n",
    "    pattern = os.path.join(output_dir, \"*\", f\"clientid_{safe_client_id}_*.csv\")\n",
    "    existing_files = glob.glob(pattern)\n",
    "    return existing_files\n",
    "\n",
    "\n",
    "def merge_with_existing_files(existing_files: List[str], new_data: pd.DataFrame, \n",
    "                            client_id: str, remove_duplicates: bool) -> pd.DataFrame:\n",
    "    \"\"\"기존 파일들과 새 데이터를 병합\"\"\"\n",
    "    try:\n",
    "        all_data = [new_data]\n",
    "        total_existing_rows = 0\n",
    "        \n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                existing_df = pd.read_csv(file_path, low_memory=False)\n",
    "                all_data.append(existing_df)\n",
    "                total_existing_rows += len(existing_df)\n",
    "            except Exception as e:\n",
    "                print(f\"파일 로드 실패 {file_path}: {e}\")\n",
    "        \n",
    "        # 모든 데이터 결합\n",
    "        combined_data = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # 중복 제거\n",
    "        if remove_duplicates:\n",
    "            combined_data = remove_duplicate_records(combined_data, client_id)\n",
    "        \n",
    "        # 시간순 정렬\n",
    "        combined_data['timestamp'] = pd.to_datetime(combined_data['timestamp'])\n",
    "        combined_data.sort_values(by='timestamp', inplace=True)\n",
    "        combined_data.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # 기존 파일들 삭제\n",
    "        for file_path in existing_files:\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f\"파일 삭제 실패 {file_path}: {e}\")\n",
    "        \n",
    "        return combined_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"파일 병합 중 오류 (Client {client_id}): {e}\")\n",
    "        return new_data\n",
    "\n",
    "\n",
    "def save_data_by_month(df: pd.DataFrame, output_dir: str, safe_client_id: str):\n",
    "    \"\"\"데이터를 월별로 분할하여 CSV로 저장\"\"\"\n",
    "    try:\n",
    "        # 월별로 그룹화\n",
    "        df['year_month'] = df['timestamp'].dt.strftime('%y%m')\n",
    "        monthly_groups = df.groupby('year_month')\n",
    "        \n",
    "        for year_month, month_data in monthly_groups:\n",
    "            start_date_str = month_data['timestamp'].min().strftime('%y%m%d')\n",
    "            \n",
    "            monthly_dir = os.path.join(output_dir, year_month)\n",
    "            os.makedirs(monthly_dir, exist_ok=True)\n",
    "            \n",
    "            filename = f\"{safe_client_id}_{start_date_str}.csv\"\n",
    "            filepath = os.path.join(monthly_dir, filename)\n",
    "            \n",
    "            month_data_clean = month_data.drop('year_month', axis=1)\n",
    "            month_data_clean.to_csv(filepath, index=False, encoding='utf-8')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"월별 저장 중 오류: {e}\")\n",
    "\n",
    "\n",
    "def remove_duplicate_records(df: pd.DataFrame, client_id: str) -> pd.DataFrame:\n",
    "    \"\"\"중복 레코드 제거 (timestamp 기준)\"\"\"\n",
    "    try:\n",
    "        df_deduplicated = df.drop_duplicates(subset=['clientid', 'timestamp'], keep='last')\n",
    "        \n",
    "        original_count = len(df)\n",
    "        final_count = len(df_deduplicated)\n",
    "        \n",
    "        if original_count != final_count:\n",
    "            print(f\"  Client {client_id}: 중복 제거 ({original_count} -> {final_count})\")\n",
    "        \n",
    "        return df_deduplicated\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  중복 제거 중 오류 (Client {client_id}): {e}\")\n",
    "        return df\n",
    "\n",
    "\n",
    "def process_multiple_files_parallel(csv_files: List[str], output_dir: str = \"processed\", \n",
    "                                   remove_duplicates: bool = True, max_workers: Optional[int] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Ray를 사용한 병렬 파일 처리\n",
    "    \n",
    "    Args:\n",
    "        csv_files: 처리할 CSV 파일 리스트\n",
    "        output_dir: 출력 디렉토리\n",
    "        remove_duplicates: 중복 데이터 제거 여부\n",
    "        max_workers: 최대 워커 수 (None이면 CPU 코어 수 사용)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Ray 초기화\n",
    "    if not ray.is_initialized():\n",
    "        # CPU 코어 수의 80% 사용 (시스템 안정성을 위해)\n",
    "        num_cpus = max_workers or max(1, int(os.cpu_count() * 0.8))\n",
    "        ray.init(num_cpus=num_cpus, ignore_reinit_error=True)\n",
    "        print(f\"🚀 Ray 초기화 완료 (워커 수: {num_cpus})\")\n",
    "    \n",
    "    total_files = len(csv_files)\n",
    "    print(f\"📁 총 {total_files}개 파일 병렬 처리 시작\")\n",
    "    print(f\"📂 출력 디렉토리: {output_dir}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # 진행률 추적기 생성\n",
    "    progress_tracker = ProgressTracker.remote(total_files)\n",
    "    \n",
    "    # 전체 처리 시작 시간\n",
    "    total_start_time = time.time()\n",
    "    \n",
    "    # 모든 파일을 병렬로 처리\n",
    "    file_futures = []\n",
    "    for csv_file in csv_files:\n",
    "        future = preproc_betterwhy_parallel.remote(\n",
    "            csv_file, output_dir, remove_duplicates, progress_tracker\n",
    "        )\n",
    "        file_futures.append(future)\n",
    "    \n",
    "    # 모든 작업 완료 대기\n",
    "    print(\"⏳ 모든 파일 병렬 처리 중...\")\n",
    "    results = ray.get(file_futures)\n",
    "    \n",
    "    # 최종 통계\n",
    "    total_end_time = time.time()\n",
    "    total_duration = total_end_time - total_start_time\n",
    "    final_stats = ray.get(progress_tracker.get_stats.remote())\n",
    "    \n",
    "    successful_files = sum(1 for r in results if r.get('success', False))\n",
    "    failed_files = len(results) - successful_files\n",
    "    total_rows = sum(r.get('rows_processed', 0) for r in results if r.get('success', False))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"🎉 병렬 처리 완료!\")\n",
    "    print(f\"📈 성공: {successful_files}개 | ❌ 실패: {failed_files}개\")\n",
    "    print(f\"📊 총 처리 행 수: {total_rows:,}행\")\n",
    "    print(f\"⏱️  총 소요시간: {format_duration(total_duration)}\")\n",
    "    print(f\"⚡ 평균 파일당: {format_duration(total_duration / total_files)}\")\n",
    "    \n",
    "    # 실패한 파일들 출력\n",
    "    if failed_files > 0:\n",
    "        print(f\"\\n❌ 실패한 파일들:\")\n",
    "        for result in results:\n",
    "            if not result.get('success', False):\n",
    "                file_name = os.path.basename(result.get('file', 'Unknown'))\n",
    "                error = result.get('error', 'Unknown error')\n",
    "                print(f\"   - {file_name}: {error}\")\n",
    "    \n",
    "    return {\n",
    "        'total_files': total_files,\n",
    "        'successful': successful_files,\n",
    "        'failed': failed_files,\n",
    "        'total_duration': total_duration,\n",
    "        'avg_duration_per_file': total_duration / total_files,\n",
    "        'total_rows_processed': total_rows,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "\n",
    "def format_duration(seconds: float) -> str:\n",
    "    \"\"\"초를 읽기 쉬운 형태로 변환\"\"\"\n",
    "    if seconds < 60:\n",
    "        return f\"{seconds:.1f}초\"\n",
    "    elif seconds < 3600:\n",
    "        minutes = int(seconds // 60)\n",
    "        secs = seconds % 60\n",
    "        return f\"{minutes}분 {secs:.1f}초\"\n",
    "    else:\n",
    "        hours = int(seconds // 3600)\n",
    "        minutes = int((seconds % 3600) // 60)\n",
    "        secs = seconds % 60\n",
    "        return f\"{hours}시간 {minutes}분 {secs:.1f}초\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d7dd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:01:07,021\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 300개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 🔄 처리 시작: 1357rqwe_V000BL0011_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 0.3% | 성공: 0 | 실패: 1 | 예상 남은 시간: 5분 39.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 0.7% | 성공: 0 | 실패: 2 | 예상 남은 시간: 2분 58.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 1.0% | 성공: 0 | 실패: 3 | 예상 남은 시간: 2분 2.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 1.3% | 성공: 0 | 실패: 4 | 예상 남은 시간: 1분 41.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 1.7% | 성공: 0 | 실패: 5 | 예상 남은 시간: 1분 56.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 2.0% | 성공: 0 | 실패: 6 | 예상 남은 시간: 1분 39.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 2.3% | 성공: 0 | 실패: 7 | 예상 남은 시간: 1분 41.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 2.7% | 성공: 0 | 실패: 8 | 예상 남은 시간: 1분 41.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65069)\u001b[0m 📦 aim21c_V007AJ0000_NIRO LONGRANGE_201801.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=65070)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65070)\u001b[0m 🔄 처리 시작: ajutaxi-9_V020BG0010_IONIQ 2019_201701.csv\u001b[32m [repeated 14x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m 📦 48625ff_V004CA0001_EV6 LONGRANGE_202210.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65116)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m 🔄 처리 시작: alice2235_V011AK0000_PORTER2_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 3.0% | 성공: 0 | 실패: 9 | 예상 남은 시간: 6분 16.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 3.3% | 성공: 0 | 실패: 10 | 예상 남은 시간: 5분 39.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m 🔄 처리 시작: azking_V000CC0019_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m 🔄 처리 시작: babaliian_V000CD0076_ST1_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 3.7% | 성공: 1 | 실패: 10 | 예상 남은 시간: 5분 41.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m ✅ adreamcar_V011AI0001_PORTER2_202301.csv: 완료 (24,500행, 11.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m 🔄 처리 시작: bbotti_V000BE0017_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 4.0% | 성공: 2 | 실패: 10 | 예상 남은 시간: 5분 18.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 4.3% | 성공: 3 | 실패: 10 | 예상 남은 시간: 5분 42.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m 📦 bbotti_V000BE0017_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m 📦 babaliian_V000CD0076_ST1_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: bbs001_V020CA0000_IONIQ 2019_201710.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65196)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m 🔄 처리 시작: beston_V013AK0001_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65069)\u001b[0m ✅ aim21c_V007AJ0000_NIRO LONGRANGE_201801.csv: 완료 (30,036행, 14.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 4.7% | 성공: 4 | 실패: 10 | 예상 남은 시간: 9분 1.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 bbs001_V020CA0000_IONIQ 2019_201710.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65085)\u001b[0m ✅ airme_V000CC0050_EV6 LONGRANGE_202403.csv: 완료 (29,998행, 24.5초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 5.0% | 성공: 5 | 실패: 10 | 예상 남은 시간: 8분 35.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65066)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 5.3% | 성공: 6 | 실패: 10 | 예상 남은 시간: 8분 10.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 🔄 처리 시작: bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m 📦 bluesky8571_V000CD0059_EV3 LONGRANGE_202504.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m 🔄 처리 시작: bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 5.7% | 성공: 7 | 실패: 10 | 예상 남은 시간: 8분 56.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m ✅ ableautos_V000CB0021_EV6 LONGRANGE_202206.csv: 완료 (48,218행, 26.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 6.0% | 성공: 7 | 실패: 11 | 예상 남은 시간: 8분 26.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: boxing0217_V026CA000_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 6.3% | 성공: 8 | 실패: 11 | 예상 남은 시간: 8분 17.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 📦 bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 6.7% | 성공: 8 | 실패: 12 | 예상 남은 시간: 7분 53.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 7.0% | 성공: 8 | 실패: 13 | 예상 남은 시간: 7분 30.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 7.3% | 성공: 8 | 실패: 14 | 예상 남은 시간: 7분 9.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m 🔄 처리 시작: cgtaxi-1_V003BA0005_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 7.7% | 성공: 9 | 실패: 14 | 예상 남은 시간: 6분 59.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 8.0% | 성공: 10 | 실패: 14 | 예상 남은 시간: 6분 46.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m 📦 bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65274)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 8.3% | 성공: 11 | 실패: 14 | 예상 남은 시간: 6분 37.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m ✅ bbotti_V000BE0017_IONIQ5 LONGRANGE.csv: 완료 (32,775행, 23.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65145)\u001b[0m ✅ babaliian_V000CD0076_ST1_202407.csv: 완료 (54,401행, 23.6초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65274)\u001b[0m 🔄 처리 시작: cjl-dgds-007_V011BE0025_PORTER2.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 8.7% | 성공: 11 | 실패: 15 | 예상 남은 시간: 6분 54.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 9.0% | 성공: 11 | 실패: 16 | 예상 남은 시간: 6분 47.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65145)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 9.3% | 성공: 12 | 실패: 16 | 예상 남은 시간: 7분 18.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m 🔄 처리 시작: cjl-dgea-016_V011BE0022_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65274)\u001b[0m 📦 cjl-dgds-011_V011BE0023_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ✅ bjgjw2579_V000CC0077_EV6 LONGRANGE_202109.csv: 완료 (21,290행, 17.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65066)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 9.7% | 성공: 12 | 실패: 17 | 예상 남은 시간: 7분 42.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 10.0% | 성공: 12 | 실패: 18 | 예상 남은 시간: 7분 25.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 10.3% | 성공: 12 | 실패: 19 | 예상 남은 시간: 7분 10.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 🔄 처리 시작: cjl-dgss-012_V011BE0013_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 📦 cjl-dgss-012_V011BE0013_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 10.7% | 성공: 13 | 실패: 19 | 예상 남은 시간: 7분 39.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65067)\u001b[0m ✅ cjl-dgds-006_V011BE0024_PORTER2.csv: 완료 (57,476행, 17.6초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 11.0% | 성공: 14 | 실패: 19 | 예상 남은 시간: 7분 39.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65196)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 11.3% | 성공: 15 | 실패: 19 | 예상 남은 시간: 7분 28.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 11.7% | 성공: 15 | 실패: 20 | 예상 남은 시간: 7분 17.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 12.0% | 성공: 15 | 실패: 21 | 예상 남은 시간: 7분 4.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 12.3% | 성공: 15 | 실패: 22 | 예상 남은 시간: 6분 51.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 12.7% | 성공: 15 | 실패: 23 | 예상 남은 시간: 6분 41.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 13.0% | 성공: 15 | 실패: 24 | 예상 남은 시간: 6분 31.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65259)\u001b[0m ✅ bluewing4_V000CB0068_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (49,084행, 27.3초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 13.3% | 성공: 16 | 실패: 24 | 예상 남은 시간: 6분 21.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 13.7% | 성공: 17 | 실패: 24 | 예상 남은 시간: 6분 14.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 🔄 처리 시작: cjl-gbyc-016_V012BE0139_BONGO3.csv\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m 📦 cjl-dgss-013_V011BE0014_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 📦 cjl-gbyc-016_V012BE0139_BONGO3.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ✅ c1228kr_V000CD0084_IONIQ5 LONGRANGE_202201.csv: 완료 (69,216행, 27.0초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65259)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 14.0% | 성공: 17 | 실패: 25 | 예상 남은 시간: 6분 23.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m 🔄 처리 시작: clausewitx_V000CB0063_GV70_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 14.3% | 성공: 18 | 실패: 25 | 예상 남은 시간: 6분 35.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 14.7% | 성공: 19 | 실패: 25 | 예상 남은 시간: 6분 37.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m 📦 clausewitx_V000CB0063_GV70_202210.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65063)\u001b[0m ✅ cjawl74_V000CC0007_PORTER2_202412.csv: 완료 (135,662행, 32.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65068)\u001b[0m ✅ cjl-dgea-016_V011BE0022_PORTER2.csv: 완료 (126,135행, 27.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65068)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 15.0% | 성공: 20 | 실패: 25 | 예상 남은 시간: 6분 34.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m 🔄 처리 시작: cyberlmk_V021BJ0001_EV9_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 15.3% | 성공: 21 | 실패: 25 | 예상 남은 시간: 6분 32.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m 🔄 처리 시작: day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 15.7% | 성공: 21 | 실패: 26 | 예상 남은 시간: 6분 29.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 16.0% | 성공: 22 | 실패: 26 | 예상 남은 시간: 6분 29.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 cjosooo_V000CD0023_ST1_202407.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ✅ cjl-dgss-013_V011BE0014_PORTER2.csv: 완료 (33,859행, 14.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m 📦 day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 16.3% | 성공: 23 | 실패: 26 | 예상 남은 시간: 6분 27.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 🔄 처리 시작: daegitaxi-2_V03BA0020_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 🔄 처리 시작: ddongkolip_V000CA0035_ST1_202405.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65510)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 16.7% | 성공: 24 | 실패: 26 | 예상 남은 시간: 6분 24.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 17.0% | 성공: 24 | 실패: 27 | 예상 남은 시간: 6분 15.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 17.3% | 성공: 25 | 실패: 27 | 예상 남은 시간: 6분 14.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 ddtaxi-1_V004BA0001_EV6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65448)\u001b[0m ✅ clausewitx_V000CB0063_GV70_202210.csv: 완료 (20,442행, 16.1초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m 🔄 처리 시작: ddtaxi-5_V004BA0003_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65448)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 📦 ddongkolip_V000CA0035_ST1_202405.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m 🔄 처리 시작: dibidib_V021BJ0002_EV9_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 17.7% | 성공: 26 | 실패: 27 | 예상 남은 시간: 7분 3.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65066)\u001b[0m ✅ cyberlmk_V021BJ0001_EV9_202308.csv: 완료 (51,138행, 21.0초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 18.0% | 성공: 27 | 실패: 27 | 예상 남은 시간: 6분 57.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 18.3% | 성공: 27 | 실패: 28 | 예상 남은 시간: 6분 49.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 18.7% | 성공: 28 | 실패: 28 | 예상 남은 시간: 6분 55.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: dlcksgh3595_V000CA0027_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65196)\u001b[0m ✅ day9672_V000CD0072_IONIQ5 LONGRANGE 2022_202310.csv: 완료 (33,700행, 24.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ✅ cjosooo_V000CD0023_ST1_202407.csv: 완료 (75,922행, 29.3초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 19.0% | 성공: 29 | 실패: 28 | 예상 남은 시간: 6분 53.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: dufdl1025_V004BJ0000_EV6 LONGRANGE_202404.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ delpainus_V000CE0022_IONIQ5 LONGRANGE 2022_202307.csv: 완료 (12,786행, 8.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m 📦 dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m 🔄 처리 시작: dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 19.3% | 성공: 30 | 실패: 28 | 예상 남은 시간: 7분 20.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65450)\u001b[0m ✅ deeps7011_V000CC0052_EV6 LONGRANGE_202411.csv: 완료 (51,818행, 28.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 19.7% | 성공: 31 | 실패: 28 | 예상 남은 시간: 7분 19.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 20.0% | 성공: 32 | 실패: 28 | 예상 남은 시간: 7분 12.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 20.3% | 성공: 32 | 실패: 29 | 예상 남은 시간: 7분 4.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m 🔄 처리 시작: eha031_V000CD0097_PORTER2_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m 🔄 처리 시작: ehdghans1_V000CC0074_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 20.7% | 성공: 32 | 실패: 30 | 예상 남은 시간: 6분 55.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 21.0% | 성공: 32 | 실패: 31 | 예상 남은 시간: 6분 47.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m 🔄 처리 시작: emob-1_V000BD0002_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 ekfmd3152_V009BL0002_KONA LONGRANGE_202004.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m 📦 emob-1_V000BD0002_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ✅ ddtaxi-5_V004BA0003_EV6 LONGRANGE_202201.csv: 완료 (59,745행, 31.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 21.3% | 성공: 33 | 실패: 31 | 예상 남은 시간: 6분 59.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: emob-2_V020BD0000_IONIQ 2019.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 21.7% | 성공: 33 | 실패: 32 | 예상 남은 시간: 6분 51.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 22.0% | 성공: 33 | 실패: 33 | 예상 남은 시간: 6분 44.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 22.3% | 성공: 33 | 실패: 34 | 예상 남은 시간: 6분 37.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 📦 emob-2_V020BD0000_IONIQ 2019.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 22.7% | 성공: 34 | 실패: 34 | 예상 남은 시간: 6분 31.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65673)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 23.0% | 성공: 35 | 실패: 34 | 예상 남은 시간: 6분 26.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ✅ ddongkolip_V000CA0035_ST1_202405.csv: 완료 (97,846행, 39.7초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 23.3% | 성공: 36 | 실패: 34 | 예상 남은 시간: 6분 30.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 🔄 처리 시작: geni8895_V000CD0081_BONGO3_202210.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65540)\u001b[0m ✅ emob-1_V000BD0002_IONIQ5 LONGRANGE.csv: 완료 (14,685행, 10.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 23.7% | 성공: 37 | 실패: 34 | 예상 남은 시간: 6분 25.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m 📦 geni8895_V000CD0081_BONGO3_202210.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 24.0% | 성공: 38 | 실패: 34 | 예상 남은 시간: 6분 24.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 24.3% | 성공: 38 | 실패: 35 | 예상 남은 시간: 6분 18.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: giugi_V004BE0005_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 24.7% | 성공: 38 | 실패: 36 | 예상 남은 시간: 6분 11.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ✅ dmcdimo_V000CC0005_EV6 LONGRANGE_202211.csv: 완료 (39,493행, 29.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m 🔄 처리 시작: hahakuhyun_V004BI0000_EV6 LONGRANGE_202401.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 25.0% | 성공: 39 | 실패: 36 | 예상 남은 시간: 6분 14.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m 📦 ha8519_V021BI0003_EV9_202401.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 25.3% | 성공: 40 | 실패: 36 | 예상 남은 시간: 6분 12.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 25.7% | 성공: 40 | 실패: 37 | 예상 남은 시간: 6분 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ✅ fojokr_V000CC0029_CASPER LONGRANGE_202410.csv: 완료 (19,547행, 11.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m 🔄 처리 시작: heo3252_V009BL0004_KONA LONGRANGE_201901.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m 📦 heo3252_V009BL0004_KONA LONGRANGE_201901.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 26.0% | 성공: 41 | 실패: 37 | 예상 남은 시간: 6분 9.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65674)\u001b[0m ✅ dnwjdals1_V000CC0016_IONIQ5 LONGRANGE_202107.csv: 완료 (50,135행, 30.8초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 26.3% | 성공: 42 | 실패: 37 | 예상 남은 시간: 6분 13.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65421)\u001b[0m ✅ geni8895_V000CD0081_BONGO3_202210.csv: 완료 (49,895행, 17.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: hmp4522_V000CB0085_EV3 LONGRANGE_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m 📦 hmc1006_V000CD0036_ST1_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 26.7% | 성공: 43 | 실패: 37 | 예상 남은 시간: 6분 12.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 27.0% | 성공: 44 | 실패: 37 | 예상 남은 시간: 6분 9.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 hmp4522_V000CB0085_EV3 LONGRANGE_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65808)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ esm3100_V000CB0089_BONGO3_202304.csv: 완료 (63,510행, 22.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 27.3% | 성공: 44 | 실패: 38 | 예상 남은 시간: 6분 11.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 27.7% | 성공: 45 | 실패: 38 | 예상 남은 시간: 6분 7.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65910)\u001b[0m 🔄 처리 시작: hophip5677_V000CA0024_CASPER LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 28.0% | 성공: 45 | 실패: 39 | 예상 남은 시간: 6분 2.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 28.3% | 성공: 46 | 실패: 39 | 예상 남은 시간: 6분 2.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 hyisjung_V007AL0001_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m 🔄 처리 시작: iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 28.7% | 성공: 47 | 실패: 39 | 예상 남은 시간: 5분 57.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 29.0% | 성공: 48 | 실패: 39 | 예상 남은 시간: 5분 54.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ helleus77_V005CA0000_EV6 STANDARD_202108.csv: 완료 (27,107행, 16.7초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 📦 ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: hyisjung_V007AL0001_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m 📦 iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 29.3% | 성공: 49 | 실패: 39 | 예상 남은 시간: 5분 54.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 29.7% | 성공: 50 | 실패: 39 | 예상 남은 시간: 5분 49.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65510)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m 🔄 처리 시작: j227_V022BL0000_KONA LONGRANGE 2세대_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ honeybto_V015BL0000_GV60_202205.csv: 완료 (11,975행, 10.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 30.0% | 성공: 50 | 실패: 40 | 예상 남은 시간: 5분 50.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 janko7_V000CE0001_EV3 LONGRANGE_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 🔄 처리 시작: jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 30.3% | 성공: 51 | 실패: 40 | 예상 남은 시간: 5분 48.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m 📦 j227_V022BL0000_KONA LONGRANGE 2세대_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65975)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 30.7% | 성공: 52 | 실패: 40 | 예상 남은 시간: 5분 49.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 31.0% | 성공: 53 | 실패: 40 | 예상 남은 시간: 5분 48.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ dufdl1025_V004BJ0000_EV6 LONGRANGE_202404.csv: 완료 (124,926행, 56.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 jhs3101_V000CD0065_PORTER2_202002.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: jhs3101_V000CD0065_PORTER2_202002.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: jinjinjw_V000CD0040_IONIQ5 LONGRANGE_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 31.3% | 성공: 53 | 실패: 41 | 예상 남은 시간: 5분 45.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 31.7% | 성공: 54 | 실패: 41 | 예상 남은 시간: 5분 41.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ ignatius9107_V000CB0094_IONIQ5 N NE_202502.csv: 완료 (18,649행, 14.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65975)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m ✅ hmc1006_V000CD0036_ST1_202504.csv: 완료 (34,127행, 24.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 jmjang2_V000CD0034_ST1_202405.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: jmjang2_V000CD0034_ST1_202405.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 📦 jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 32.0% | 성공: 55 | 실패: 41 | 예상 남은 시간: 5분 47.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ✅ j227_V022BL0000_KONA LONGRANGE 2세대_202311.csv: 완료 (38,610행, 18.8초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 32.3% | 성공: 56 | 실패: 41 | 예상 남은 시간: 5분 42.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65595)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 32.7% | 성공: 57 | 실패: 41 | 예상 남은 시간: 5분 43.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ janko7_V000CE0001_EV3 LONGRANGE_202504.csv: 완료 (50,008행, 19.2초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 33.0% | 성공: 57 | 실패: 42 | 예상 남은 시간: 5분 39.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 33.3% | 성공: 57 | 실패: 43 | 예상 남은 시간: 5분 35.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 33.7% | 성공: 57 | 실패: 44 | 예상 남은 시간: 5분 30.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m 🔄 처리 시작: joiltaxi-19_V000BA0008_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 34.0% | 성공: 58 | 실패: 44 | 예상 남은 시간: 5분 27.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 34.3% | 성공: 58 | 실패: 45 | 예상 남은 시간: 5분 22.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65595)\u001b[0m ✅ iamme77_V000CB0058_IONIQ5 LONGRANGE 2022_202310.csv: 완료 (25,076행, 20.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 jmmath_V000BD0000_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65808)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ jhs3101_V000CD0065_PORTER2_202002.csv: 완료 (30,601행, 16.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m 🔄 처리 시작: joiltaxi-26_V004BA0030_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m 📦 joiltaxi-21_V004BA0027_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66126)\u001b[0m 🔄 처리 시작: joiltaxi-3_V000BA0004_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 34.7% | 성공: 58 | 실패: 46 | 예상 남은 시간: 5분 43.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66126)\u001b[0m 🔄 처리 시작: joiltaxi-7_V004BA0019_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 35.0% | 성공: 58 | 실패: 47 | 예상 남은 시간: 5분 38.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 35.3% | 성공: 59 | 실패: 47 | 예상 남은 시간: 5분 34.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ✅ jdisky_V000CE0010_IONIQ5 LONGRANGE_202112.csv: 완료 (63,216행, 31.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 35.7% | 성공: 59 | 실패: 48 | 예상 남은 시간: 5분 29.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 36.0% | 성공: 59 | 실패: 49 | 예상 남은 시간: 5분 24.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 36.3% | 성공: 59 | 실패: 50 | 예상 남은 시간: 5분 23.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 36.7% | 성공: 60 | 실패: 50 | 예상 남은 시간: 5분 18.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m ✅ js5540810_V000CA0025_IONIQ 2019_201607.csv: 완료 (4,216행, 2.0초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 37.0% | 성공: 61 | 실패: 50 | 예상 남은 시간: 5분 16.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65064)\u001b[0m 📦 js5540810_V000CA0025_IONIQ 2019_201607.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 jsmtnaud_V000CB0041_IONIQ5 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: jtkim0601_V007AL0000_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 37.3% | 성공: 62 | 실패: 50 | 예상 남은 시간: 5분 14.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ jmjang2_V000CD0034_ST1_202405.csv: 완료 (50,665행, 28.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ jmm3303_V000CD0032_THE NEW IONIQ5 LONGRANGE_202503.csv: 완료 (40,596행, 29.2초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 37.7% | 성공: 63 | 실패: 50 | 예상 남은 시간: 5분 12.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65809)\u001b[0m ✅ jinsu7426_V000CD0041_EV6 LONGRANGE_202407.csv: 완료 (39,656행, 31.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 38.0% | 성공: 64 | 실패: 50 | 예상 남은 시간: 5분 12.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 junhyuk0413_V000CD0029_NIRO2_202209.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 🔄 처리 시작: juhwan7455_V000CE0018_EV3 LONGRANGE_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ jmmath_V000BD0000_IONIQ5 LONGRANGE_202207.csv: 완료 (37,205행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 38.3% | 성공: 65 | 실패: 50 | 예상 남은 시간: 5분 15.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65808)\u001b[0m ✅ joiltaxi-26_V004BA0030_EV6 LONGRANGE_202201.csv: 완료 (26,822행, 26.5초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 38.7% | 성공: 66 | 실패: 50 | 예상 남은 시간: 5분 18.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 📦 junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 🔄 처리 시작: k2elryu_V017BL0000_G80_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 39.0% | 성공: 66 | 실패: 51 | 예상 남은 시간: 5분 13.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 🔄 처리 시작: kate3070kr_V000CC0001_GV70_202107.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 39.3% | 성공: 67 | 실패: 51 | 예상 남은 시간: 5분 10.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m ✅ jog5064_V000CB0077_EV6 LONGRANGE_202307.csv: 완료 (42,704행, 34.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 39.7% | 성공: 68 | 실패: 51 | 예상 남은 시간: 5분 9.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: kepco-3_V000BH0002_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 40.0% | 성공: 68 | 실패: 52 | 예상 남은 시간: 5분 5.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 kate3070kr_V000CC0001_GV70_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: kgs0002_V000CB0010_EV6 LONGRANGE_202205.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ jtkim0601_V007AL0000_NIRO LONGRANGE_201808.csv: 완료 (33,713행, 17.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 40.3% | 성공: 69 | 실패: 52 | 예상 남은 시간: 5분 12.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 kgs0002_V000CB0010_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ junsuck86_V000CB0027_EV6 LONGRANGE_202304.csv: 완료 (18,512행, 17.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: kimdajo_V000CC0008_EV6 LONGRANGE_202210.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 40.7% | 성공: 70 | 실패: 52 | 예상 남은 시간: 5분 9.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 41.0% | 성공: 71 | 실패: 52 | 예상 남은 시간: 5분 6.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 🔄 처리 시작: kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66268)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 41.3% | 성공: 72 | 실패: 52 | 예상 남은 시간: 5분 4.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 📦 kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66074)\u001b[0m ✅ joiltaxi-21_V004BA0027_EV6 LONGRANGE_202201.csv: 완료 (102,839행, 45.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 41.7% | 성공: 73 | 실패: 52 | 예상 남은 시간: 5분 6.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 42.0% | 성공: 74 | 실패: 52 | 예상 남은 시간: 5분 3.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m 🔄 처리 시작: kkhjust00_V000CC0068_EV3 STANDARD_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m 📦 kkhjust00_V000CC0068_EV3 STANDARD_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ✅ junghun1155_V004AL0000_EV6 LONGRANGE_202302.csv: 완료 (39,510행, 28.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66381)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 42.3% | 성공: 75 | 실패: 52 | 예상 남은 시간: 5분 10.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m 🔄 처리 시작: korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ✅ kjyzeal_V003CA0000_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (18,699행, 14.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m 📦 korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 42.7% | 성공: 76 | 실패: 52 | 예상 남은 시간: 5분 9.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m ✅ kor87_V000CC0020_NIRO PLUS_202207.csv: 완료 (22,971행, 10.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m 📦 ksjksj87_V029BL0001_EV3 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 43.0% | 성공: 77 | 실패: 52 | 예상 남은 시간: 5분 9.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66073)\u001b[0m 🔄 처리 시작: ksjksj87_V029BL0001_EV3 LONGRANGE_202409.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 43.3% | 성공: 78 | 실패: 52 | 예상 남은 시간: 5분 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ kate3070kr_V000CC0001_GV70_202107.csv: 완료 (49,522행, 34.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 43.7% | 성공: 78 | 실패: 53 | 예상 남은 시간: 5분 4.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 📦 koreataxi-1_V000BB0000_IONIQ5 LONGRANGE_202204.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m 📦 kung417s_V004AK0001_EV6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m 🔄 처리 시작: ky80901_V000CD0024_ST1_202406.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66320)\u001b[0m ✅ kkhjust00_V000CC0068_EV3 STANDARD_202408.csv: 완료 (42,935행, 22.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 44.0% | 성공: 79 | 실패: 53 | 예상 남은 시간: 5분 8.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 44.3% | 성공: 80 | 실패: 53 | 예상 남은 시간: 5분 8.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66535)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 44.7% | 성공: 81 | 실패: 53 | 예상 남은 시간: 5분 4.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m 📦 ky80901_V000CD0024_ST1_202406.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: lbk5510_V003CA0002_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 45.0% | 성공: 82 | 실패: 53 | 예상 남은 시간: 5분 2.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ kimzizone2_V000CB0057_IONIQ5 LONGRANGE_202203.csv: 완료 (39,367행, 33.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 🔄 처리 시작: ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 45.3% | 성공: 82 | 실패: 54 | 예상 남은 시간: 4분 58.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m 📦 ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 45.7% | 성공: 83 | 실패: 54 | 예상 남은 시간: 5분 0.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ kimdajo_V000CC0008_EV6 LONGRANGE_202210.csv: 완료 (71,624행, 35.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 🔄 처리 시작: lee1174_V004CG0022_EV9_202505.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ✅ korea1736_V000CE0007_IONIQ5 LONGRANGE_202203.csv: 완료 (38,715행, 32.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m 🔄 처리 시작: lee5957_V000BH0015_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 📦 lee1174_V004CG0022_EV9_202505.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m 📦 lee5957_V000BH0015_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66073)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 46.0% | 성공: 84 | 실패: 54 | 예상 남은 시간: 5분 9.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ✅ koreataxi-1_V000BB0000_IONIQ5 LONGRANGE_202204.csv: 완료 (66,058행, 35.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 🔄 처리 시작: leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 📦 leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66615)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m 🔄 처리 시작: leejh824_V000CB0009_GV70_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 46.3% | 성공: 85 | 실패: 54 | 예상 남은 시간: 5분 10.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 46.7% | 성공: 85 | 실패: 55 | 예상 남은 시간: 5분 6.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 47.0% | 성공: 85 | 실패: 56 | 예상 남은 시간: 5분 2.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m 🔄 처리 시작: legojeon_V000CB0036_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m 🔄 처리 시작: lijingice007_V000CA0038_ST1_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 47.3% | 성공: 86 | 실패: 56 | 예상 남은 시간: 5분 1.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65510)\u001b[0m ✅ kung417s_V004AK0001_EV6 LONGRANGE_202201.csv: 완료 (30,162행, 32.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ kyh108_V003BL0001_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (38,800행, 33.6초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 47.7% | 성공: 87 | 실패: 56 | 예상 남은 시간: 5분 2.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ✅ leejangju_V000CC0032_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (15,210행, 12.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m 📦 lijingice007_V000CA0038_ST1_202411.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m 🔄 처리 시작: lny-taxi-p1_V013BC0000_IONIQ6 LONGRANGE_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 48.0% | 성공: 88 | 실패: 56 | 예상 남은 시간: 4분 59.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 48.3% | 성공: 88 | 실패: 57 | 예상 남은 시간: 4분 56.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ✅ lee5957_V000BH0015_IONIQ5 LONGRANGE.csv: 완료 (29,953행, 24.1초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 48.7% | 성공: 89 | 실패: 57 | 예상 남은 시간: 4분 54.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 49.0% | 성공: 90 | 실패: 57 | 예상 남은 시간: 4분 50.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 49.3% | 성공: 91 | 실패: 57 | 예상 남은 시간: 4분 46.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ ldw8482_V000CA0034_EV6 LONGRANGE_202204.csv: 완료 (33,566행, 31.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 49.7% | 성공: 92 | 실패: 57 | 예상 남은 시간: 4분 42.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 50.0% | 성공: 92 | 실패: 58 | 예상 남은 시간: 4분 39.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65751)\u001b[0m ✅ ldhljs7725_V000CB0070_THE NEW IONIQ5 LONGRANGE_202408.csv: 완료 (38,221행, 31.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m 📦 lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65751)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m 🔄 처리 시작: lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ✅ ky80901_V000CD0024_ST1_202406.csv: 완료 (85,190행, 41.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 50.3% | 성공: 93 | 실패: 58 | 예상 남은 시간: 4분 41.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 50.7% | 성공: 93 | 실패: 59 | 예상 남은 시간: 4분 39.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 lotteglogis-dg-16_V011BD0001_PORTER2.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: lotteglogis-dg-31_V011BD0006_PORTER2_202401.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 51.0% | 성공: 93 | 실패: 60 | 예상 남은 시간: 4분 37.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 51.3% | 성공: 94 | 실패: 60 | 예상 남은 시간: 4분 33.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66214)\u001b[0m ✅ lostcity1_V000CC0058_PORTER2_202412.csv: 완료 (23,571행, 11.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 📦 lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 🔄 처리 시작: lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66486)\u001b[0m ✅ lotteglogis-dg-22_V011BD0008_PORTER2_202301.csv: 완료 (31,932행, 18.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 51.7% | 성공: 95 | 실패: 60 | 예상 남은 시간: 4분 38.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 52.0% | 성공: 96 | 실패: 60 | 예상 남은 시간: 4분 36.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66847)\u001b[0m 🔄 처리 시작: lotteglogis-dg-7_V011BD0002_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ✅ lotteglogis-dg-19_V012BD0018_BONGO3.csv: 완료 (55,193행, 20.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 🔄 처리 시작: lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 52.3% | 성공: 97 | 실패: 60 | 예상 남은 시간: 4분 35.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66847)\u001b[0m 📦 lotteglogis-dg-7_V011BD0002_PORTER2_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 52.7% | 성공: 98 | 실패: 60 | 예상 남은 시간: 4분 33.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66615)\u001b[0m ✅ lijingice007_V000CA0038_ST1_202411.csv: 완료 (72,451행, 33.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m ✅ lotteglogis-dg-16_V011BD0001_PORTER2.csv: 완료 (94,610행, 27.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 🔄 처리 시작: ltgdg-12_V011BE0001_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 53.0% | 성공: 99 | 실패: 60 | 예상 남은 시간: 4분 33.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 📦 lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65609)\u001b[0m 📦 ltgdg-12_V011BE0001_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ✅ lotteglogis-dg-10_V011BD0005_PORTER2_202310.csv: 완료 (140,054행, 33.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 53.3% | 성공: 100 | 실패: 60 | 예상 남은 시간: 4분 31.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 53.7% | 성공: 101 | 실패: 60 | 예상 남은 시간: 4분 28.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66730)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: ltgdg-17_V012BE0016_BONGO3_2024.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 54.0% | 성공: 101 | 실패: 61 | 예상 남은 시간: 4분 25.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 54.3% | 성공: 102 | 실패: 61 | 예상 남은 시간: 4분 24.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66834)\u001b[0m 📦 ltgdg-13_V011BE0003_PORTER2_2024.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 54.7% | 성공: 103 | 실패: 61 | 예상 남은 시간: 4분 22.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m ✅ lotteglogis-dg-34_V011BD0010_PORTER2_202301.csv: 완료 (81,403행, 26.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66779)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 55.0% | 성공: 103 | 실패: 62 | 예상 남은 시간: 4분 19.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 🔄 처리 시작: ltgdg-21_V011BE0002_PORTER2_2024.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 55.3% | 성공: 104 | 실패: 62 | 예상 남은 시간: 4분 17.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 55.7% | 성공: 105 | 실패: 62 | 예상 남은 시간: 4분 16.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 ltgdg-18_V011BE0009_PORTER2_2023.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ✅ ltgdg-14_V012BE0013_BONGO3_2022.csv: 완료 (16,822행, 6.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m 🔄 처리 시작: ltgdg-24_V012BE0023_BONGO3_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 56.0% | 성공: 106 | 실패: 62 | 예상 남은 시간: 4분 14.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 56.3% | 성공: 107 | 실패: 62 | 예상 남은 시간: 4분 12.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 56.7% | 성공: 107 | 실패: 63 | 예상 남은 시간: 4분 9.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m 📦 ltgdg-24_V012BE0023_BONGO3_2022.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ✅ lotteglogis-dg-8_V011BD0003_PORTER2_202308.csv: 완료 (97,769행, 26.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65609)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67008)\u001b[0m 🔄 처리 시작: ltgdg-33_V011BE0006_PORTER2_2023.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 57.0% | 성공: 108 | 실패: 63 | 예상 남은 시간: 4분 8.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 📦 ltgdg-3_V011BE0005_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66834)\u001b[0m ✅ ltgdg-13_V011BE0003_PORTER2_2024.csv: 완료 (85,518행, 22.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 57.3% | 성공: 109 | 실패: 63 | 예상 남은 시간: 4분 7.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m ✅ ltgdg-24_V012BE0023_BONGO3_2022.csv: 완료 (20,744행, 10.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m 🔄 처리 시작: ltgdg-5_V011BE0008_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 57.7% | 성공: 109 | 실패: 64 | 예상 남은 시간: 4분 5.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 58.0% | 성공: 110 | 실패: 64 | 예상 남은 시간: 4분 6.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m 📦 ltgyc-3_V011BE0011_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m 🔄 처리 시작: ltgyc-3_V011BE0011_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ ltgdg-18_V011BE0009_PORTER2_2023.csv: 완료 (103,280행, 28.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 58.3% | 성공: 110 | 실패: 65 | 예상 남은 시간: 4분 3.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 58.7% | 성공: 110 | 실패: 66 | 예상 남은 시간: 3분 59.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 59.0% | 성공: 111 | 실패: 66 | 예상 남은 시간: 3분 57.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 🔄 처리 시작: mailhera_V000CE0019_PORTER2_202307.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67008)\u001b[0m ✅ ltgdg-33_V011BE0006_PORTER2_2023.csv: 완료 (39,530행, 19.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 59.3% | 성공: 112 | 실패: 66 | 예상 남은 시간: 3분 58.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 📦 mailhera_V000CE0019_PORTER2_202307.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 59.7% | 성공: 113 | 실패: 66 | 예상 남은 시간: 3분 55.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 60.0% | 성공: 114 | 실패: 66 | 예상 남은 시간: 3분 52.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66215)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 60.3% | 성공: 115 | 실패: 66 | 예상 남은 시간: 3분 50.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 60.7% | 성공: 115 | 실패: 67 | 예상 남은 시간: 3분 48.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 61.0% | 성공: 115 | 실패: 68 | 예상 남은 시간: 3분 45.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m 🔄 처리 시작: maxcom3_V021BA0000_EV9_202312.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ✅ ltgdg-3_V011BE0005_PORTER2_2023.csv: 완료 (79,762행, 24.0초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m 📦 mkj2449_V000BL0009_IONIQ5 LONGRANGE_202110.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 61.3% | 성공: 116 | 실패: 68 | 예상 남은 시간: 3분 42.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 61.7% | 성공: 117 | 실패: 68 | 예상 남은 시간: 3분 39.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66953)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m 🔄 처리 시작: naeibbo_V000CD0025_BONGO3_202406.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ✅ ltgdg-5_V011BE0008_PORTER2_2023.csv: 완료 (35,665행, 19.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m 📦 mxri13_V015BK0000_GV60_202307.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67008)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 62.0% | 성공: 118 | 실패: 68 | 예상 남은 시간: 3분 42.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m 📦 naeibbo_V000CD0025_BONGO3_202406.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66215)\u001b[0m ✅ man8243_V000BL0007_IONIQ5 LONGRANGE_202204.csv: 완료 (18,649행, 14.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67173)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 62.3% | 성공: 119 | 실패: 68 | 예상 남은 시간: 3분 41.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66730)\u001b[0m 📦 myhkk1797_V000BI0003_EV3 LONGRANGE_202402.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 🔄 처리 시작: needman_V004BI0002_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 62.7% | 성공: 119 | 실패: 69 | 예상 남은 시간: 3분 38.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 63.0% | 성공: 120 | 실패: 69 | 예상 남은 시간: 3분 36.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66561)\u001b[0m ✅ mkj2449_V000BL0009_IONIQ5 LONGRANGE_202110.csv: 완료 (19,108행, 17.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=66779)\u001b[0m 📦 needman_V004BI0002_EV6 LONGRANGE_202403.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: nukesub_V000CE0014_EV3 LONGRANGE_202504.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 63.3% | 성공: 121 | 실패: 69 | 예상 남은 시간: 3분 35.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67303)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ✅ nukesub_V000CE0014_EV3 LONGRANGE_202504.csv: 완료 (9,044행, 4.3초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 63.7% | 성공: 122 | 실패: 69 | 예상 남은 시간: 3분 34.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ lyj6081_V000CB0067_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (59,831행, 35.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: parksw7022_V000CD0033_IONIQ6 STANDARD_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 64.0% | 성공: 123 | 실패: 69 | 예상 남은 시간: 3분 32.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67155)\u001b[0m ✅ musein_V000CB0096_EV9_202404.csv: 완료 (42,694행, 25.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 📦 parksw7022_V000CD0033_IONIQ6 STANDARD_202502.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 64.3% | 성공: 124 | 실패: 69 | 예상 남은 시간: 3분 32.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ✅ naeibbo_V000CD0025_BONGO3_202406.csv: 완료 (116,268행, 30.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m 🔄 처리 시작: pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 📦 ocs7777_V000CA0039_ST1_202407.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 64.7% | 성공: 125 | 실패: 69 | 예상 남은 시간: 3분 31.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 65.0% | 성공: 126 | 실패: 69 | 예상 남은 시간: 3분 28.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m 📦 pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 65.3% | 성공: 127 | 실패: 69 | 예상 남은 시간: 3분 27.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ✅ ntragic_V004CA0000_EV6 LONGRANGE_202005.csv: 완료 (28,533행, 20.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m 🔄 처리 시작: pgtaxi-16_V004BL0002_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67355)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 🔄 처리 시작: pgtaxi-17_V003BL0003_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 65.7% | 성공: 127 | 실패: 70 | 예상 남은 시간: 3분 24.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 🔄 처리 시작: pgtaxi-4_V013BL0001_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 66.0% | 성공: 128 | 실패: 70 | 예상 남은 시간: 3분 22.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: pity2002_V000CA0010_IONIQ5 LONGRANGE_202111.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 66.3% | 성공: 128 | 실패: 71 | 예상 남은 시간: 3분 19.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 66.7% | 성공: 128 | 실패: 72 | 예상 남은 시간: 3분 16.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 📦 polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 67.0% | 성공: 129 | 실패: 72 | 예상 남은 시간: 3분 13.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 67.3% | 성공: 130 | 실패: 72 | 예상 남은 시간: 3분 11.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m 📦 pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: printo2000_V000CB0100_PORTER2_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 📦 printo2000_V000CB0100_PORTER2_202210.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ✅ polarbar_V013BL0000_IONIQ6 LONGRANGE_202207.csv: 완료 (2,101행, 2.4초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: pmkp37_V000CB0033_IONIQ5 LONGRANGE 2022_202309.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=66730)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m 🔄 처리 시작: pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m 🔄 처리 시작: pyh8965_EV6 LONGRANGE_202406.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 67.7% | 성공: 130 | 실패: 73 | 예상 남은 시간: 3분 10.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m 🔄 처리 시작: relier_V018AL0000_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m 📦 relier_V018AL0000_NIRO2_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 📦 pgtaxi-4_V013BL0001_IONIQ6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 68.0% | 성공: 131 | 실패: 73 | 예상 남은 시간: 3분 9.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67392)\u001b[0m ✅ pgtaxi-5_V007BL0000_NIRO LONGRANGE.csv: 완료 (24,499행, 10.6초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 68.3% | 성공: 132 | 실패: 73 | 예상 남은 시간: 3분 7.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 68.7% | 성공: 132 | 실패: 74 | 예상 남은 시간: 3분 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ✅ printo2000_V000CB0100_PORTER2_202210.csv: 완료 (22,462행, 9.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: reviewshare-4_V009BH0001_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: reviewshare-7_V009BH0002_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 69.0% | 성공: 132 | 실패: 75 | 예상 남은 시간: 3분 1.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67472)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 🔄 처리 시작: revu-n-11_V009BL0006_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 📦 revu-n-11_V009BL0006_KONA LONGRANGE_202104.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m 🔄 처리 시작: revu-n-12_V000BE0012_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 69.3% | 성공: 132 | 실패: 76 | 예상 남은 시간: 3분 1.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m 🔄 처리 시작: revu-n-15_V004BE0002_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ parkee82_V000CC0011_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (54,857행, 33.9초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 69.7% | 성공: 133 | 실패: 76 | 예상 남은 시간: 2분 58.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 70.0% | 성공: 134 | 실패: 76 | 예상 남은 시간: 2분 55.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ✅ ocs7777_V000CA0039_ST1_202407.csv: 완료 (70,461행, 34.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m 📦 revu-n-15_V004BE0002_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 revu-n-18_V012BE0040_BONGO3.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 70.3% | 성공: 135 | 실패: 76 | 예상 남은 시간: 2분 53.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67022)\u001b[0m ✅ pgtaxi-15_V013BL0002_IONIQ6 LONGRANGE.csv: 완료 (34,492행, 26.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67517)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m 🔄 처리 시작: revu-n-21_V021BE0004_EV9.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 🔄 처리 시작: revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 70.7% | 성공: 136 | 실패: 76 | 예상 남은 시간: 2분 52.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: revu-n-22_V004BE0008_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 71.0% | 성공: 137 | 실패: 76 | 예상 남은 시간: 2분 50.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 📦 revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67156)\u001b[0m ✅ pgtaxi-16_V004BL0002_EV6 LONGRANGE.csv: 완료 (45,676행, 29.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ✅ relier_V018AL0000_NIRO2_202207.csv: 완료 (37,437행, 17.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m 📦 revu-n-23_V004BE0004_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 71.3% | 성공: 138 | 실패: 76 | 예상 남은 시간: 2분 49.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m 🔄 처리 시작: revu-n-23_V004BE0004_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 71.7% | 성공: 139 | 실패: 76 | 예상 남은 시간: 2분 46.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m 📦 revu-n-21_V021BE0004_EV9.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 72.0% | 성공: 140 | 실패: 76 | 예상 남은 시간: 2분 44.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ✅ revu-n-15_V004BE0002_EV6 LONGRANGE.csv: 완료 (17,605행, 13.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m 🔄 처리 시작: revu-n-25_V018BE0000_NIRO2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ revu-n-18_V012BE0040_BONGO3.csv: 완료 (27,007행, 11.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: revu-n-32_V004BE0011_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 📦 revu-n-22_V004BE0008_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 72.3% | 성공: 141 | 실패: 76 | 예상 남은 시간: 2분 42.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 72.7% | 성공: 141 | 실패: 77 | 예상 남은 시간: 2분 39.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 73.0% | 성공: 141 | 실패: 78 | 예상 남은 시간: 2분 37.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 🔄 처리 시작: revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 73.3% | 성공: 142 | 실패: 78 | 예상 남은 시간: 2분 35.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 📦 revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 📦 revu-n-32_V004BE0011_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m 📦 revu-n-27_V021BE0000_EV9.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67248)\u001b[0m ✅ revu-n-23_V004BE0004_EV6 LONGRANGE.csv: 완료 (7,296행, 8.6초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m 🔄 처리 시작: revu-n-35_V016BF0000_GV70.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: revu-n-39_V004BF0003_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ✅ revu-n-25_V018BE0000_NIRO2_202401.csv: 완료 (7,959행, 5.5초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 73.7% | 성공: 143 | 실패: 78 | 예상 남은 시간: 2분 33.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m 🔄 처리 시작: revu-n-41_V004BF0002_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 74.0% | 성공: 143 | 실패: 79 | 예상 남은 시간: 2분 30.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 74.3% | 성공: 143 | 실패: 80 | 예상 남은 시간: 2분 28.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 74.7% | 성공: 143 | 실패: 81 | 예상 남은 시간: 2분 25.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 75.0% | 성공: 143 | 실패: 82 | 예상 남은 시간: 2분 23.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 75.3% | 성공: 143 | 실패: 83 | 예상 남은 시간: 2분 20.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 75.7% | 성공: 143 | 실패: 84 | 예상 남은 시간: 2분 18.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 76.0% | 성공: 143 | 실패: 85 | 예상 남은 시간: 2분 15.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: revu-n-57_V003BG0001_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 76.3% | 성공: 144 | 실패: 85 | 예상 남은 시간: 2분 14.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: revu-n-54_V004BG0000_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67355)\u001b[0m ✅ revu-n-38_V003BF0002_IONIQ5 LONGRANGE 2022.csv: 완료 (13,283행, 8.5초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 76.7% | 성공: 145 | 실패: 85 | 예상 남은 시간: 2분 12.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ✅ revu-n-20_V000BE0020_IONIQ5 LONGRANGE.csv: 완료 (50,981행, 23.8초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67303)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 🔄 처리 시작: revu-n-66_V004BH0002_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 📦 revu-n-64_V004BG0004_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 📦 revu-n-66_V004BH0002_EV6 LONGRANGE_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: revu-n-64_V004BG0004_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67593)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ✅ revu-n-21_V021BE0004_EV9.csv: 완료 (84,832행, 27.8초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 77.0% | 성공: 146 | 실패: 85 | 예상 남은 시간: 2분 12.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 77.3% | 성공: 146 | 실패: 86 | 예상 남은 시간: 2분 9.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m 🔄 처리 시작: revu-n-68_V004BH0000_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m 🔄 처리 시작: revu-n-69_V004BH0001_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m 📦 revu-n-69_V004BH0001_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 77.7% | 성공: 147 | 실패: 86 | 예상 남은 시간: 2분 8.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67250)\u001b[0m ✅ revu-n-27_V021BE0000_EV9.csv: 완료 (39,943행, 23.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m 🔄 처리 시작: revu-n-70_V009BH0000_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 78.0% | 성공: 148 | 실패: 86 | 예상 남은 시간: 2분 6.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ✅ revu-n-32_V004BE0011_EV6 LONGRANGE.csv: 완료 (47,100행, 26.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: revu-n-8_V016BE0001_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 78.3% | 성공: 148 | 실패: 87 | 예상 남은 시간: 2분 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: revu-n-9_V000BE0009_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 78.7% | 성공: 148 | 실패: 88 | 예상 남은 시간: 2분 2.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: revu-u-2_V000BE0029_IONIQ5 LONGRANGE_202101.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 79.0% | 성공: 148 | 실패: 89 | 예상 남은 시간: 1분 59.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 79.3% | 성공: 149 | 실패: 89 | 예상 남은 시간: 1분 57.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m 📦 revu-n-70_V009BH0000_KONA LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 79.7% | 성공: 150 | 실패: 89 | 예상 남은 시간: 1분 55.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 📦 revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 80.0% | 성공: 151 | 실패: 89 | 예상 남은 시간: 1분 53.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 80.3% | 성공: 152 | 실패: 89 | 예상 남은 시간: 1분 51.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67472)\u001b[0m ✅ revu-n-41_V004BF0002_EV6 LONGRANGE.csv: 완료 (40,943행, 25.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: rwww87_V000CB0006_EV6 LONGRANGE_202311.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67770)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ s112661140_V004CA0002_EV6 LONGRANGE_202205.csv: 완료 (225행, 0.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 80.7% | 성공: 153 | 실패: 89 | 예상 남은 시간: 1분 49.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 📦 rwww87_V000CB0006_EV6 LONGRANGE_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 81.0% | 성공: 154 | 실패: 89 | 예상 남은 시간: 1분 47.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 81.3% | 성공: 155 | 실패: 89 | 예상 남은 시간: 1분 45.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 🔄 처리 시작: sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 81.7% | 성공: 156 | 실패: 89 | 예상 남은 시간: 1분 43.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 82.0% | 성공: 157 | 실패: 89 | 예상 남은 시간: 1분 41.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ revu-n-63_V000BG0012_IONIQ5 LONGRANGE.csv: 완료 (52,478행, 26.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m 🔄 처리 시작: shcs111_V009BL0001_KONA LONGRANGE_201809.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ✅ revu-u-5_V000BE0032_IONIQ5 LONGRANGE_202201.csv: 완료 (9,963행, 9.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67517)\u001b[0m ✅ revu-n-69_V004BH0001_EV6 LONGRANGE.csv: 완료 (29,150행, 18.8초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 82.3% | 성공: 158 | 실패: 89 | 예상 남은 시간: 1분 39.3초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 82.7% | 성공: 158 | 실패: 90 | 예상 남은 시간: 1분 37.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m 🔄 처리 시작: shome_SOUL LONGRANGE_201901.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m 📦 sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m 📦 shcs111_V009BL0001_KONA LONGRANGE_201809.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 83.0% | 성공: 159 | 실패: 90 | 예상 남은 시간: 1분 35.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ s2love1003_V000CB0069_THE NEW IONIQ5 LONGRANGE_202409.csv: 완료 (12,949행, 9.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 83.3% | 성공: 159 | 실패: 91 | 예상 남은 시간: 1분 33.4초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 83.7% | 성공: 159 | 실패: 92 | 예상 남은 시간: 1분 31.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 84.0% | 성공: 160 | 실패: 92 | 예상 남은 시간: 1분 29.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 84.3% | 성공: 160 | 실패: 93 | 예상 남은 시간: 1분 26.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: smra1999_V000CB0039_EV9_202401.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ✅ rlaxo120_V009BL0003_KONA LONGRANGE_201811.csv: 완료 (35,851행, 15.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ✅ revu-n-70_V009BH0000_KONA LONGRANGE.csv: 완료 (48,341행, 14.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 sl-ev-1_V004BE0009_EV6 LONGRANGE_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: sosanamu_V000CC0062_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 84.7% | 성공: 161 | 실패: 93 | 예상 남은 시간: 1분 25.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67809)\u001b[0m ✅ shcs111_V009BL0001_KONA LONGRANGE_201809.csv: 완료 (28,868행, 12.7초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 85.0% | 성공: 162 | 실패: 93 | 예상 남은 시간: 1분 23.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67250)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 🔄 처리 시작: ssa1011_V022AK0000_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 🔄 처리 시작: stock_V021BI0001_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 📦 sitestev6_SITESTEV6_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 📦 ssa1011_V022AK0000_KONA LONGRANGE 2세대_202301.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 85.3% | 성공: 163 | 실패: 93 | 예상 남은 시간: 1분 22.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 📦 stock_V021BI0001_EV9_202307.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ✅ rwww87_V000CB0006_EV6 LONGRANGE_202311.csv: 완료 (38,584행, 23.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: sunghyun_V000CC0066_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67809)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 85.7% | 성공: 164 | 실패: 93 | 예상 남은 시간: 1분 21.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 📦 sunghyun_V000CC0066_BONGO3_202412.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ✅ sosanamu_V000CC0062_NIRO LONGRANGE_201902.csv: 완료 (34,851행, 19.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: taerok_V000CA0020_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 86.0% | 성공: 165 | 실패: 93 | 예상 남은 시간: 1분 19.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ✅ ssa1011_V022AK0000_KONA LONGRANGE 2세대_202301.csv: 완료 (29,422행, 11.5초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 86.3% | 성공: 166 | 실패: 93 | 예상 남은 시간: 1분 17.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 📦 taerok_V000CA0020_KONA LONGRANGE_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 86.7% | 성공: 167 | 실패: 93 | 예상 남은 시간: 1분 15.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ✅ side3150_V000CD0078_IONIQ6 LONGRANGE_202312.csv: 완료 (44,111행, 24.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m 🔄 처리 시작: testbongo_TESTBONGO_BONGO3_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67303)\u001b[0m ✅ sbk5611_V003CA0001_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (67,221행, 29.9초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 87.0% | 성공: 168 | 실패: 93 | 예상 남은 시간: 1분 13.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m 📦 testbongo_TESTBONGO_BONGO3_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m ✅ testbongo_TESTBONGO_BONGO3_202201.csv: 완료 (8,793행, 3.0초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 87.3% | 성공: 169 | 실패: 93 | 예상 남은 시간: 1분 11.9초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 87.7% | 성공: 170 | 실패: 93 | 예상 남은 시간: 1분 9.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 88.0% | 성공: 171 | 실패: 93 | 예상 남은 시간: 1분 7.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 88.3% | 성공: 172 | 실패: 93 | 예상 남은 시간: 1분 5.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67770)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 📦 tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ✅ stock_V021BI0001_EV9_202307.csv: 완료 (40,366행, 22.9초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 88.7% | 성공: 173 | 실패: 93 | 예상 남은 시간: 1분 4.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: ty3951_V000CC0070_EV6 LONGRANGE_202408.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 89.0% | 성공: 174 | 실패: 93 | 예상 남은 시간: 1분 2.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 📦 uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 📦 ty3951_V000CC0070_EV6 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67731)\u001b[0m ✅ test01_TESTNIRO01_NIRO PLUS_202201.csv: 완료 (35,911행, 17.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 89.3% | 성공: 175 | 실패: 93 | 예상 남은 시간: 1분 0.5초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 89.7% | 성공: 176 | 실패: 93 | 예상 남은 시간: 58.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=65860)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 🔄 처리 시작: vunyvuny2_V003CE0000_SOUL LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 90.0% | 성공: 177 | 실패: 93 | 예상 남은 시간: 56.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m 🔄 처리 시작: wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m 📦 vunyvuny2_V003CE0000_SOUL LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m 🔄 처리 시작: wce4122_V000CB0008_EV6 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 90.3% | 성공: 178 | 실패: 93 | 예상 남은 시간: 54.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m 📦 vitadoice11_V000CC0085_IONIQ5 LONGRANGE_202106.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67972)\u001b[0m ✅ testev9_TESTEV9_EV9_2023.csv: 완료 (29,057행, 15.8초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 🔄 처리 시작: whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 90.7% | 성공: 179 | 실패: 93 | 예상 남은 시간: 52.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=65860)\u001b[0m ✅ vunyvuny2_V003CE0000_SOUL LONGRANGE.csv: 완료 (13,170행, 6.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m 📦 wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m 📦 wce4122_V000CB0008_EV6 LONGRANGE_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 📦 whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 91.0% | 성공: 180 | 실패: 93 | 예상 남은 시간: 51.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ✅ tlsqjatjq628_V000CC0081_EV3 LONGRANGE_202408.csv: 완료 (50,013행, 20.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: wildseven_V000CD0027_SOUL LONGRANGE_201906.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=68131)\u001b[0m 📦 win7102_V000CE0017_EV3 LONGRANGE_202503.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68131)\u001b[0m 🔄 처리 시작: win7102_V000CE0017_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 91.3% | 성공: 181 | 실패: 93 | 예상 남은 시간: 49.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m ✅ wildseven_V000CD0027_SOUL LONGRANGE_201906.csv: 완료 (10,810행, 7.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 🔄 처리 시작: wjs4156_V000CD0077_EV3 STANDARD_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67972)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67516)\u001b[0m 📦 wjs4156_V000CD0077_EV3 STANDARD_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 91.7% | 성공: 182 | 실패: 93 | 예상 남은 시간: 48.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 92.0% | 성공: 183 | 실패: 93 | 예상 남은 시간: 46.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ✅ ty3951_V000CC0070_EV6 LONGRANGE_202408.csv: 완료 (36,415행, 28.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ✅ uk22da_V000CD0037_IONIQ5 LONGRANGE 2022_202312.csv: 완료 (46,171행, 29.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68212)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 92.3% | 성공: 183 | 실패: 94 | 예상 남은 시간: 44.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 92.7% | 성공: 183 | 실패: 95 | 예상 남은 시간: 42.1초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 93.0% | 성공: 183 | 실패: 96 | 예상 남은 시간: 40.0초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 93.3% | 성공: 183 | 실패: 97 | 예상 남은 시간: 38.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 📦 wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 93.7% | 성공: 184 | 실패: 97 | 예상 남은 시간: 36.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67542)\u001b[0m ✅ vitadoice11_V000CC0085_IONIQ5 LONGRANGE_202106.csv: 완료 (35,354행, 28.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 94.0% | 성공: 184 | 실패: 98 | 예상 남은 시간: 34.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yitaxi-10_V03BA0032_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 94.3% | 성공: 184 | 실패: 99 | 예상 남은 시간: 32.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 94.7% | 성공: 184 | 실패: 100 | 예상 남은 시간: 30.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yitaxi-1_V03BA0023_EV6 LONGRANGE_202209.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yitaxi-2_V03BA0024_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 95.0% | 성공: 184 | 실패: 101 | 예상 남은 시간: 28.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 95.3% | 성공: 184 | 실패: 102 | 예상 남은 시간: 26.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 95.7% | 성공: 184 | 실패: 103 | 예상 남은 시간: 24.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yitaxi-5_V03BA0027_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 96.0% | 성공: 184 | 실패: 104 | 예상 남은 시간: 22.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yitaxi-9_V03BA0031_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 96.3% | 성공: 184 | 실패: 105 | 예상 남은 시간: 20.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 🔄 처리 시작: yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 96.7% | 성공: 185 | 실패: 105 | 예상 남은 시간: 18.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68212)\u001b[0m 📦 xlos20_V004AK0000_EV6 LONGRANGE_202101.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68025)\u001b[0m ✅ wer007_V000CD0079_THE NEW IONIQ5 LONGRANGE_202504.csv: 완료 (48,260행, 31.3초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 97.0% | 성공: 186 | 실패: 105 | 예상 남은 시간: 16.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=67542)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ✅ wntjdgml_V000CA0008_CASPER LONGRANGE_202408.csv: 완료 (19,822행, 8.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ✅ whote564_V000CD0095_IONIQ5 LONGRANGE 2022_202311.csv: 완료 (45,543행, 29.6초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 97.3% | 성공: 187 | 실패: 105 | 예상 남은 시간: 14.8초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 97.7% | 성공: 187 | 실패: 106 | 예상 남은 시간: 12.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 🔄 처리 시작: yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 🔄 처리 시작: zoh71z_V009BL0000_KONA LONGRANGE_201810.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 98.0% | 성공: 188 | 실패: 106 | 예상 남은 시간: 11.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68077)\u001b[0m ✅ wce4122_V000CB0008_EV6 LONGRANGE_202110.csv: 완료 (43,276행, 32.8초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 98.3% | 성공: 189 | 실패: 106 | 예상 남은 시간: 9.2초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 98.7% | 성공: 190 | 실패: 106 | 예상 남은 시간: 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m 📦 zoh71z_V009BL0000_KONA LONGRANGE_201810.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m 📦 yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68131)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=67883)\u001b[0m ✅ zoh71z_V009BL0000_KONA LONGRANGE_201810.csv: 완료 (50,678행, 11.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m 📦 yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 99.0% | 성공: 191 | 실패: 106 | 예상 남은 시간: 5.6초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 99.3% | 성공: 192 | 실패: 106 | 예상 남은 시간: 3.7초\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 99.7% | 성공: 193 | 실패: 106 | 예상 남은 시간: 1.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=68212)\u001b[0m ✅ xlos20_V004AK0000_EV6 LONGRANGE_202101.csv: 완료 (37,783행, 21.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67665)\u001b[0m ✅ yousjun_V003BA0012_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (57,775행, 19.4초)\n",
      "\u001b[36m(ProgressTracker pid=65065)\u001b[0m 📊 진행률: 100.0% | 성공: 194 | 실패: 106 | 예상 남은 시간: 0.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=67770)\u001b[0m ✅ yjtaxi-6_V003AL0003_IONIQ5 LONGRANGE 2022_202211.csv: 완료 (119,165행, 28.3초)\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 194개 | ❌ 실패: 106개\n",
      "📊 총 처리 행 수: 8,626,476행\n",
      "⏱️  총 소요시간: 9분 25.5초\n",
      "⚡ 평균 파일당: 1.9초\n",
      "\n",
      "❌ 실패한 파일들:\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 9분 25.5초\n",
      "   - 파일당 평균: 1.9초\n",
      "   - 성공률: 64.7%\n",
      "   - 총 처리 행 수: 8,626,476행\n",
      "   - 시간당 처리량: 54916570행/시간\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=68077)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/532998891.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 사용 예시\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV 파일 리스트 (실제 파일 경로로 수정하세요)\n",
    "    # csv_files = [\n",
    "    #     # \"/path/to/your/file1.csv\",\n",
    "    #     # \"/path/to/your/file2.csv\",\n",
    "    #     # 또는 glob 패턴 사용:\n",
    "    #     # *glob.glob(\"/path/to/your/data/*.csv\")\n",
    "    # ]\n",
    "    \n",
    "    csv_files = csv_files = glob.glob(\"/Volumes/Data/betterwhy_origin/20250716_0722(300대)/**/*.csv\", recursive=True)\n",
    "    # 병렬 처리 실행 (CPU 코어 수의 80% 사용)\n",
    "    results = process_multiple_files_parallel(\n",
    "        csv_files=csv_files,\n",
    "        output_dir=\"/Volumes/Data/betterwhy_processed\",\n",
    "        remove_duplicates=True,\n",
    "        max_workers=None  # None이면 자동으로 CPU 코어 수의 80% 사용\n",
    "    )\n",
    "    \n",
    "    # 결과 분석\n",
    "    if results:\n",
    "        print(f\"\\n📊 최종 처리 통계:\")\n",
    "        print(f\"   - 총 처리 시간: {format_duration(results['total_duration'])}\")\n",
    "        print(f\"   - 파일당 평균: {format_duration(results['avg_duration_per_file'])}\")\n",
    "        print(f\"   - 성공률: {(results['successful']/results['total_files']*100):.1f}%\")\n",
    "        print(f\"   - 총 처리 행 수: {results['total_rows_processed']:,}행\")\n",
    "        print(f\"   - 시간당 처리량: {results['total_rows_processed']/(results['total_duration']/3600):.0f}행/시간\")\n",
    "    \n",
    "    # Ray 종료\n",
    "    ray.shutdown()\n",
    "    print(\"🔚 Ray 종료 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5eb187ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 36개의 폴더를 찾았습니다.\n",
      "찾은 폴더 목록:\n",
      "/Volumes/Data/betterwhy_origin/20250514_0520(추가_20대)\n",
      "/Volumes/Data/betterwhy_origin/20250319_0325(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250611_0617(추가_20대)\n",
      "/Volumes/Data/betterwhy_origin/20250514_0520(260대)\n",
      "/Volumes/Data/betterwhy_origin/20250226_0304(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250430_0506(추가_20대)\n",
      "/Volumes/Data/betterwhy_origin/20250702_0708(300대)\n",
      "/Volumes/Data/betterwhy_origin/20250423_0429(240대)\n",
      "/Volumes/Data/betterwhy_origin/20250604_0610(280대)\n",
      "/Volumes/Data/betterwhy_origin/20250409_0415(추가_20대)\n",
      "/Volumes/Data/betterwhy_origin/20250618_0624(300대)\n",
      "/Volumes/Data/betterwhy_origin/20250326_0401(추가_20대)\n",
      "/Volumes/Data/betterwhy_origin/20250409_0415(220대)\n",
      "/Volumes/Data/betterwhy_origin/20250625_0701(300대)\n",
      "/Volumes/Data/betterwhy_origin/20250108_0114(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250219_0225(200대_2대는_교체)\n",
      "/Volumes/Data/betterwhy_origin/20250528_0603(280대)\n",
      "/Volumes/Data/betterwhy_origin/20250416_0422(240대)\n",
      "/Volumes/Data/betterwhy_origin/20250430_0506(240대)\n",
      "/Volumes/Data/betterwhy_origin/20250521_0527(280대)\n",
      "/Volumes/Data/betterwhy_origin/20250326_0401(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250129_0204(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250101_0107(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250507_0513(260대)\n",
      "/Volumes/Data/betterwhy_origin/20250212_0218(199대_3대는_교체)\n",
      "/Volumes/Data/betterwhy_origin/20250402_0408(220대)\n",
      "/Volumes/Data/betterwhy_origin/20250205_0211(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250115_0121(200대_62대는_교체)\n",
      "/Volumes/Data/betterwhy_origin/20250312_0318(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250611_0617(280대)\n",
      "/Volumes/Data/betterwhy_origin/20250305_0311(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250122_0128(200대)\n",
      "/Volumes/Data/betterwhy_origin/20250723_0730(320대)\n",
      "/Volumes/Data/betterwhy_origin/20250709_0715(300대)\n",
      "/Volumes/Data/betterwhy_origin/20250716_0722(300대)\n",
      "/Volumes/Data/betterwhy_origin/20250723(추가20대)\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "# 검색할 기본 경로\n",
    "base_path = '/Volumes/Data/betterwhy_origin'\n",
    "\n",
    "# '2025'로 시작하는 폴더를 찾는 패턴\n",
    "search_pattern = os.path.join(base_path, '2025*')\n",
    "\n",
    "# glob.glob() 함수를 사용해 패턴에 맞는 모든 경로를 가져온 후,\n",
    "# os.path.isdir() 함수로 폴더만 필터링하여 리스트에 담습니다.\n",
    "folder_list = [f for f in glob.glob(search_pattern) if os.path.isdir(f)]\n",
    "\n",
    "# 결과 확인\n",
    "if folder_list:\n",
    "    print(f\"총 {len(folder_list)}개의 폴더를 찾았습니다.\")\n",
    "    print(\"찾은 폴더 목록:\")\n",
    "    for folder in folder_list:\n",
    "        print(folder)\n",
    "else:\n",
    "    print(\"해당하는 폴더를 찾지 못했습니다.\")\n",
    "\n",
    "# 이제 'folder_list' 변수에 '2025'로 시작하는 폴더들의 경로가 리스트 형태로 담겨 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73542776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:15:24,296\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 20개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m 🔄 처리 시작: smra1999_EV9_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m 🔄 처리 시작: day9672_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m 📦 9224_ST1_202411.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m 📦 day9672_IONIQ5 LONGRANGE 2022_202310.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m 🔄 처리 시작: 9224_ST1_202411.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70098)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m 📦 smra1999_EV9_202401.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 5.0% | 성공: 1 | 실패: 0 | 예상 남은 시간: 3분 55.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ✅ 9224_ST1_202411.csv: 완료 (7,794행, 10.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m 🔄 처리 시작: delpainus_IONIQ5 LONGRANGE 2022_202307.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70097)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 39x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m 📦 delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 10.0% | 성공: 2 | 실패: 0 | 예상 남은 시간: 3분 55.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m ✅ shcs111_KONA LONGRANGE_201809.csv: 완료 (23,497행, 25.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m 🔄 처리 시작: c1228kr_IONIQ5 LONGRANGE_202201.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70181)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m 🔄 처리 시작: wer007_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 파일 병합 중 오류 (Client V000CE0019): time data \"2025-07-16 11:38:27.141\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 15.0% | 성공: 3 | 실패: 0 | 예상 남은 시간: 2분 52.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m 📦 c1228kr_IONIQ5 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m 📦 wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 20.0% | 성공: 4 | 실패: 0 | 예상 남은 시간: 2분 17.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ✅ mailhera_PORTER2_202307.csv: 완료 (89,918행, 29.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ✅ smra1999_EV9_202401.csv: 완료 (83,084행, 33.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m 🔄 처리 시작: rwww87_EV6 LONGRANGE_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m 📦 rwww87_EV6 LONGRANGE_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70048)\u001b[0m ✅ delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 완료 (29,586행, 33.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 🔄 처리 시작: s112661140_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 📦 s112661140_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 25.0% | 성공: 5 | 실패: 0 | 예상 남은 시간: 2분 22.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70248)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m 🔄 처리 시작: nukesub_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m 📦 nukesub_EV3 LONGRANGE_202504.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 30.0% | 성공: 6 | 실패: 0 | 예상 남은 시간: 2분 21.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m ✅ babaliian_ST1_202407.csv: 완료 (37,908행, 59.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m 🔄 처리 시작: juhwan7455_EV3 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m 📦 juhwan7455_EV3 LONGRANGE_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70447)\u001b[0m 🔄 처리 시작: wjs4156_EV3 STANDARD_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 35.0% | 성공: 7 | 실패: 0 | 예상 남은 시간: 2분 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m ✅ korea1736_IONIQ5 LONGRANGE_202203.csv: 완료 (41,350행, 1분 7.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m 🔄 처리 시작: geni8895_BONGO3_202210.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 40.0% | 성공: 8 | 실패: 0 | 예상 남은 시간: 1분 43.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70057)\u001b[0m ✅ day9672_IONIQ5 LONGRANGE 2022_202310.csv: 완료 (35,277행, 1분 7.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70053)\u001b[0m 📦 geni8895_BONGO3_202210.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70057)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 45.0% | 성공: 9 | 실패: 0 | 예상 남은 시간: 1분 27.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 🔄 처리 시작: taerok_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m 📦 taerok_KONA LONGRANGE_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ✅ s112661140_EV6 LONGRANGE_202205.csv: 완료 (46,324행, 35.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m 🔄 처리 시작: heinzel_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 50.0% | 성공: 10 | 실패: 0 | 예상 남은 시간: 1분 15.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m ✅ wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 완료 (28,881행, 47.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70054)\u001b[0m ✅ jdisky_IONIQ5 LONGRANGE_202112.csv: 완료 (44,841행, 1분 14.5초)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 55.0% | 성공: 11 | 실패: 0 | 예상 남은 시간: 1분 2.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70181)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m 📦 heinzel_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m 🔄 처리 시작: side3150_IONIQ6 LONGRANGE_202312.csv\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 60.0% | 성공: 12 | 실패: 0 | 예상 남은 시간: 53.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70248)\u001b[0m ✅ nukesub_EV3 LONGRANGE_202504.csv: 완료 (20,514행, 30.5초)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 65.0% | 성공: 13 | 실패: 0 | 예상 남은 시간: 44.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70055)\u001b[0m ✅ c1228kr_IONIQ5 LONGRANGE_202201.csv: 완료 (35,968행, 56.8초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70055)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=70559)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 70.0% | 성공: 14 | 실패: 0 | 예상 남은 시간: 38.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70181)\u001b[0m 📦 side3150_IONIQ6 LONGRANGE_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70050)\u001b[0m ✅ rwww87_EV6 LONGRANGE_202311.csv: 완료 (36,781행, 56.3초)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 75.0% | 성공: 15 | 실패: 0 | 예상 남은 시간: 32.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70474)\u001b[0m ✅ heinzel_EV6 LONGRANGE_202205.csv: 완료 (41,942행, 22.7초)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 80.0% | 성공: 16 | 실패: 0 | 예상 남은 시간: 25.1초\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 85.0% | 성공: 17 | 실패: 0 | 예상 남은 시간: 18.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70052)\u001b[0m ✅ taerok_KONA LONGRANGE_202302.csv: 완료 (49,654행, 30.4초)\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 90.0% | 성공: 18 | 실패: 0 | 예상 남은 시간: 11.4초\n",
      "\u001b[36m(ProgressTracker pid=70049)\u001b[0m 📊 진행률: 95.0% | 성공: 19 | 실패: 0 | 예상 남은 시간: 5.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70051)\u001b[0m ✅ juhwan7455_EV3 LONGRANGE_202407.csv: 완료 (57,613행, 41.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 20개 | ❌ 실패: 0개\n",
      "📊 총 처리 행 수: 834,306행\n",
      "⏱️  총 소요시간: 1분 56.1초\n",
      "⚡ 평균 파일당: 5.8초\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 1분 56.1초\n",
      "   - 파일당 평균: 5.8초\n",
      "   - 성공률: 100.0%\n",
      "   - 총 처리 행 수: 834,306행\n",
      "   - 시간당 처리량: 25869559행/시간\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70447)\u001b[0m ✅ wjs4156_EV3 STANDARD_202502.csv: 완료 (39,115행, 35.7초)\n",
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:17:25,661\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 200개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: honeybto_GV60_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 0.5% | 성공: 0 | 실패: 1 | 예상 남은 시간: 3분 14.1초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 1.0% | 성공: 0 | 실패: 2 | 예상 남은 시간: 1분 36.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 📦 honeybto_GV60_202205.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=70784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 emob-1_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 🔄 처리 시작: alice2235_PORTER2_202201.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m 🔄 처리 시작: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m 📦 revu-n-12_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70824)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ✅ honeybto_GV60_202205.csv: 완료 (5,534행, 9.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m 📦 revu-n-68_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 1.5% | 성공: 1 | 실패: 2 | 예상 남은 시간: 12분 1.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 2.0% | 성공: 1 | 실패: 3 | 예상 남은 시간: 9분 19.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: revu-n-34_GV70.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 2.5% | 성공: 2 | 실패: 3 | 예상 남은 시간: 9분 8.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 📦 revu-n-34_GV70.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 3.0% | 성공: 3 | 실패: 3 | 예상 남은 시간: 9분 38.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70782)\u001b[0m ✅ ekfmd3152_KONA LONGRANGE_202004.csv: 완료 (20,791행, 13.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ alice2235_PORTER2_202201.csv: 완료 (59,561행, 16.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70885)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 🔄 처리 시작: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 📦 cjl-dgds-006_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m ✅ rlaxo120_KONA LONGRANGE_201811.csv: 완료 (20,341행, 23.1초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 3.5% | 성공: 4 | 실패: 3 | 예상 남은 시간: 11분 0.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70916)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 4.0% | 성공: 5 | 실패: 3 | 예상 남은 시간: 10분 54.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ✅ revu-n-68_EV6 LONGRANGE.csv: 완료 (43,281행, 25.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m 🔄 처리 시작: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m 📦 ajutaxi-27_IONIQ 2019_201701.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 4.5% | 성공: 6 | 실패: 3 | 예상 남은 시간: 10분 20.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m ✅ revu-n-12_IONIQ5 LONGRANGE_202201.csv: 완료 (62,585행, 28.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70780)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m 🔄 처리 시작: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 5.0% | 성공: 7 | 실패: 3 | 예상 남은 시간: 10분 22.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ emob-1_IONIQ5 LONGRANGE.csv: 완료 (42,507행, 33.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: ltgdg-18_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m 📦 ltgdg-14_BONGO3_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ✅ revu-n-34_GV70.csv: 완료 (45,680행, 21.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70783)\u001b[0m ✅ ajutaxi-27_IONIQ 2019_201701.csv: 완료 (13,913행, 6.6초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 5.5% | 성공: 8 | 실패: 3 | 예상 남은 시간: 9분 55.5초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 6.0% | 성공: 9 | 실패: 3 | 예상 남은 시간: 9분 3.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70783)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m 📦 revu-n-32_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 📦 ltgdg-18_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m 🔄 처리 시작: man8243_IONIQ5 LONGRANGE_202204.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71048)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 6.5% | 성공: 10 | 실패: 3 | 예상 남은 시간: 11분 59.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m 📦 man8243_IONIQ5 LONGRANGE_202204.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ✅ cjl-dgds-006_PORTER2.csv: 완료 (61,642행, 31.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 🔄 처리 시작: yitaxi-8_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 7.0% | 성공: 11 | 실패: 3 | 예상 남은 시간: 11분 40.3초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 7.5% | 성공: 12 | 실패: 3 | 예상 남은 시간: 10분 51.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 8.0% | 성공: 12 | 실패: 4 | 예상 남은 시간: 10분 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 revu-n-48_NIRO LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m 📦 pity2002_IONIQ5 LONGRANGE_202111.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ sihehe_NIRO2_202207.csv: 완료 (49,233행, 17.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m 🔄 처리 시작: pity2002_IONIQ5 LONGRANGE_202111.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m 파일 병합 중 오류 (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20173. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 8.5% | 성공: 13 | 실패: 4 | 예상 남은 시간: 10분 17.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71018)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 📦 yitaxi-8_EV6 LONGRANGE_202209.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ✅ ltgdg-18_PORTER2_2023.csv: 완료 (83,910행, 28.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m 🔄 처리 시작: junghun1155_EV6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 9.0% | 성공: 14 | 실패: 4 | 예상 남은 시간: 10분 21.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: stock_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ pgtaxi-15_IONIQ6 LONGRANGE.csv: 완료 (63,209행, 1분 0.7초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 9.5% | 성공: 15 | 실패: 4 | 예상 남은 시간: 9분 47.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: j227_KONA LONGRANGE 2세대_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 10.0% | 성공: 15 | 실패: 5 | 예상 남은 시간: 9분 17.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 10.5% | 성공: 16 | 실패: 5 | 예상 남은 시간: 9분 4.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 파일 병합 중 오류 (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 caifa0622_IONIQ5 LONGRANGE_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 📦 j227_KONA LONGRANGE 2세대_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 11.0% | 성공: 16 | 실패: 6 | 예상 남은 시간: 9분 20.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ revu-n-48_NIRO LONGRANGE.csv: 완료 (20,842행, 11.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 cjl-dgea-016_PORTER2.csv: 5개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70779)\u001b[0m ✅ pity2002_IONIQ5 LONGRANGE_202111.csv: 완료 (40,480행, 25.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 11.5% | 성공: 17 | 실패: 6 | 예상 남은 시간: 10분 6.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71254)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71254)\u001b[0m 🔄 처리 시작: lotteglogis-dg-19_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 12.0% | 성공: 18 | 실패: 6 | 예상 남은 시간: 10분 4.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ caifa0622_IONIQ5 LONGRANGE_202107.csv: 완료 (38,130행, 22.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 12.5% | 성공: 19 | 실패: 6 | 예상 남은 시간: 9분 47.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 📦 cjl-dgss-015_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 🔄 처리 시작: cjl-dgss-015_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: jskim_IONIQ5 LONGRANGE_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: ajutaxi-14_IONIQ5 STANDARD_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 13.0% | 성공: 19 | 실패: 7 | 예상 남은 시간: 9분 57.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 13.5% | 성공: 19 | 실패: 8 | 예상 남은 시간: 9분 33.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 cjl-dgss-013_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 14.0% | 성공: 20 | 실패: 8 | 예상 남은 시간: 10분 23.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70780)\u001b[0m ✅ revu-n-32_EV6 LONGRANGE.csv: 완료 (80,721행, 1분 9.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ✅ j227_KONA LONGRANGE 2세대_202311.csv: 완료 (60,370행, 40.3초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 14.5% | 성공: 21 | 실패: 8 | 예상 남은 시간: 10분 2.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70775)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 ajutaxi-4_IONIQ 2019_201801.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 🔄 처리 시작: jmmath_IONIQ5 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71430)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 15.0% | 성공: 21 | 실패: 9 | 예상 남은 시간: 10분 43.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m 📦 jmmath_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 🔄 처리 시작: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 🔄 처리 시작: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 15.5% | 성공: 22 | 실패: 9 | 예상 남은 시간: 10분 35.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71018)\u001b[0m ✅ junghun1155_EV6 LONGRANGE_202302.csv: 완료 (50,305행, 55.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 16.0% | 성공: 23 | 실패: 9 | 예상 남은 시간: 10분 26.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 📦 lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 16.5% | 성공: 24 | 실패: 9 | 예상 남은 시간: 10분 20.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71254)\u001b[0m ✅ lotteglogis-dg-19_BONGO3.csv: 완료 (87,475행, 37.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ ajutaxi-4_IONIQ 2019_201801.csv: 완료 (100,718행, 22.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m 🔄 처리 시작: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 revu-n-23_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 17.0% | 성공: 25 | 실패: 9 | 예상 남은 시간: 10분 7.8초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 17.5% | 성공: 26 | 실패: 9 | 예상 남은 시간: 9분 51.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 📦 ha8519_EV9_202401.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ cjl-dgss-013_PORTER2.csv: 완료 (84,945행, 35.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 🔄 처리 시작: ha8519_EV9_202401.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71547)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 18.0% | 성공: 27 | 실패: 9 | 예상 남은 시간: 9분 50.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ revu-n-23_EV6 LONGRANGE.csv: 완료 (5,304행, 6.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 testbongo_BONGO3_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 18.5% | 성공: 28 | 실패: 9 | 예상 남은 시간: 9분 59.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ cjl-dgea-016_PORTER2.csv: 완료 (143,031행, 1분 6.8초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: test01_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 19.0% | 성공: 28 | 실패: 10 | 예상 남은 시간: 9분 43.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: cyberlmk_EV9_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m 파일 병합 중 오류 (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 19.5% | 성공: 29 | 실패: 10 | 예상 남은 시간: 9분 37.8초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 20.0% | 성공: 29 | 실패: 11 | 예상 남은 시간: 9분 21.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m 🔄 처리 시작: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 cyberlmk_EV9_202308.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71509)\u001b[0m ✅ lotteglogis-dg-2_BONGO3.csv: 완료 (70,532행, 16.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m 📦 revu-n-15_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m 🔄 처리 시작: polarbar_IONIQ6 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71509)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 20.5% | 성공: 30 | 실패: 11 | 예상 남은 시간: 9분 18.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ✅ lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (85,002행, 30.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 🔄 처리 시작: k2elryu_G80_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 21.0% | 성공: 30 | 실패: 12 | 예상 남은 시간: 9분 2.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 🔄 처리 시작: test01_NIRO PLUS_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 완료 (16,295행, 16.6초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 21.5% | 성공: 31 | 실패: 12 | 예상 남은 시간: 8분 48.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 22.0% | 성공: 32 | 실패: 12 | 예상 남은 시간: 8분 34.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ dufdl1025_EV6 LONGRANGE_202404.csv: 완료 (142,456행, 2분 7.0초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 22.5% | 성공: 32 | 실패: 13 | 예상 남은 시간: 8분 19.8초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 23.0% | 성공: 33 | 실패: 13 | 예상 남은 시간: 8분 7.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 📦 ddtaxi-1_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 🔄 처리 시작: dibidib_EV9_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m ✅ ha8519_EV9_202401.csv: 완료 (24,049행, 21.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70775)\u001b[0m ✅ jmmath_IONIQ5 LONGRANGE_202207.csv: 완료 (33,051행, 49.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 ltgyc-4_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 23.5% | 성공: 34 | 실패: 13 | 예상 남은 시간: 8분 22.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70885)\u001b[0m 📦 dibidib_EV9_202407.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70775)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 24.0% | 성공: 35 | 실패: 13 | 예상 남은 시간: 8분 17.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: ltgdg-23_BONGO3_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 24.5% | 성공: 36 | 실패: 13 | 예상 남은 시간: 8분 5.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 🔄 처리 시작: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m 📦 kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ✅ test01_NIRO PLUS_202201.csv: 완료 (3,243행, 13.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 ltgdg-23_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 25.0% | 성공: 37 | 실패: 13 | 예상 남은 시간: 8분 12.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 🔄 처리 시작: relier_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71587)\u001b[0m ✅ revu-n-15_EV6 LONGRANGE.csv: 완료 (27,629행, 23.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71761)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m 🔄 처리 시작: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 📦 relier_NIRO2_202207.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ ltgyc-4_BONGO3.csv: 완료 (107,527행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 25.5% | 성공: 38 | 실패: 13 | 예상 남은 시간: 8분 17.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 완료 (61행, 3.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 26.0% | 성공: 39 | 실패: 13 | 예상 남은 시간: 8분 20.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 woojukjk_EV6 LONGRANGE_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 26.5% | 성공: 40 | 실패: 13 | 예상 남은 시간: 8분 25.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ cyberlmk_EV9_202308.csv: 완료 (59,363행, 45.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 27.0% | 성공: 40 | 실패: 14 | 예상 남은 시간: 8분 13.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: ltgdg-13_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 파일 병합 중 오류 (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 27.5% | 성공: 41 | 실패: 14 | 예상 남은 시간: 8분 3.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 ltgdg-13_PORTER2_2024.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 ajutaxi-25_IONIQ 2019_201701.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71900)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ ltgdg-23_BONGO3_2023.csv: 완료 (68,839행, 25.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: ajutaxi-25_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 파일 병합 중 오류 (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 28.0% | 성공: 42 | 실패: 14 | 예상 남은 시간: 8분 37.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ ltgdg-13_PORTER2_2024.csv: 완료 (80,484행, 18.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 28.5% | 성공: 43 | 실패: 14 | 예상 남은 시간: 8분 28.9초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 29.0% | 성공: 44 | 실패: 14 | 예상 남은 시간: 8분 16.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: jtkim0601_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 29.5% | 성공: 45 | 실패: 14 | 예상 남은 시간: 8분 5.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 revu-n-41_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72012)\u001b[0m 🔄 처리 시작: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 30.0% | 성공: 46 | 실패: 14 | 예상 남은 시간: 7분 60.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 30.5% | 성공: 46 | 실패: 15 | 예상 남은 시간: 7분 48.9초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 31.0% | 성공: 47 | 실패: 15 | 예상 남은 시간: 7분 38.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 jtkim0601_NIRO LONGRANGE_201808.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ✅ relier_NIRO2_202207.csv: 완료 (103,886행, 48.8초)\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: cjl-gbyc-013_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 31.5% | 성공: 48 | 실패: 15 | 예상 남은 시간: 7분 38.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m 📦 kung417s_EV6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 32.0% | 성공: 48 | 실패: 16 | 예상 남은 시간: 7분 29.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 🔄 처리 시작: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 📦 lotteglogis-dg-28_BONGO3_202309.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70777)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ ddtaxi-1_EV6 LONGRANGE_202201.csv: 완료 (60,474행, 1분 5.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 📦 revu-n-20_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 32.5% | 성공: 49 | 실패: 16 | 예상 남은 시간: 7분 25.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71411)\u001b[0m ✅ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (43,943행, 57.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 🔄 처리 시작: 628dani_CASPER LONGRANGE_202410.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 cjl-gbyc-013_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 📦 628dani_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=71411)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 33.0% | 성공: 50 | 실패: 16 | 예상 남은 시간: 7분 34.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 📦 48625ff_EV6 LONGRANGE_202210.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ✅ lotteglogis-dg-28_BONGO3_202309.csv: 완료 (118,590행, 17.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 🔄 처리 시작: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 33.5% | 성공: 50 | 실패: 17 | 예상 남은 시간: 7분 24.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 🔄 처리 시작: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 34.0% | 성공: 51 | 실패: 17 | 예상 남은 시간: 7분 21.1초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 34.5% | 성공: 52 | 실패: 17 | 예상 남은 시간: 7분 13.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72069)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 🔄 처리 시작: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ✅ 628dani_CASPER LONGRANGE_202410.csv: 완료 (26,037행, 11.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m 📦 kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 📦 pgtaxi-5_NIRO LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: revu-n-8_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 35.0% | 성공: 52 | 실패: 18 | 예상 남은 시간: 7분 10.7초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 35.5% | 성공: 53 | 실패: 18 | 예상 남은 시간: 7분 3.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 bbs001_IONIQ 2019_201710.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ jtkim0601_NIRO LONGRANGE_201808.csv: 완료 (55,720행, 30.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72185)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 pgtaxi-4_IONIQ6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: bbs001_IONIQ 2019_201710.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72185)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 파일 병합 중 오류 (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 36.0% | 성공: 54 | 실패: 18 | 예상 남은 시간: 7분 8.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ✅ pgtaxi-5_NIRO LONGRANGE.csv: 완료 (30,885행, 12.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 🔄 처리 시작: joiltaxi-21_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 36.5% | 성공: 55 | 실패: 18 | 예상 남은 시간: 7분 1.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ revu-n-41_EV6 LONGRANGE.csv: 완료 (27,780행, 40.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m 📦 joiltaxi-21_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 37.0% | 성공: 56 | 실패: 18 | 예상 남은 시간: 7분 8.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ✅ revu-n-20_IONIQ5 LONGRANGE.csv: 완료 (29,268행, 40.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72027)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 🔄 처리 시작: ltgdg-12_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 37.5% | 성공: 57 | 실패: 18 | 예상 남은 시간: 7분 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ✅ kung417s_EV6 LONGRANGE_202201.csv: 완료 (52,119행, 51.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72329)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 📦 ltgdg-12_PORTER2.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m 🔄 처리 시작: sitestev6_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m 📦 sitestev6_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72329)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 🔄 처리 시작: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 38.0% | 성공: 57 | 실패: 19 | 예상 남은 시간: 7분 21.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 🔄 처리 시작: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 38.5% | 성공: 58 | 실패: 19 | 예상 남은 시간: 7분 15.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71713)\u001b[0m ✅ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (66,543행, 48.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 39.0% | 성공: 59 | 실패: 19 | 예상 남은 시간: 7분 8.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ bbs001_IONIQ 2019_201710.csv: 완료 (36,408행, 40.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 파일 병합 중 오류 (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ pgtaxi-4_IONIQ6 LONGRANGE.csv: 완료 (73,576행, 42.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 39.5% | 성공: 60 | 실패: 19 | 예상 남은 시간: 7분 0.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 🔄 처리 시작: ltgdg-24_BONGO3_2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 📦 ajutaxi-1_IONIQ 2019_201701.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72533)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 revu-n-39_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 파일 병합 중 오류 (Client V011BE0001): time data \"2025-07-16 09:25:52.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 📦 ltgdg-24_BONGO3_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 40.0% | 성공: 61 | 실패: 19 | 예상 남은 시간: 7분 6.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ✅ ltgdg-12_PORTER2.csv: 완료 (100,496행, 30.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 🔄 처리 시작: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 40.5% | 성공: 61 | 실패: 20 | 예상 남은 시간: 6분 59.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 🔄 처리 시작: mkj2449_IONIQ5 LONGRANGE_202110.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72533)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 📦 mkj2449_IONIQ5 LONGRANGE_202110.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 파일 병합 중 오류 (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71350)\u001b[0m ✅ ltgdg-24_BONGO3_2022.csv: 완료 (55,733행, 15.0초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 41.0% | 성공: 62 | 실패: 20 | 예상 남은 시간: 7분 0.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72629)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m 🔄 처리 시작: revu-n-54_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 41.5% | 성공: 63 | 실패: 20 | 예상 남은 시간: 6분 58.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 🔄 처리 시작: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 42.0% | 성공: 63 | 실패: 21 | 예상 남은 시간: 6분 49.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m 📦 revu-n-54_EV6 LONGRANGE_2023.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ 48625ff_EV6 LONGRANGE_202210.csv: 완료 (70,631행, 1분 23.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 📦 aim21c_NIRO LONGRANGE_201801.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 42.5% | 성공: 64 | 실패: 21 | 예상 남은 시간: 6분 47.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 🔄 처리 시작: aim21c_NIRO LONGRANGE_201801.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ✅ ajutaxi-1_IONIQ 2019_201701.csv: 완료 (93,562행, 30.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 🔄 처리 시작: cjl-gbyc-016_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 파일 병합 중 오류 (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 43.0% | 성공: 65 | 실패: 21 | 예상 남은 시간: 6분 45.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72027)\u001b[0m ✅ mkj2449_IONIQ5 LONGRANGE_202110.csv: 완료 (69,433행, 20.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 📦 cjl-gbyc-016_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m 🔄 처리 시작: hahakuhyun_EV6 LONGRANGE_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ revu-n-39_EV6 LONGRANGE.csv: 완료 (55,459행, 32.0초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 43.5% | 성공: 66 | 실패: 21 | 예상 남은 시간: 6분 39.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: ltgdg-32_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72629)\u001b[0m ✅ revu-n-54_EV6 LONGRANGE_2023.csv: 완료 (23,047행, 14.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 44.0% | 성공: 67 | 실패: 21 | 예상 남은 시간: 6분 35.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72629)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 🔄 처리 시작: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 ltgdg-32_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 📦 yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 🔄 처리 시작: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 📦 pgtaxi-16_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ✅ yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 완료 (13,503행, 11.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 44.5% | 성공: 68 | 실패: 21 | 예상 남은 시간: 6분 45.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 파일 병합 중 오류 (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ ltgdg-32_PORTER2_2023.csv: 완료 (74,459행, 18.5초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 45.0% | 성공: 69 | 실패: 21 | 예상 남은 시간: 6분 38.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 45.5% | 성공: 70 | 실패: 21 | 예상 남은 시간: 6분 33.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 tsiyhj_EV6 LONGRANGE_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 46.0% | 성공: 70 | 실패: 22 | 예상 남은 시간: 6분 27.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 🔄 처리 시작: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 46.5% | 성공: 71 | 실패: 22 | 예상 남은 시간: 6분 19.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (70,737행, 1분 26.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ aim21c_NIRO LONGRANGE_201801.csv: 완료 (39,657행, 33.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 🔄 처리 시작: xlos20_EV6 LONGRANGE_202101.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m 📦 xlos20_EV6 LONGRANGE_202101.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 📦 revu-n-64_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ✅ hahakuhyun_EV6 LONGRANGE_202401.csv: 완료 (40,067행, 30.7초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 47.0% | 성공: 72 | 실패: 22 | 예상 남은 시간: 6분 20.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 47.5% | 성공: 73 | 실패: 22 | 예상 남은 시간: 6분 13.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 파일 병합 중 오류 (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23028. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 48.0% | 성공: 74 | 실패: 22 | 예상 남은 시간: 6분 8.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ✅ pgtaxi-16_EV6 LONGRANGE.csv: 완료 (23,028행, 19.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 🔄 처리 시작: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m 📦 sl-ev-1_EV6 LONGRANGE_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ✅ cjl-gbyc-016_BONGO3.csv: 완료 (97,428행, 36.5초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 48.5% | 성공: 75 | 실패: 22 | 예상 남은 시간: 6분 3.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72069)\u001b[0m ✅ joiltaxi-21_EV6 LONGRANGE_202201.csv: 완료 (83,952행, 1분 41.1초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 49.0% | 성공: 76 | 실패: 22 | 예상 남은 시간: 5분 56.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 📦 revu-n-63_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72997)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m 🔄 처리 시작: ltgyc-3_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m 🔄 처리 시작: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m 📦 revu-n-11_KONA LONGRANGE_202104.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=71759)\u001b[0m ✅ sitestev6_EV6 LONGRANGE_202201.csv: 완료 (84,032행, 1분 27.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73049)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ tsiyhj_EV6 LONGRANGE_202407.csv: 완료 (37,590행, 32.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m 📦 ltgyc-3_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: ltgdg-34_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 49.5% | 성공: 77 | 실패: 22 | 예상 남은 시간: 6분 5.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 ltgdg-34_BONGO3.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 50.0% | 성공: 78 | 실패: 22 | 예상 남은 시간: 6분 5.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m 파일 병합 중 오류 (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72671)\u001b[0m ✅ ltgyc-3_PORTER2.csv: 완료 (68,739행, 18.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: cjl-dgds-011_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 50.5% | 성공: 79 | 실패: 22 | 예상 남은 시간: 6분 0.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 cjl-dgds-011_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 51.0% | 성공: 80 | 실패: 22 | 예상 남은 시간: 5분 53.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m 파일 병합 중 오류 (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72997)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m ✅ lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 완료 (62,844행, 29.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: ltgdg-22_BONGO3_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72997)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 🔄 처리 시작: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 51.5% | 성공: 80 | 실패: 23 | 예상 남은 시간: 5분 49.3초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 52.0% | 성공: 80 | 실패: 24 | 예상 남은 시간: 5분 42.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 🔄 처리 시작: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 🔄 처리 시작: maxcom3_EV9_202312.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 52.5% | 성공: 80 | 실패: 25 | 예상 남은 시간: 5분 35.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 🔄 처리 시작: cjl-dgno-004_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 53.0% | 성공: 81 | 실패: 25 | 예상 남은 시간: 5분 30.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ✅ revu-n-64_EV6 LONGRANGE.csv: 완료 (38,910행, 42.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 📦 cjl-dgno-004_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 53.5% | 성공: 82 | 실패: 25 | 예상 남은 시간: 5분 24.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m 🔄 처리 시작: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 54.0% | 성공: 82 | 실패: 26 | 예상 남은 시간: 5분 18.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ ltgdg-34_BONGO3.csv: 완료 (57,250행, 15.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 🔄 처리 시작: lotteglogis-dg-20_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m 📦 revu-u-2_IONIQ5 LONGRANGE_202101.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ✅ cjl-dgno-004_PORTER2.csv: 완료 (59,285행, 11.6초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 54.5% | 성공: 83 | 실패: 26 | 예상 남은 시간: 5분 19.6초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 55.0% | 성공: 84 | 실패: 26 | 예상 남은 시간: 5분 15.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 📦 lotteglogis-dg-20_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 파일 병합 중 오류 (Client V012BE0021): time data \"2025-07-16 08:30:40.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 🔄 처리 시작: ltgdg-17_BONGO3_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 55.5% | 성공: 85 | 실패: 26 | 예상 남은 시간: 5분 9.3초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 56.0% | 성공: 86 | 실패: 26 | 예상 남은 시간: 5분 3.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 🔄 처리 시작: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 📦 revu-n-25_NIRO2_202401.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m 📦 yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70777)\u001b[0m ✅ xlos20_EV6 LONGRANGE_202101.csv: 완료 (36,296행, 56.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 파일 병합 중 오류 (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6572. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 56.5% | 성공: 87 | 실패: 26 | 예상 남은 시간: 5분 0.8초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 57.0% | 성공: 88 | 실패: 26 | 예상 남은 시간: 4분 54.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70778)\u001b[0m 🔄 처리 시작: revu-n-25_NIRO2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ✅ revu-n-63_IONIQ5 LONGRANGE.csv: 완료 (46,927행, 50.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 🔄 처리 시작: helleus77_EV6 STANDARD_202108.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m 📦 ltgdg-17_BONGO3_2024.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m 📦 helleus77_EV6 STANDARD_202108.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72425)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=72425)\u001b[0m ✅ sl-ev-1_EV6 LONGRANGE_2022.csv: 완료 (37,612행, 52.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m 🔄 처리 시작: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 57.5% | 성공: 89 | 실패: 26 | 예상 남은 시간: 4분 57.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 58.0% | 성공: 90 | 실패: 26 | 예상 남은 시간: 4분 51.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m 📦 cjl-dgss-012_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ✅ lotteglogis-dg-20_BONGO3.csv: 완료 (115,446행, 25.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 🔄 처리 시작: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 58.5% | 성공: 91 | 실패: 26 | 예상 남은 시간: 4분 45.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m 📦 revu-n-18_BONGO3.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 59.0% | 성공: 92 | 실패: 26 | 예상 남은 시간: 4분 42.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=70781)\u001b[0m ✅ ltgdg-17_BONGO3_2024.csv: 완료 (128,926행, 21.9초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m 🔄 처리 시작: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 59.5% | 성공: 93 | 실패: 26 | 예상 남은 시간: 4분 37.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m 🔄 처리 시작: joiltaxi-8_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 📦 joiltaxi-3_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=70781)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m 📦 joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m 🔄 처리 시작: ltgdg-21_PORTER2_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 🔄 처리 시작: lotteglogis-dg-22_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m 📦 ltgdg-21_PORTER2_2024.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 📦 lotteglogis-dg-22_PORTER2_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 60.0% | 성공: 94 | 실패: 26 | 예상 남은 시간: 4분 41.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72817)\u001b[0m ✅ helleus77_EV6 STANDARD_202108.csv: 완료 (30,874행, 30.5초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72817)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 60.5% | 성공: 95 | 실패: 26 | 예상 남은 시간: 4분 37.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 완료 (32,992행, 22.8초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 61.0% | 성공: 96 | 실패: 26 | 예상 남은 시간: 4분 33.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: revu-n-66_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73143)\u001b[0m ✅ revu-n-18_BONGO3.csv: 완료 (46,907행, 25.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 revu-n-66_EV6 LONGRANGE_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 61.5% | 성공: 97 | 실패: 26 | 예상 남은 시간: 4분 28.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m 🔄 처리 시작: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m 📦 reviewshare-4_KONA LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m 🔄 처리 시작: joiltaxi-7_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 62.0% | 성공: 98 | 실패: 26 | 예상 남은 시간: 4분 24.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 62.5% | 성공: 99 | 실패: 26 | 예상 남은 시간: 4분 18.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73373)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 63.0% | 성공: 99 | 실패: 27 | 예상 남은 시간: 4분 13.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 63.5% | 성공: 99 | 실패: 28 | 예상 남은 시간: 4분 7.8초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 64.0% | 성공: 99 | 실패: 29 | 예상 남은 시간: 4분 2.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ✅ ltgdg-21_PORTER2_2024.csv: 완료 (85,806행, 19.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m 📦 zoh71z_KONA LONGRANGE_201810.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 🔄 처리 시작: bbotti_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 64.5% | 성공: 100 | 실패: 29 | 예상 남은 시간: 3분 59.4초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 65.0% | 성공: 101 | 실패: 29 | 예상 남은 시간: 3분 54.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m 🔄 처리 시작: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73142)\u001b[0m ✅ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (43,461행, 48.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m 📦 bbotti_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m 📦 joiltaxi-7_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ✅ joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 완료 (75,629행, 26.0초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 65.5% | 성공: 102 | 실패: 29 | 예상 남은 시간: 3분 53.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 🔄 처리 시작: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73281)\u001b[0m ✅ reviewshare-4_KONA LONGRANGE.csv: 완료 (32,434행, 13.1초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 66.0% | 성공: 102 | 실패: 30 | 예상 남은 시간: 3분 48.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 🔄 처리 시작: cjl-dgno-005_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73569)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 🔄 처리 시작: ajutaxi-18_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 66.5% | 성공: 102 | 실패: 31 | 예상 남은 시간: 3분 43.5초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 67.0% | 성공: 102 | 실패: 32 | 예상 남은 시간: 3분 38.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 🔄 처리 시작: mxri13_GV60_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 🔄 처리 시작: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 67.5% | 성공: 102 | 실패: 33 | 예상 남은 시간: 3분 33.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 🔄 처리 시작: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 68.0% | 성공: 103 | 실패: 33 | 예상 남은 시간: 3분 29.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ✅ lotteglogis-dg-22_PORTER2_202301.csv: 완료 (37,944행, 24.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m 📦 heo3252_KONA LONGRANGE_201901.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m 🔄 처리 시작: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 📦 revu-n-49_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73628)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 📦 pyh8965_EV6 LONGRANGE_202406.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: emob-2_IONIQ 2019.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 📦 emob-2_IONIQ 2019.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 68.5% | 성공: 104 | 실패: 33 | 예상 남은 시간: 3분 32.9초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 69.0% | 성공: 105 | 실패: 33 | 예상 남은 시간: 3분 28.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73373)\u001b[0m ✅ zoh71z_KONA LONGRANGE_201810.csv: 완료 (46,038행, 31.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 🔄 처리 시작: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 69.5% | 성공: 106 | 실패: 33 | 예상 남은 시간: 3분 23.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 🔄 처리 시작: cjl-dgea-008_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73373)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 📦 lee5957_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 70.0% | 성공: 107 | 실패: 33 | 예상 남은 시간: 3분 19.9초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 70.5% | 성공: 108 | 실패: 33 | 예상 남은 시간: 3분 16.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73501)\u001b[0m ✅ joiltaxi-7_EV6 LONGRANGE_202201.csv: 완료 (94,766행, 36.0초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ✅ revu-n-49_EV6 LONGRANGE.csv: 완료 (46,172행, 25.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 📦 cjl-dgea-008_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73719)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 🔄 처리 시작: cjl-gbyc-018_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 71.0% | 성공: 108 | 실패: 34 | 예상 남은 시간: 3분 12.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 71.5% | 성공: 109 | 실패: 34 | 예상 남은 시간: 3분 8.9초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 72.0% | 성공: 110 | 실패: 34 | 예상 남은 시간: 3분 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ✅ emob-2_IONIQ 2019.csv: 완료 (18,282행, 19.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ revu-n-66_EV6 LONGRANGE_202304.csv: 완료 (51,962행, 49.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 72.5% | 성공: 111 | 실패: 34 | 예상 남은 시간: 3분 0.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m 📦 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: ltgdg-1_BONGO3_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73374)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 ltgdg-1_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73374)\u001b[0m ✅ heo3252_KONA LONGRANGE_201901.csv: 완료 (45,859행, 31.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 73.0% | 성공: 112 | 실패: 34 | 예상 남은 시간: 2분 57.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ✅ cjl-dgea-008_BONGO3.csv: 완료 (63,959행, 16.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 73.5% | 성공: 113 | 실패: 34 | 예상 남은 시간: 2분 54.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: revu-n-21_EV9.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=72782)\u001b[0m ✅ bbotti_IONIQ5 LONGRANGE.csv: 완료 (44,645행, 51.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 📦 ksy-taxi-p1_EV6 LONGRANGE_202303.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m 🔄 처리 시작: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 revu-n-22_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=72782)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73428)\u001b[0m ✅ joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 완료 (5,433행, 5.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 📦 revu-n-21_EV9.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 🔄 처리 시작: kepco-1_IONIQ5 LONGRANGE_202110.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 74.0% | 성공: 114 | 실패: 34 | 예상 남은 시간: 2분 52.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2732 MiB, 70 objects, write throughput 422 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(preprocess_batch_parallel pid=73843)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m 🔄 처리 시작: ddtaxi-4_KONA LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 74.5% | 성공: 115 | 실패: 34 | 예상 남은 시간: 2분 50.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 📦 kepco-1_IONIQ5 LONGRANGE_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ ltgdg-1_BONGO3_2023.csv: 완료 (72,001행, 22.8초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 75.0% | 성공: 115 | 실패: 35 | 예상 남은 시간: 2분 45.7초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 75.5% | 성공: 116 | 실패: 35 | 예상 남은 시간: 2분 42.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ✅ lee5957_IONIQ5 LONGRANGE.csv: 완료 (39,790행, 38.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m 📦 ddtaxi-4_KONA LONGRANGE_201901.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 파일 병합 중 오류 (Client V021BE0004): time data \"2025-07-16 01:14:58.627\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ✅ revu-n-21_EV9.csv: 완료 (100,642행, 25.7초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 76.0% | 성공: 117 | 실패: 35 | 예상 남은 시간: 2분 39.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73541)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 🔄 처리 시작: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 76.5% | 성공: 117 | 실패: 36 | 예상 남은 시간: 2분 35.3초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 77.0% | 성공: 117 | 실패: 37 | 예상 남은 시간: 2분 31.0초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 77.5% | 성공: 117 | 실패: 38 | 예상 남은 시간: 2분 27.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 🔄 처리 시작: ssa1011_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: ltgdg-33_PORTER2_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m 📦 ssa1011_KONA LONGRANGE 2세대_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 📦 ltgdg-33_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73995)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 78.0% | 성공: 118 | 실패: 38 | 예상 남은 시간: 2분 25.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 joiltaxi-26_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ✅ ksy-taxi-p1_EV6 LONGRANGE_202303.csv: 완료 (148,647행, 45.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 🔄 처리 시작: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 파일 병합 중 오류 (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 78.5% | 성공: 119 | 실패: 38 | 예상 남은 시간: 2분 21.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ revu-n-22_EV6 LONGRANGE.csv: 완료 (70,077행, 36.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: endy11_PORTER2_202306.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 79.0% | 성공: 120 | 실패: 38 | 예상 남은 시간: 2분 18.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 📦 revu-n-38_IONIQ5 LONGRANGE 2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 79.5% | 성공: 121 | 실패: 38 | 예상 남은 시간: 2분 14.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ✅ ltgdg-33_PORTER2_2023.csv: 완료 (41,472행, 12.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 80.0% | 성공: 121 | 실패: 39 | 예상 남은 시간: 2분 10.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 80.5% | 성공: 121 | 실패: 40 | 예상 남은 시간: 2분 6.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: dlcksgh3595_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73614)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 81.0% | 성공: 122 | 실패: 40 | 예상 남은 시간: 2분 2.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 파일 병합 중 오류 (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: ddtaxi-5_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 🔄 처리 시작: revu-n-27_EV9.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 📦 revu-n-27_EV9.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73569)\u001b[0m ✅ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 완료 (44,144행, 53.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73569)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 파일 병합 중 오류 (Client V003BF0002): time data \"2025-07-16 01:17:03.196\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 endy11_PORTER2_202306.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 81.5% | 성공: 123 | 실패: 40 | 예상 남은 시간: 2분 0.2초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 82.0% | 성공: 124 | 실패: 40 | 예상 남은 시간: 1분 56.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ✅ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 완료 (30,170행, 13.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ✅ kepco-1_IONIQ5 LONGRANGE_202110.csv: 완료 (35,635행, 41.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 🔄 처리 시작: ltgdg-5_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 🔄 처리 시작: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 📦 yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m 📦 lotteglogis-dg-33_PORTER2_202301.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 📦 revu-n-4_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 82.5% | 성공: 125 | 실패: 40 | 예상 남은 시간: 1분 53.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 파일 병합 중 오류 (Client V021BE0000): time data \"2025-07-16 00:27:35.894\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 5967. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ✅ revu-n-27_EV9.csv: 완료 (5,967행, 11.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 🔄 처리 시작: adreamcar_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m 🔄 처리 시작: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 📦 adreamcar_PORTER2_202301.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 83.0% | 성공: 126 | 실패: 40 | 예상 남은 시간: 1분 50.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73541)\u001b[0m ✅ ssa1011_KONA LONGRANGE 2세대_202301.csv: 완료 (47,149행, 31.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m 📦 hyisjung_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74132)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 83.5% | 성공: 127 | 실패: 40 | 예상 남은 시간: 1분 47.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ endy11_PORTER2_202306.csv: 완료 (96,206행, 25.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 파일 병합 중 오류 (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 84.0% | 성공: 128 | 실패: 40 | 예상 남은 시간: 1분 43.4초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 84.5% | 성공: 129 | 실패: 40 | 예상 남은 시간: 1분 39.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 🔄 처리 시작: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m 🔄 처리 시작: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 ksjksj87_EV3 LONGRANGE_202409.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m 📦 ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74147)\u001b[0m ✅ hyisjung_NIRO LONGRANGE_201808.csv: 완료 (12,579행, 8.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 85.0% | 성공: 130 | 실패: 40 | 예상 남은 시간: 1분 36.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74147)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 85.5% | 성공: 131 | 실패: 40 | 예상 남은 시간: 1분 32.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 📦 revu-n-58_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ✅ adreamcar_PORTER2_202301.csv: 완료 (10,571행, 11.9초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 🔄 처리 시작: ltgdg-3_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m 🔄 처리 시작: ltgdg-6_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 📦 ltgdg-3_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m 📦 ltgdg-6_PORTER2_2024.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74198)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ✅ revu-n-4_EV6 LONGRANGE.csv: 완료 (46,655행, 23.3초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 86.0% | 성공: 132 | 실패: 40 | 예상 남은 시간: 1분 30.1초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 86.5% | 성공: 132 | 실패: 41 | 예상 남은 시간: 1분 26.5초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 87.0% | 성공: 133 | 실패: 41 | 예상 남은 시간: 1분 23.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m 🔄 처리 시작: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m ✅ yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (112,114행, 35.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73614)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 87.5% | 성공: 133 | 실패: 42 | 예상 남은 시간: 1분 20.1초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 88.0% | 성공: 133 | 실패: 43 | 예상 남은 시간: 1분 16.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 📦 js5540810_IONIQ 2019_201607.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73614)\u001b[0m 🔄 처리 시작: js5540810_IONIQ 2019_201607.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74212)\u001b[0m ✅ ltgdg-6_PORTER2_2024.csv: 완료 (34,055행, 13.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 88.5% | 성공: 134 | 실패: 43 | 예상 남은 시간: 1분 13.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74212)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 89.0% | 성공: 135 | 실패: 43 | 예상 남은 시간: 1분 10.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 파일 병합 중 오류 (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 89.5% | 성공: 136 | 실패: 43 | 예상 남은 시간: 1분 6.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 🔄 처리 시작: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 90.0% | 성공: 137 | 실패: 43 | 예상 남은 시간: 1분 3.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 yaa7890_PORTER2_202003.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: yaa7890_PORTER2_202003.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m ✅ ltgdg-3_PORTER2_2023.csv: 완료 (66,661행, 19.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ✅ revu-n-58_EV6 LONGRANGE.csv: 완료 (34,017행, 25.9초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 90.5% | 성공: 138 | 실패: 43 | 예상 남은 시간: 59.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74342)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 91.0% | 성공: 139 | 실패: 43 | 예상 남은 시간: 56.7초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 91.5% | 성공: 140 | 실패: 43 | 예상 남은 시간: 53.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m 📦 ntragic_EV6 LONGRANGE_202005.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 🔄 처리 시작: testev9_EV9_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ ksjksj87_EV3 LONGRANGE_202409.csv: 완료 (48,774행, 30.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m 📦 testev9_EV9_2023.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: lotteglogis-dg-7_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ yaa7890_PORTER2_202003.csv: 완료 (15,131행, 8.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74061)\u001b[0m 📦 yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 lotteglogis-dg-7_PORTER2_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m 파일 병합 중 오류 (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74312)\u001b[0m ✅ ntragic_EV6 LONGRANGE_202005.csv: 완료 (54,951행, 15.8초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 92.0% | 성공: 141 | 실패: 43 | 예상 남은 시간: 50.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74312)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 92.5% | 성공: 142 | 실패: 43 | 예상 남은 시간: 47.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m 🔄 처리 시작: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 93.0% | 성공: 143 | 실패: 43 | 예상 남은 시간: 43.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (1,066행, 1.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 wntjdgml_CASPER LONGRANGE_202408.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m 📦 lotteglogis-dg-8_PORTER2_202308.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m 🔄 처리 시작: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 93.5% | 성공: 144 | 실패: 43 | 예상 남은 시간: 40.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ lotteglogis-dg-1_PORTER2_202306.csv: 완료 (14,411행, 9.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73842)\u001b[0m ✅ testev9_EV9_2023.csv: 완료 (5,246행, 15.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74433)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m 🔄 처리 시작: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m 📦 bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m 📦 beston_IONIQ6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74448)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74448)\u001b[0m 🔄 처리 시작: revu-n-35_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 94.0% | 성공: 145 | 실패: 43 | 예상 남은 시간: 38.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 파일 병합 중 오류 (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73881)\u001b[0m ✅ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 완료 (31,567행, 54.5초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 94.5% | 성공: 146 | 실패: 43 | 예상 남은 시간: 34.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ lotteglogis-dg-7_PORTER2_202311.csv: 완료 (51,246행, 20.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74448)\u001b[0m 📦 revu-n-35_GV70.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=73099)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: cjl-gbyc-010_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 95.0% | 성공: 146 | 실패: 44 | 예상 남은 시간: 31.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 🔄 처리 시작: cody8406_IONIQ 2020_202007.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ wntjdgml_CASPER LONGRANGE_202408.csv: 완료 (29,877행, 20.5초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 95.5% | 성공: 147 | 실패: 44 | 예상 남은 시간: 28.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m 파일 병합 중 오류 (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 96.0% | 성공: 148 | 실패: 44 | 예상 남은 시간: 25.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m 📦 cody8406_IONIQ 2020_202007.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74419)\u001b[0m ✅ lotteglogis-dg-8_PORTER2_202308.csv: 완료 (44,518행, 24.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 📦 joiltaxi-9_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m 🔄 처리 시작: joiltaxi-9_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 96.5% | 성공: 149 | 실패: 44 | 예상 남은 시간: 22.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74342)\u001b[0m ✅ lotteglogis-dg-10_PORTER2_202310.csv: 완료 (63,984행, 54.2초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 97.0% | 성공: 150 | 실패: 44 | 예상 남은 시간: 19.4초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 97.5% | 성공: 151 | 실패: 44 | 예상 남은 시간: 16.1초\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 98.0% | 성공: 152 | 실패: 44 | 예상 남은 시간: 12.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73099)\u001b[0m ✅ cody8406_IONIQ 2020_202007.csv: 완료 (35,915행, 25.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 98.5% | 성공: 153 | 실패: 44 | 예상 남은 시간: 9.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73719)\u001b[0m ✅ koreataxi-1_IONIQ5 LONGRANGE_202204.csv: 완료 (134,336행, 1분 18.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=73800)\u001b[0m ✅ joiltaxi-9_EV6 LONGRANGE_202201.csv: 완료 (92,730행, 33.4초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 99.0% | 성공: 154 | 실패: 44 | 예상 남은 시간: 6.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74420)\u001b[0m ✅ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (42,757행, 53.8초)\n",
      "\u001b[36m(ProgressTracker pid=70776)\u001b[0m 📊 진행률: 99.5% | 성공: 155 | 실패: 44 | 예상 남은 시간: 3.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74433)\u001b[0m ✅ beston_IONIQ6 LONGRANGE_202201.csv: 완료 (56,290행, 59.7초)\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 156개 | ❌ 실패: 44개\n",
      "📊 총 처리 행 수: 8,761,766행\n",
      "⏱️  총 소요시간: 10분 58.7초\n",
      "⚡ 평균 파일당: 3.3초\n",
      "\n",
      "❌ 실패한 파일들:\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 10분 58.7초\n",
      "   - 파일당 평균: 3.3초\n",
      "   - 성공률: 78.0%\n",
      "   - 총 처리 행 수: 8,761,766행\n",
      "   - 시간당 처리량: 47888991행/시간\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74419)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:28:28,523\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 20개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m 🔄 처리 시작: lostcity1_PORTER2_202412.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m 🔄 처리 시작: sosanamu_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m 🔄 처리 시작: woojoov_CASPER LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m 📦 woojoov_CASPER LONGRANGE_202503.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m 📦 hoya3838_IONIQ 2019_201807.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m 📦 sosanamu_NIRO LONGRANGE_201902.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=74938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 5.0% | 성공: 1 | 실패: 0 | 예상 남은 시간: 2분 20.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74911)\u001b[0m 🔄 처리 시작: kkhjust00_EV3 STANDARD_202408.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ✅ woojoov_CASPER LONGRANGE_202503.csv: 완료 (8,023행, 6.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m 📦 printo2000_PORTER2_202210.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74955)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 10.0% | 성공: 2 | 실패: 0 | 예상 남은 시간: 1분 50.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m ✅ hoya3838_IONIQ 2019_201807.csv: 완료 (4,699행, 10.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m 🔄 처리 시작: wce4122_EV6 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m 📦 wce4122_EV6 LONGRANGE_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 15.0% | 성공: 3 | 실패: 0 | 예상 남은 시간: 1분 33.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m 파일 병합 중 오류 (Client V000CB0100): time data \"2025-07-16 10:05:19.604\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74895)\u001b[0m ✅ printo2000_PORTER2_202210.csv: 완료 (52,500행, 9.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75009)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m 📦 car0365_EV6 LONGRANGE_202109.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m 🔄 처리 시작: car0365_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 20.0% | 성공: 4 | 실패: 0 | 예상 남은 시간: 1분 39.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m ✅ bjgjw2579_EV6 LONGRANGE_202109.csv: 완료 (19,581행, 23.5초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=74897)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m 🔄 처리 시작: sunghyun_BONGO3_202412.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 25.0% | 성공: 5 | 실패: 0 | 예상 남은 시간: 1분 18.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m 📦 win7102_EV3 LONGRANGE_202503.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74897)\u001b[0m 📦 sunghyun_BONGO3_202412.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 30.0% | 성공: 6 | 실패: 0 | 예상 남은 시간: 1분 14.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m ✅ lostcity1_PORTER2_202412.csv: 완료 (55,772행, 24.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m 🔄 처리 시작: win7102_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74911)\u001b[0m ✅ kkhjust00_EV3 STANDARD_202408.csv: 완료 (21,219행, 29.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75086)\u001b[0m 🔄 처리 시작: go051s_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75086)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 35.0% | 성공: 7 | 실패: 0 | 예상 남은 시간: 1분 3.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ✅ sosanamu_NIRO LONGRANGE_201902.csv: 완료 (48,012행, 32.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m 🔄 처리 시작: vunyvuny2_SOUL LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m 📦 vunyvuny2_SOUL LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75086)\u001b[0m 📦 go051s_BONGO3_202412.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m ✅ car0365_EV6 LONGRANGE_202109.csv: 완료 (41,210행, 33.7초)\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 40.0% | 성공: 8 | 실패: 0 | 예상 남은 시간: 1분 19.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75009)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75247)\u001b[0m 🔄 처리 시작: tlsqjatjq628_EV3 LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75216)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75247)\u001b[0m 📦 tlsqjatjq628_EV3 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m 🔄 처리 시작: ehdghans1_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75366)\u001b[0m 🔄 처리 시작: ltj1937_EV3 LONGRANGE_202412.csv\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 45.0% | 성공: 9 | 실패: 0 | 예상 남은 시간: 1분 29.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75009)\u001b[0m 📦 ehdghans1_IONIQ5 LONGRANGE_202206.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m ✅ ty3951_EV6 LONGRANGE_202408.csv: 완료 (45,811행, 1분 11.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m 🔄 처리 시작: janko7_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74896)\u001b[0m 📦 janko7_EV3 LONGRANGE_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 50.0% | 성공: 10 | 실패: 0 | 예상 남은 시간: 1분 17.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74891)\u001b[0m ✅ vunyvuny2_SOUL LONGRANGE.csv: 완료 (41,694행, 43.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m 🔄 처리 시작: thdwlsdn000_CASPER LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75455)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m 📦 thdwlsdn000_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 55.0% | 성공: 11 | 실패: 0 | 예상 남은 시간: 1분 22.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74894)\u001b[0m ✅ wce4122_EV6 LONGRANGE_202110.csv: 완료 (38,945행, 1분 28.7초)\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 60.0% | 성공: 12 | 실패: 0 | 예상 남은 시간: 1분 7.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75572)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 65.0% | 성공: 13 | 실패: 0 | 예상 남은 시간: 56.8초\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 70.0% | 성공: 14 | 실패: 0 | 예상 남은 시간: 49.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=74893)\u001b[0m ✅ win7102_EV3 LONGRANGE_202503.csv: 완료 (29,808행, 1분 19.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 75.0% | 성공: 15 | 실패: 0 | 예상 남은 시간: 38.4초\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 80.0% | 성공: 16 | 실패: 0 | 예상 남은 시간: 29.6초\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 85.0% | 성공: 17 | 실패: 0 | 예상 남은 시간: 21.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75455)\u001b[0m ✅ thdwlsdn000_CASPER LONGRANGE_202410.csv: 완료 (15,088행, 38.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 90.0% | 성공: 18 | 실패: 0 | 예상 남은 시간: 13.8초\n",
      "\u001b[36m(ProgressTracker pid=74890)\u001b[0m 📊 진행률: 95.0% | 성공: 19 | 실패: 0 | 예상 남은 시간: 6.6초\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 20개 | ❌ 실패: 0개\n",
      "📊 총 처리 행 수: 873,132행\n",
      "⏱️  총 소요시간: 2분 11.3초\n",
      "⚡ 평균 파일당: 6.6초\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 2분 11.3초\n",
      "   - 파일당 평균: 6.6초\n",
      "   - 성공률: 100.0%\n",
      "   - 총 처리 행 수: 873,132행\n",
      "   - 시간당 처리량: 23936157행/시간\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75366)\u001b[0m ✅ ltj1937_EV3 LONGRANGE_202412.csv: 완료 (104,856행, 57.0초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75572)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:30:44,645\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 260개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 🔄 처리 시작: honeybto_GV60_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m 🔄 처리 시작: emob-1_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 0.4% | 성공: 0 | 실패: 1 | 예상 남은 시간: 4분 58.5초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 0.8% | 성공: 0 | 실패: 2 | 예상 남은 시간: 2분 31.0초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 1.2% | 성공: 0 | 실패: 3 | 예상 남은 시간: 1분 43.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 1.5% | 성공: 0 | 실패: 4 | 예상 남은 시간: 1분 18.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 🔄 처리 시작: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m 📦 pgtaxi-15_IONIQ6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m 📦 ekfmd3152_KONA LONGRANGE_202004.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=75792)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 📦 uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 🔄 처리 시작: revu-n-12_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m 파일 병합 중 오류 (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15937. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m ✅ ekfmd3152_KONA LONGRANGE_202004.csv: 완료 (15,937행, 6.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m 🔄 처리 시작: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m 📦 emob-1_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 📦 sepira_ST1_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 1.9% | 성공: 1 | 실패: 4 | 예상 남은 시간: 6분 35.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 2.3% | 성공: 1 | 실패: 5 | 예상 남은 시간: 5분 48.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75819)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m 🔄 처리 시작: revu-n-34_GV70.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 2.7% | 성공: 2 | 실패: 5 | 예상 남은 시간: 7분 23.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ✅ revu-n-68_EV6 LONGRANGE.csv: 완료 (12,645행, 11.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m 파일 병합 중 오류 (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m ✅ rlaxo120_KONA LONGRANGE_201811.csv: 완료 (43,413행, 11.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75786)\u001b[0m 📦 revu-n-34_GV70.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 3.1% | 성공: 3 | 실패: 5 | 예상 남은 시간: 7분 9.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 파일 병합 중 오류 (Client V015BL0000): time data \"2025-07-16 10:11:33.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 3.5% | 성공: 4 | 실패: 5 | 예상 남은 시간: 6분 56.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ honeybto_GV60_202205.csv: 완료 (30,473행, 13.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m 🔄 처리 시작: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 3.8% | 성공: 5 | 실패: 5 | 예상 남은 시간: 7분 26.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75789)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m 📦 cjl-dgds-006_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m ✅ pgtaxi-15_IONIQ6 LONGRANGE.csv: 완료 (9,649행, 16.7초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 4.2% | 성공: 5 | 실패: 6 | 예상 남은 시간: 7분 21.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m 파일 병합 중 오류 (Client V000BD0002): time data \"2025-07-16 08:00:34.338\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75787)\u001b[0m ✅ emob-1_IONIQ5 LONGRANGE.csv: 완료 (37,071행, 20.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 4.6% | 성공: 6 | 실패: 6 | 예상 남은 시간: 7분 32.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m 🔄 처리 시작: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 5.0% | 성공: 7 | 실패: 6 | 예상 남은 시간: 7분 11.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 🔄 처리 시작: ltgdg-14_BONGO3_2022.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ✅ sepira_ST1_202407.csv: 완료 (56,469행, 21.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m 🔄 처리 시작: revu-n-32_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75787)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m 📦 iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m 📦 dufdl1025_EV6 LONGRANGE_202404.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 파일 병합 중 오류 (Client V000CD0096): time data \"2025-07-16 00:00:02.159\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 🔄 처리 시작: ltgdg-18_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m 파일 병합 중 오류 (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m 📦 revu-n-32_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75791)\u001b[0m ✅ cjl-dgds-006_PORTER2.csv: 완료 (54,532행, 17.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 5.4% | 성공: 8 | 실패: 6 | 예상 남은 시간: 9분 2.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 📦 ltgdg-18_PORTER2_2023.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 5.8% | 성공: 9 | 실패: 6 | 예상 남은 시간: 8분 37.8초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 6.2% | 성공: 10 | 실패: 6 | 예상 남은 시간: 8분 5.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 🔄 처리 시작: deeps7011_EV6 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m 📦 sihehe_NIRO2_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 파일 병합 중 오류 (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ ltgdg-14_BONGO3_2022.csv: 완료 (42,486행, 12.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75791)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=75791)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 파일 병합 중 오류 (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 11537. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: man8243_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 man8243_IONIQ5 LONGRANGE_202204.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ man8243_IONIQ5 LONGRANGE_202204.csv: 완료 (11,537행, 13.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 6.5% | 성공: 11 | 실패: 6 | 예상 남은 시간: 11분 31.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m ✅ sihehe_NIRO2_202207.csv: 완료 (44,401행, 17.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 6.9% | 성공: 12 | 실패: 6 | 예상 남은 시간: 11분 15.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 파일 병합 중 오류 (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m 🔄 처리 시작: jct4589_SOUL LONGRANGE_201903.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m 📦 jct4589_SOUL LONGRANGE_201903.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75785)\u001b[0m ✅ ltgdg-18_PORTER2_2023.csv: 완료 (91,560행, 32.9초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 7.3% | 성공: 13 | 실패: 6 | 예상 남은 시간: 11분 46.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 yitaxi-8_EV6 LONGRANGE_202209.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 7.7% | 성공: 14 | 실패: 6 | 예상 남은 시간: 11분 33.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ✅ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 완료 (30,327행, 56.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 🔄 처리 시작: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 8.1% | 성공: 14 | 실패: 7 | 예상 남은 시간: 11분 1.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 📦 revu-n-48_NIRO LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 8.5% | 성공: 15 | 실패: 7 | 예상 남은 시간: 10분 56.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 🔄 처리 시작: junghun1155_EV6 LONGRANGE_202302.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75954)\u001b[0m ✅ jct4589_SOUL LONGRANGE_201903.csv: 완료 (13,984행, 10.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75785)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 📦 junghun1155_EV6 LONGRANGE_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 📦 jog5064_EV6 LONGRANGE_202307.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 🔄 처리 시작: jog5064_EV6 LONGRANGE_202307.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76174)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m 🔄 처리 시작: stock_EV9_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m 파일 병합 중 오류 (Client V004BE0011): time data \"2025-07-16 04:35:21.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 8.8% | 성공: 16 | 실패: 7 | 예상 남은 시간: 12분 34.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75908)\u001b[0m ✅ revu-n-32_EV6 LONGRANGE.csv: 완료 (65,859행, 50.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 9.2% | 성공: 17 | 실패: 7 | 예상 남은 시간: 12분 36.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75789)\u001b[0m ✅ iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 완료 (30,605행, 54.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 9.6% | 성공: 18 | 실패: 7 | 예상 남은 시간: 12분 5.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m 📦 stock_EV9_202307.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 🔄 처리 시작: ableautos_EV6 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ✅ revu-n-48_NIRO LONGRANGE.csv: 완료 (31,961행, 19.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 🔄 처리 시작: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 10.0% | 성공: 18 | 실패: 8 | 예상 남은 시간: 11분 55.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 🔄 처리 시작: jinsu7426_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m 파일 병합 중 오류 (Client V004BJ0000): time data \"2025-07-16 00:00:00.136\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 10.4% | 성공: 19 | 실패: 8 | 예상 남은 시간: 11분 50.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75790)\u001b[0m ✅ dufdl1025_EV6 LONGRANGE_202404.csv: 완료 (87,412행, 1분 9.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 📦 ableautos_EV6 LONGRANGE_202206.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75789)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: j227_KONA LONGRANGE 2세대_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 j227_KONA LONGRANGE 2세대_202311.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75790)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ yitaxi-8_EV6 LONGRANGE_202209.csv: 완료 (67,823행, 45.0초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 10.8% | 성공: 20 | 실패: 8 | 예상 남은 시간: 12분 54.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 11.2% | 성공: 20 | 실패: 9 | 예상 남은 시간: 12분 25.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 파일 병합 중 오류 (Client V004AL0000): time data \"2025-07-16 07:30:40.451\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ✅ junghun1155_EV6 LONGRANGE_202302.csv: 완료 (43,041행, 43.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 11.5% | 성공: 21 | 실패: 9 | 예상 남은 시간: 12분 57.8초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 11.9% | 성공: 22 | 실패: 9 | 예상 남은 시간: 12분 37.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ j227_KONA LONGRANGE 2세대_202311.csv: 완료 (19,475행, 14.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: pmkp37_IONIQ5 LONGRANGE 2022_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 cjl-dgea-016_PORTER2.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 🔄 처리 시작: lotteglogis-dg-19_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 12.3% | 성공: 23 | 실패: 9 | 예상 남은 시간: 12분 45.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V022BL0000): time data \"2025-07-16 01:17:05.000\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19475. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ deeps7011_EV6 LONGRANGE_202411.csv: 완료 (33,211행, 1분 15.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 📦 lotteglogis-dg-19_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 🔄 처리 시작: cjl-dgss-015_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 📦 cjl-dgss-015_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 12.7% | 성공: 24 | 실패: 9 | 예상 남은 시간: 14분 2.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ✅ jinsu7426_EV6 LONGRANGE_202407.csv: 완료 (14,069행, 43.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 🔄 처리 시작: jskim_IONIQ5 LONGRANGE_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 13.1% | 성공: 24 | 실패: 10 | 예상 남은 시간: 13분 41.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 🔄 처리 시작: ajutaxi-14_IONIQ5 STANDARD_202202.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 13.5% | 성공: 24 | 실패: 11 | 예상 남은 시간: 13분 14.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 🔄 처리 시작: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 13.8% | 성공: 25 | 실패: 11 | 예상 남은 시간: 12분 58.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 14.2% | 성공: 25 | 실패: 12 | 예상 남은 시간: 12분 36.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 파일 병합 중 오류 (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 14.6% | 성공: 26 | 실패: 12 | 예상 남은 시간: 12분 25.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ✅ jog5064_EV6 LONGRANGE_202307.csv: 완료 (29,132행, 1분 0.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ cjl-dgea-016_PORTER2.csv: 완료 (139,461행, 34.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 📦 jmmath_IONIQ5 LONGRANGE_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 🔄 처리 시작: jmmath_IONIQ5 LONGRANGE_202207.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 15.0% | 성공: 27 | 실패: 12 | 예상 남은 시간: 12분 9.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 🔄 처리 시작: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 15.4% | 성공: 27 | 실패: 13 | 예상 남은 시간: 12분 5.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 🔄 처리 시작: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 📦 revu-n-23_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 파일 병합 중 오류 (Client V012BD0018): time data \"2025-07-16 00:00:02.589\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76110)\u001b[0m ✅ lotteglogis-dg-19_BONGO3.csv: 완료 (88,946행, 23.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 📦 cjl-dgss-013_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 15.8% | 성공: 28 | 실패: 13 | 예상 남은 시간: 11분 58.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76174)\u001b[0m ✅ stock_EV9_202307.csv: 완료 (42,521행, 1분 2.0초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 16.2% | 성공: 29 | 실패: 13 | 예상 남은 시간: 11분 41.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 완료 (39,445행, 31.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 파일 병합 중 오류 (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10298. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ✅ revu-n-23_EV6 LONGRANGE.csv: 완료 (10,298행, 6.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 16.5% | 성공: 30 | 실패: 13 | 예상 남은 시간: 11분 40.1초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 16.9% | 성공: 31 | 실패: 13 | 예상 남은 시간: 11분 22.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75784)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 lotteglogis-dg-2_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ cjl-dgss-015_BONGO3.csv: 완료 (63,439행, 24.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m 🔄 처리 시작: naeibbo_BONGO3_202406.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 17.3% | 성공: 32 | 실패: 13 | 예상 남은 시간: 11분 18.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m ✅ cjl-dgss-013_PORTER2.csv: 완료 (85,141행, 18.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 파일 병합 중 오류 (Client V011BE0014): time data \"2025-07-16 00:19:12.266\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76211)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m 📦 naeibbo_BONGO3_202406.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m 🔄 처리 시작: bluesky8571_EV3 LONGRANGE_202504.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76675)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 17.7% | 성공: 33 | 실패: 13 | 예상 남은 시간: 11분 29.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ✅ jmmath_IONIQ5 LONGRANGE_202207.csv: 완료 (25,097행, 22.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 🔄 처리 시작: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 🔄 처리 시작: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 18.1% | 성공: 34 | 실패: 13 | 예상 남은 시간: 11분 16.8초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 18.5% | 성공: 34 | 실패: 14 | 예상 남은 시간: 11분 0.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 📦 s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 18.8% | 성공: 35 | 실패: 14 | 예상 남은 시간: 10분 56.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 📦 testbongo_BONGO3_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76211)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ lotteglogis-dg-2_BONGO3.csv: 완료 (77,227행, 17.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: polarbar_IONIQ6 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m ✅ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 완료 (15,846행, 7.2초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 19.2% | 성공: 36 | 실패: 14 | 예상 남은 시간: 10분 53.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 19.6% | 성공: 37 | 실패: 14 | 예상 남은 시간: 10분 39.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 🔄 처리 시작: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 20.0% | 성공: 37 | 실패: 15 | 예상 남은 시간: 10분 27.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 파일 병합 중 오류 (Client V021BI0003): time data \"2025-07-16 02:32:32.953\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 📦 test01_NIRO PLUS_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 📦 revu-n-15_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 20.4% | 성공: 38 | 실패: 15 | 예상 남은 시간: 10분 26.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ ha8519_EV9_202401.csv: 완료 (59,959행, 16.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 🔄 처리 시작: test01_NIRO PLUS_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76546)\u001b[0m ✅ bluesky8571_EV3 LONGRANGE_202504.csv: 완료 (26,812행, 18.9초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 20.8% | 성공: 39 | 실패: 15 | 예상 남은 시간: 10분 12.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 파일 병합 중 오류 (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 21.2% | 성공: 39 | 실패: 16 | 예상 남은 시간: 9분 60.0초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 21.5% | 성공: 40 | 실패: 16 | 예상 남은 시간: 9분 46.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76766)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m 파일 병합 중 오류 (Client V000CD0025): time data \"2025-07-16 00:02:13.084\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 21.9% | 성공: 41 | 실패: 16 | 예상 남은 시간: 9분 46.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 ltgyc-4_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 🔄 처리 시작: ddtaxi-1_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76562)\u001b[0m ✅ naeibbo_BONGO3_202406.csv: 완료 (93,783행, 25.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 파일 병합 중 오류 (Client TESTNIRO01): time data \"2025-07-16 11:29:15.204\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 18068. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 22.3% | 성공: 42 | 실패: 16 | 예상 남은 시간: 9분 47.4초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 22.7% | 성공: 43 | 실패: 16 | 예상 남은 시간: 9분 37.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ lbk5510_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (92,674행, 38.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76171)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 23.1% | 성공: 44 | 실패: 16 | 예상 남은 시간: 9분 26.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 23.5% | 성공: 45 | 실패: 16 | 예상 남은 시간: 9분 15.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ revu-n-15_EV6 LONGRANGE.csv: 완료 (28,964행, 13.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 🔄 처리 시작: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 📦 kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 📦 dibidib_EV9_202407.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: lotteglogis-dg-16_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ✅ cyberlmk_EV9_202308.csv: 완료 (59,212행, 20.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 파일 병합 중 오류 (Client V004BE0002): time data \"2025-07-16 02:29:06.309\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28964. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76826)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 📦 esm3100_BONGO3_202304.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ ltgyc-4_BONGO3.csv: 완료 (113,653행, 25.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 23.8% | 성공: 46 | 실패: 16 | 예상 남은 시간: 9분 57.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: wwweee_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 파일 병합 중 오류 (Client V018AL0000): time data \"2025-07-16 01:03:37.076\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21105. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 24.2% | 성공: 47 | 실패: 16 | 예상 남은 시간: 9분 52.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 24.6% | 성공: 48 | 실패: 16 | 예상 남은 시간: 9분 41.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 wwweee_BONGO3_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ lotteglogis-dg-16_PORTER2.csv: 완료 (74행, 19.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76957)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 파일 병합 중 오류 (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 📦 leejh824_GV70_202211.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75784)\u001b[0m ✅ ltgdg-23_BONGO3_2023.csv: 완료 (93,515행, 32.0초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 25.0% | 성공: 49 | 실패: 16 | 예상 남은 시간: 10분 7.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76957)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m 🔄 처리 시작: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 25.4% | 성공: 49 | 실패: 17 | 예상 남은 시간: 10분 6.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m 🔄 처리 시작: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 25.8% | 성공: 49 | 실패: 18 | 예상 남은 시간: 9분 55.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m 🔄 처리 시작: lee1174_EV6 LONGRANGE_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 파일 병합 중 오류 (Client V003BL0001): time data \"2025-07-16 00:00:01.651\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 26.2% | 성공: 50 | 실패: 18 | 예상 남은 시간: 9분 51.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ✅ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (32,955행, 39.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 파일 병합 중 오류 (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 26.5% | 성공: 51 | 실패: 18 | 예상 남은 시간: 9분 41.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ✅ ddtaxi-1_EV6 LONGRANGE_202201.csv: 완료 (63,962행, 47.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 26.9% | 성공: 52 | 실패: 18 | 예상 남은 시간: 9분 31.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 27.3% | 성공: 52 | 실패: 19 | 예상 남은 시간: 9분 20.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 🔄 처리 시작: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 🔄 처리 시작: ajutaxi-25_IONIQ 2019_201701.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 27.7% | 성공: 53 | 실패: 19 | 예상 남은 시간: 9분 12.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m 📦 lee1174_EV6 LONGRANGE_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 📦 revu-n-70_KONA LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 28.1% | 성공: 54 | 실패: 19 | 예상 남은 시간: 9분 7.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m 파일 병합 중 오류 (Client V021BJ0002): time data \"2025-07-16 00:00:00.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76689)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77118)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ wwweee_BONGO3_202304.csv: 완료 (35,332행, 25.4초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: revu-n-70_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: jtkim0601_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: kung417s_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 jtkim0601_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 📦 revu-n-41_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77118)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 파일 병합 중 오류 (Client V009BH0000): time data \"2025-07-16 02:56:13.968\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 📦 kung417s_EV6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 28.5% | 성공: 55 | 실패: 19 | 예상 남은 시간: 9분 23.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ✅ revu-n-70_KONA LONGRANGE.csv: 완료 (31,416행, 13.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 28.8% | 성공: 55 | 실패: 20 | 예상 남은 시간: 9분 14.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: dnwjdals1_IONIQ5 LONGRANGE_202107.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77137)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 📦 dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 29.2% | 성공: 56 | 실패: 20 | 예상 남은 시간: 9분 11.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ✅ leejh824_GV70_202211.csv: 완료 (42,763행, 37.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V007AL0000): time data \"2025-07-16 09:05:43.025\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28046. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 29.6% | 성공: 57 | 실패: 20 | 예상 남은 시간: 9분 6.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 🔄 처리 시작: lotteglogis-dg-28_BONGO3_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 파일 병합 중 오류 (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ jtkim0601_NIRO LONGRANGE_201808.csv: 완료 (28,046행, 12.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 30.0% | 성공: 58 | 실패: 20 | 예상 남은 시간: 9분 2.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ✅ ltgdg-13_PORTER2_2024.csv: 완료 (82,041행, 23.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77137)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m 📦 lotteglogis-dg-28_BONGO3_202309.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 🔄 처리 시작: cjl-gbyc-013_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 30.4% | 성공: 58 | 실패: 21 | 예상 남은 시간: 8분 54.0초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 30.8% | 성공: 58 | 실패: 22 | 예상 남은 시간: 8분 44.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 🔄 처리 시작: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 31.2% | 성공: 59 | 실패: 22 | 예상 남은 시간: 8분 38.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 31.5% | 성공: 60 | 실패: 22 | 예상 남은 시간: 8분 34.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 31.9% | 성공: 61 | 실패: 22 | 예상 남은 시간: 8분 25.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ✅ revu-n-41_EV6 LONGRANGE.csv: 완료 (32,157행, 26.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 📦 revu-n-20_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 파일 병합 중 오류 (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76957)\u001b[0m ✅ lee1174_EV6 LONGRANGE_202312.csv: 완료 (47,213행, 30.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 lijingice007_ST1_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: 48625ff_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 48625ff_EV6 LONGRANGE_202210.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: azking_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 🔄 처리 시작: 628dani_CASPER LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 32.3% | 성공: 62 | 실패: 22 | 예상 남은 시간: 8분 36.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m 📦 628dani_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75788)\u001b[0m ✅ lotteglogis-dg-28_BONGO3_202309.csv: 완료 (71,168행, 19.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 파일 병합 중 오류 (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 32.7% | 성공: 63 | 실패: 22 | 예상 남은 시간: 8분 32.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 33.1% | 성공: 63 | 실패: 23 | 예상 남은 시간: 8분 24.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: kimzizone2_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 azking_IONIQ5 LONGRANGE 2022_202207.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 🔄 처리 시작: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 📦 kimzizone2_IONIQ5 LONGRANGE_202203.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ✅ kung417s_EV6 LONGRANGE_202201.csv: 완료 (51,921행, 31.5초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 33.5% | 성공: 64 | 실패: 23 | 예상 남은 시간: 8분 28.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76767)\u001b[0m ✅ 628dani_CASPER LONGRANGE_202410.csv: 완료 (29,591행, 13.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77367)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m 🔄 처리 시작: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 파일 병합 중 오류 (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 33.8% | 성공: 65 | 실패: 23 | 예상 남은 시간: 8분 23.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76766)\u001b[0m ✅ revu-n-20_IONIQ5 LONGRANGE.csv: 완료 (34,356행, 24.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m 📦 pgtaxi-5_NIRO LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 🔄 처리 시작: revu-n-8_GV70.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 34.2% | 성공: 65 | 실패: 24 | 예상 남은 시간: 8분 25.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 🔄 처리 시작: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 📦 kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m 파일 병합 중 오류 (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77367)\u001b[0m ✅ pgtaxi-5_NIRO LONGRANGE.csv: 완료 (36,481행, 12.5초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 34.6% | 성공: 66 | 실패: 24 | 예상 남은 시간: 8분 30.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 📦 pgtaxi-4_IONIQ6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 35.0% | 성공: 67 | 실패: 24 | 예상 남은 시간: 8분 25.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ✅ dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 완료 (29,540행, 47.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76826)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 35.4% | 성공: 68 | 실패: 24 | 예상 남은 시간: 8분 18.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 📦 bbs001_IONIQ 2019_201710.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 파일 병합 중 오류 (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 35.8% | 성공: 69 | 실패: 24 | 예상 남은 시간: 8분 14.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ azking_IONIQ5 LONGRANGE 2022_202207.csv: 완료 (67,435행, 33.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77367)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ 48625ff_EV6 LONGRANGE_202210.csv: 완료 (56,986행, 37.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m 🔄 처리 시작: joiltaxi-21_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m 📦 joiltaxi-21_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 파일 병합 중 오류 (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 36.2% | 성공: 70 | 실패: 24 | 예상 남은 시간: 8분 21.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ✅ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (107,320행, 32.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 🔄 처리 시작: ltgdg-12_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 36.5% | 성공: 71 | 실패: 24 | 예상 남은 시간: 8분 20.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m ✅ bbs001_IONIQ 2019_201710.csv: 완료 (32,023행, 15.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 파일 병합 중 오류 (Client V020CA0000): time data \"2025-07-16 07:02:00.351\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 📦 ltgdg-12_PORTER2.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 🔄 처리 시작: sitestev6_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 36.9% | 성공: 72 | 실패: 24 | 예상 남은 시간: 8분 16.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77123)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 37.3% | 성공: 73 | 실패: 24 | 예상 남은 시간: 8분 8.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 37.7% | 성공: 73 | 실패: 25 | 예상 남은 시간: 8분 1.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 38.1% | 성공: 73 | 실패: 26 | 예상 남은 시간: 7분 53.4초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 38.5% | 성공: 73 | 실패: 27 | 예상 남은 시간: 7분 45.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 wildseven_SOUL LONGRANGE_201906.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ lijingice007_ST1_202411.csv: 완료 (52,239행, 57.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 📦 ltgdg-24_BONGO3_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 🔄 처리 시작: ltgdg-24_BONGO3_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 clausewitx_GV70_202210.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77611)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ wildseven_SOUL LONGRANGE_201906.csv: 완료 (9,073행, 12.0초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 38.8% | 성공: 74 | 실패: 27 | 예상 남은 시간: 7분 54.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 📦 sitestev6_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 39.2% | 성공: 74 | 실패: 28 | 예상 남은 시간: 7분 49.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: mkj2449_IONIQ5 LONGRANGE_202110.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77611)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 26x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 파일 병합 중 오류 (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77123)\u001b[0m ✅ ltgdg-24_BONGO3_2022.csv: 완료 (60,213행, 18.5초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 39.6% | 성공: 75 | 실패: 28 | 예상 남은 시간: 7분 52.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 40.0% | 성공: 76 | 실패: 28 | 예상 남은 시간: 7분 48.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 mkj2449_IONIQ5 LONGRANGE_202110.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77284)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 40.4% | 성공: 77 | 실패: 28 | 예상 남은 시간: 7분 42.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ✅ pgtaxi-4_IONIQ6 LONGRANGE.csv: 완료 (79,619행, 50.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 🔄 처리 시작: junhyuk0413_NIRO2_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 40.8% | 성공: 77 | 실패: 29 | 예상 남은 시간: 7분 35.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 🔄 처리 시작: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 41.2% | 성공: 77 | 실패: 30 | 예상 남은 시간: 7분 28.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 파일 병합 중 오류 (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m 🔄 처리 시작: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ✅ ltgdg-12_PORTER2.csv: 완료 (109,105행, 28.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77762)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 📦 aim21c_NIRO LONGRANGE_201801.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 🔄 처리 시작: aim21c_NIRO LONGRANGE_201801.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 파일 병합 중 오류 (Client V003CA0001): time data \"2025-07-16 00:00:02.491\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 41.5% | 성공: 78 | 실패: 30 | 예상 남은 시간: 7분 33.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (75,169행, 48.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m 📦 whote564_IONIQ5 LONGRANGE 2022_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m 파일 병합 중 오류 (Client V004BA0027): time data \"2025-07-16 03:20:48.641\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m 🔄 처리 시작: cjl-gbyc-016_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77495)\u001b[0m ✅ joiltaxi-21_EV6 LONGRANGE_202201.csv: 완료 (67,888행, 52.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 41.9% | 성공: 79 | 실패: 30 | 예상 남은 시간: 7분 32.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m 📦 cjl-gbyc-016_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 42.3% | 성공: 80 | 실패: 30 | 예상 남은 시간: 7분 27.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: hahakuhyun_EV6 LONGRANGE_202401.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 42.7% | 성공: 81 | 실패: 30 | 예상 남은 시간: 7분 21.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 파일 병합 중 오류 (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ✅ junhyuk0413_NIRO2_202209.csv: 완료 (13,135행, 15.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 43.1% | 성공: 82 | 실패: 30 | 예상 남은 시간: 7분 20.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77495)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 📦 ltgdg-32_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 🔄 처리 시작: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m 🔄 처리 시작: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 43.5% | 성공: 83 | 실패: 30 | 예상 남은 시간: 7분 20.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77284)\u001b[0m ✅ aim21c_NIRO LONGRANGE_201801.csv: 완료 (43,124행, 19.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ jinjinjw_IONIQ5 LONGRANGE_202202.csv: 완료 (6,657행, 9.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 파일 병합 중 오류 (Client SITESTEV6): time data \"2025-07-16 00:00:03.423\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76826)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 43.8% | 성공: 84 | 실패: 30 | 예상 남은 시간: 7분 15.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 44.2% | 성공: 85 | 실패: 30 | 예상 남은 시간: 7분 9.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: ocs7777_ST1_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: kate3070kr_GV70_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m ✅ hahakuhyun_EV6 LONGRANGE_202401.csv: 완료 (17,146행, 12.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 44.6% | 성공: 86 | 실패: 30 | 예상 남은 시간: 7분 7.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m 📦 yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77764)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 kate3070kr_GV70_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m 파일 병합 중 오류 (Client V012BE0139): time data \"2025-07-16 00:19:12.336\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77764)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 45.0% | 성공: 87 | 실패: 30 | 예상 남은 시간: 7분 3.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 pgtaxi-16_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 🔄 처리 시작: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ clausewitx_GV70_202210.csv: 완료 (30,539행, 55.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 📦 ehman486_EV3 LONGRANGE_202408.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 🔄 처리 시작: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 45.4% | 성공: 88 | 실패: 30 | 예상 남은 시간: 7분 5.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: ehman486_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 파일 병합 중 오류 (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ ehman486_EV3 LONGRANGE_202408.csv: 완료 (8,539행, 4.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 45.8% | 성공: 89 | 실패: 30 | 예상 남은 시간: 7분 0.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77423)\u001b[0m ✅ ltgdg-32_PORTER2_2023.csv: 완료 (79,293행, 25.5초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77423)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: xlos20_EV6 LONGRANGE_202101.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 📦 revu-n-64_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 📦 tsiyhj_EV6 LONGRANGE_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 46.2% | 성공: 90 | 실패: 30 | 예상 남은 시간: 6분 57.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ pgtaxi-16_EV6 LONGRANGE.csv: 완료 (1,006행, 11.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 📦 xlos20_EV6 LONGRANGE_202101.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 1006. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: sl-ev-1_EV6 LONGRANGE_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78030)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 파일 병합 중 오류 (Client V004BI0001): time data \"2025-07-16 06:42:06.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 sl-ev-1_EV6 LONGRANGE_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ✅ tsiyhj_EV6 LONGRANGE_202407.csv: 완료 (32,308행, 19.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 46.5% | 성공: 91 | 실패: 30 | 예상 남은 시간: 7분 2.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 🔄 처리 시작: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ✅ revu-n-64_EV6 LONGRANGE.csv: 완료 (26,666행, 17.7초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 46.9% | 성공: 92 | 실패: 30 | 예상 남은 시간: 6분 57.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 🔄 처리 시작: revu-n-63_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78030)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 47.3% | 성공: 93 | 실패: 30 | 예상 남은 시간: 6분 54.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77851)\u001b[0m ✅ yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv: 완료 (73,331행, 35.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 📦 revu-n-63_IONIQ5 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 파일 병합 중 오류 (Client V004BG0004): time data \"2025-07-16 07:46:12.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26666. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m 🔄 처리 시작: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m 📦 revu-n-11_KONA LONGRANGE_202104.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 파일 병합 중 오류 (Client V000CA0039): time data \"2025-07-16 00:00:01.556\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 📦 lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 47.7% | 성공: 94 | 실패: 30 | 예상 남은 시간: 6분 57.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ ocs7777_ST1_202407.csv: 완료 (61,131행, 42.2초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 48.1% | 성공: 95 | 실패: 30 | 예상 남은 시간: 6분 51.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ✅ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 완료 (50,650행, 1분 4.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m 🔄 처리 시작: legojeon_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: ltgyc-3_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m 📦 legojeon_NIRO LONGRANGE_201910.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77749)\u001b[0m ✅ legojeon_NIRO LONGRANGE_201910.csv: 완료 (5,708행, 2.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 48.5% | 성공: 96 | 실패: 30 | 예상 남은 시간: 6분 48.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 파일 병합 중 오류 (Client V004AK0000): time data \"2025-07-16 00:00:02.983\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 48.8% | 성공: 97 | 실패: 30 | 예상 남은 시간: 6분 44.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ xlos20_EV6 LONGRANGE_202101.csv: 완료 (34,058행, 31.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 ltgyc-3_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V004BE0009): time data \"2025-07-16 06:46:29.745\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78103)\u001b[0m 🔄 처리 시작: ltgdg-34_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 49.2% | 성공: 98 | 실패: 30 | 예상 남은 시간: 6분 40.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=76286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: cjl-dgds-011_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ sl-ev-1_EV6 LONGRANGE_2022.csv: 완료 (44,723행, 30.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 airme_EV6 LONGRANGE_202403.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m 파일 병합 중 오류 (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: airme_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m 🔄 처리 시작: lotteglogis-dg-34_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78030)\u001b[0m ✅ revu-n-11_KONA LONGRANGE_202104.csv: 완료 (64,097행, 26.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 49.6% | 성공: 99 | 실패: 30 | 예상 남은 시간: 6분 42.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 파일 병합 중 오류 (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 50.0% | 성공: 100 | 실패: 30 | 예상 남은 시간: 6분 39.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77286)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m 📦 lotteglogis-dg-34_PORTER2_202301.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 🔄 처리 시작: ltgdg-22_BONGO3_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ ltgyc-3_PORTER2.csv: 완료 (60,177행, 17.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 50.4% | 성공: 101 | 실패: 30 | 예상 남은 시간: 6분 38.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78103)\u001b[0m ✅ ltgdg-34_BONGO3.csv: 완료 (66,088행, 21.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ✅ revu-n-63_IONIQ5 LONGRANGE.csv: 완료 (65,280행, 35.9초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 50.8% | 성공: 102 | 실패: 30 | 예상 남은 시간: 6분 32.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 🔄 처리 시작: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 파일 병합 중 오류 (Client V000BG0012): time data \"2025-07-16 00:21:41.216\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 51.2% | 성공: 102 | 실패: 31 | 예상 남은 시간: 6분 26.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 🔄 처리 시작: leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 51.5% | 성공: 103 | 실패: 31 | 예상 남은 시간: 6분 21.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 🔄 처리 시작: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 51.9% | 성공: 103 | 실패: 32 | 예상 남은 시간: 6분 16.5초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 52.3% | 성공: 103 | 실패: 33 | 예상 남은 시간: 6분 11.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 ltgdg-22_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78244)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 파일 병합 중 오류 (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 52.7% | 성공: 104 | 실패: 33 | 예상 남은 시간: 6분 6.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 📦 leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 53.1% | 성공: 105 | 실패: 33 | 예상 남은 시간: 6분 1.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 🔄 처리 시작: parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ✅ lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 완료 (78,994행, 40.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: cjl-dgno-004_PORTER2.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78244)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 📦 parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=75980)\u001b[0m 📦 dmcdimo_EV6 LONGRANGE_202211.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m 🔄 처리 시작: needman_EV6 LONGRANGE_202403.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m 파일 병합 중 오류 (Client V011BD0010): time data \"2025-07-16 19:24:24.666\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 53.5% | 성공: 106 | 실패: 33 | 예상 남은 시간: 6분 6.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78169)\u001b[0m ✅ lotteglogis-dg-34_PORTER2_202301.csv: 완료 (69,096행, 23.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 53.8% | 성공: 106 | 실패: 34 | 예상 남은 시간: 6분 0.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 54.2% | 성공: 106 | 실패: 35 | 예상 남은 시간: 5분 55.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 54.6% | 성공: 107 | 실패: 35 | 예상 남은 시간: 5분 51.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m 📦 needman_EV6 LONGRANGE_202403.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: lotteglogis-dg-20_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 55.0% | 성공: 108 | 실패: 35 | 예상 남은 시간: 5분 46.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 55.4% | 성공: 109 | 실패: 35 | 예상 남은 시간: 5분 42.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 파일 병합 중 오류 (Client V012BE0021): time data \"2025-07-16 08:30:40.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ cjl-dgno-004_PORTER2.csv: 완료 (32,953행, 17.2초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 lotteglogis-dg-20_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 📦 yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m 📦 ltgdg-17_BONGO3_2024.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78401)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24182. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 55.8% | 성공: 110 | 실패: 35 | 예상 남은 시간: 5분 46.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ revu-n-25_NIRO2_202401.csv: 완료 (24,182행, 11.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 🔄 처리 시작: helleus77_EV6 STANDARD_202108.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78401)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 56.2% | 성공: 111 | 실패: 35 | 예상 남은 시간: 5분 43.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 📦 helleus77_EV6 STANDARD_202108.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 56.5% | 성공: 112 | 실패: 35 | 예상 남은 시간: 5분 40.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m 파일 병합 중 오류 (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 27019. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78282)\u001b[0m ✅ needman_EV6 LONGRANGE_202403.csv: 완료 (27,019행, 22.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ lotteglogis-dg-20_BONGO3.csv: 완료 (89,424행, 22.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78282)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ✅ leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (38,502행, 39.1초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 56.9% | 성공: 113 | 실패: 35 | 예상 남은 시간: 5분 36.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 파일 병합 중 오류 (Client V000CC0011): time data \"2025-07-16 00:00:03.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 57.3% | 성공: 114 | 실패: 35 | 예상 남은 시간: 5분 32.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77925)\u001b[0m ✅ parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (51,240행, 36.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 57.7% | 성공: 115 | 실패: 35 | 예상 남은 시간: 5분 28.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77286)\u001b[0m ✅ ltgdg-17_BONGO3_2024.csv: 완료 (107,697행, 23.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 cjl-dgss-012_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 🔄 처리 시작: hmp4522_EV3 LONGRANGE_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78502)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m 🔄 처리 시작: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 🔄 처리 시작: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 58.1% | 성공: 115 | 실패: 36 | 예상 남은 시간: 5분 25.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 🔄 처리 시작: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 58.5% | 성공: 116 | 실패: 36 | 예상 남은 시간: 5분 22.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m 📦 hmp4522_EV3 LONGRANGE_202502.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 파일 병합 중 오류 (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=76286)\u001b[0m ✅ helleus77_EV6 STANDARD_202108.csv: 완료 (33,318행, 17.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 📦 revu-n-18_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77925)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 58.8% | 성공: 117 | 실패: 36 | 예상 남은 시간: 5분 19.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (46,285행, 31.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: joiltaxi-8_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m 📦 cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 59.2% | 성공: 117 | 실패: 37 | 예상 남은 시간: 5분 15.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: ltgdg-21_PORTER2_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 59.6% | 성공: 117 | 실패: 38 | 예상 남은 시간: 5분 10.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: lotteglogis-dg-22_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 파일 병합 중 오류 (Client V003BA0012): time data \"2025-07-16 00:00:01.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77925)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 jmjang2_ST1_202405.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: jmjang2_ST1_202405.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 파일 병합 중 오류 (Client V011BE0013): time data \"2025-07-16 08:14:23.270\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 60.0% | 성공: 118 | 실패: 38 | 예상 남은 시간: 5분 11.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ✅ cjl-dgss-012_PORTER2.csv: 완료 (71,699행, 23.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78465)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: revu-n-66_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 60.4% | 성공: 119 | 실패: 38 | 예상 남은 시간: 5분 6.8초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 60.8% | 성공: 119 | 실패: 39 | 예상 남은 시간: 5분 2.0초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 61.2% | 성공: 120 | 실패: 39 | 예상 남은 시간: 4분 58.7초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 61.5% | 성공: 121 | 실패: 39 | 예상 남은 시간: 4분 54.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 revu-n-66_EV6 LONGRANGE_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 파일 병합 중 오류 (Client V011BD0008): time data \"2025-07-16 00:16:14.729\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ lotteglogis-dg-22_PORTER2_202301.csv: 완료 (31,080행, 12.1초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 🔄 처리 시작: parksw7022_IONIQ6 STANDARD_202502.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (40,270행, 29.9초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 61.9% | 성공: 122 | 실패: 39 | 예상 남은 시간: 4분 50.7초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 62.3% | 성공: 122 | 실패: 40 | 예상 남은 시간: 4분 46.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 🔄 처리 시작: reviewshare-4_KONA LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 📦 reviewshare-4_KONA LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 mamon_ST1_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 파일 병합 중 오류 (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24775. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: junsuck86_EV6 LONGRANGE_202304.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 62.7% | 성공: 123 | 실패: 40 | 예상 남은 시간: 4분 44.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ✅ parksw7022_IONIQ6 STANDARD_202502.csv: 완료 (24,775행, 10.5초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ✅ reviewshare-4_KONA LONGRANGE.csv: 완료 (13,310행, 4.8초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 63.1% | 성공: 124 | 실패: 40 | 예상 남은 시간: 4분 40.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 🔄 처리 시작: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 63.5% | 성공: 124 | 실패: 41 | 예상 남은 시간: 4분 35.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=75980)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m 📦 giugi_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 📦 zoh71z_KONA LONGRANGE_201810.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 🔄 처리 시작: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 🔄 처리 시작: bbotti_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 63.8% | 성공: 125 | 실패: 41 | 예상 남은 시간: 4분 34.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78515)\u001b[0m ✅ giugi_EV6 LONGRANGE.csv: 완료 (6,401행, 5.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78502)\u001b[0m ✅ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 완료 (60,242행, 35.2초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 64.2% | 성공: 126 | 실패: 41 | 예상 남은 시간: 4분 30.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 📦 bbotti_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 파일 병합 중 오류 (Client V004BH0002): time data \"2025-07-16 01:08:28.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 64.6% | 성공: 127 | 실패: 41 | 예상 남은 시간: 4분 28.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ✅ revu-n-66_EV6 LONGRANGE_202304.csv: 완료 (47,240행, 22.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78731)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 65.0% | 성공: 127 | 실패: 42 | 예상 남은 시간: 4분 24.4초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 65.4% | 성공: 128 | 실패: 42 | 예상 남은 시간: 4분 20.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 65.8% | 성공: 128 | 실패: 43 | 예상 남은 시간: 4분 15.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 📦 mxri13_GV60_202307.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 66.2% | 성공: 129 | 실패: 43 | 예상 남은 시간: 4분 12.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 66.5% | 성공: 130 | 실패: 43 | 예상 남은 시간: 4분 9.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 파일 병합 중 오류 (Client V009BL0000): time data \"2025-07-16 00:00:02.657\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77939)\u001b[0m ✅ hmp4522_EV3 LONGRANGE_202502.csv: 완료 (74,081행, 50.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 🔄 처리 시작: mxri13_GV60_202307.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 66.9% | 성공: 131 | 실패: 43 | 예상 남은 시간: 4분 5.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m 🔄 처리 시작: fojokr_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 daegitaxi-2_IONIQ5 LONGRANGE_202207.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78778)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ junsuck86_EV6 LONGRANGE_202304.csv: 완료 (20,326행, 22.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m 🔄 처리 시작: hmc1006_ST1_202504.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m 📦 fojokr_CASPER LONGRANGE_202410.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 runmanzzang_ST1_202507.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 67.3% | 성공: 132 | 실패: 43 | 예상 남은 시간: 4분 5.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 파일 병합 중 오류 (Client V015BK0000): time data \"2025-07-16 00:00:02.714\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 7999. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 67.7% | 성공: 132 | 실패: 44 | 예상 남은 시간: 4분 1.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 68.1% | 성공: 132 | 실패: 45 | 예상 남은 시간: 3분 57.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78634)\u001b[0m ✅ mxri13_GV60_202307.csv: 완료 (7,999행, 13.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: pyh8965_EV6 LONGRANGE_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ✅ bbotti_IONIQ5 LONGRANGE.csv: 완료 (47,967행, 24.1초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 68.5% | 성공: 133 | 실패: 45 | 예상 남은 시간: 3분 54.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 🔄 처리 시작: heo3252_KONA LONGRANGE_201901.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78634)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 📦 heo3252_KONA LONGRANGE_201901.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 파일 병합 중 오류 (Client V000BE0017): time data \"2025-07-16 00:00:01.186\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 pyh8965_EV6 LONGRANGE_202406.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 68.8% | 성공: 134 | 실패: 45 | 예상 남은 시간: 3분 52.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ jmjang2_ST1_202405.csv: 완료 (58,327행, 54.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: emob-2_IONIQ 2019.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 emob-2_IONIQ 2019.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 69.2% | 성공: 135 | 실패: 45 | 예상 남은 시간: 3분 51.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 파일 병합 중 오류 (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ✅ heo3252_KONA LONGRANGE_201901.csv: 완료 (47,872행, 13.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 🔄 처리 시작: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 69.6% | 성공: 136 | 실패: 45 | 예상 남은 시간: 3분 47.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: cjl-dgea-008_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 70.0% | 성공: 136 | 실패: 46 | 예상 남은 시간: 3분 43.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: 1357rqwe_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 70.4% | 성공: 137 | 실패: 46 | 예상 남은 시간: 3분 39.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 📦 lee5957_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78947)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 70.8% | 성공: 138 | 실패: 46 | 예상 남은 시간: 3분 38.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 파일 병합 중 오류 (Client V020BD0000): time data \"2025-07-16 17:13:12.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28250. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ emob-2_IONIQ 2019.csv: 완료 (28,250행, 7.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: ddongkolip_ST1_202405.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78779)\u001b[0m ✅ fojokr_CASPER LONGRANGE_202410.csv: 완료 (60,311행, 32.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 ddongkolip_ST1_202405.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78947)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 71.2% | 성공: 139 | 실패: 46 | 예상 남은 시간: 3분 35.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: cjl-gbyc-018_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 71.5% | 성공: 139 | 실패: 47 | 예상 남은 시간: 3분 31.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: ksy-taxi-p1_EV6 LONGRANGE_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 71.9% | 성공: 139 | 실패: 48 | 예상 남은 시간: 3분 27.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: revu-n-21_EV9.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 72.3% | 성공: 140 | 실패: 48 | 예상 남은 시간: 3분 24.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 72.7% | 성공: 140 | 실패: 49 | 예상 남은 시간: 3분 20.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 revu-n-22_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ pyh8965_EV6 LONGRANGE_202406.csv: 완료 (38,361행, 26.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 73.1% | 성공: 141 | 실패: 49 | 예상 남은 시간: 3분 18.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=77938)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=77938)\u001b[0m ✅ hmc1006_ST1_202504.csv: 완료 (24,105행, 42.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 📦 ltgdg-1_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 73.5% | 성공: 142 | 실패: 49 | 예상 남은 시간: 3분 16.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 완료 (4,527행, 10.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 ddtaxi-4_KONA LONGRANGE_201901.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 파일 병합 중 오류 (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: ddtaxi-4_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 73.8% | 성공: 143 | 실패: 49 | 예상 남은 시간: 3분 13.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78643)\u001b[0m ✅ lee5957_IONIQ5 LONGRANGE.csv: 완료 (37,134행, 24.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79021)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 74.2% | 성공: 144 | 실패: 49 | 예상 남은 시간: 3분 10.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 📦 eha031_PORTER2_202211.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ✅ eha031_PORTER2_202211.csv: 완료 (9,515행, 4.0초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 74.6% | 성공: 144 | 실패: 50 | 예상 남은 시간: 3분 7.1초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 75.0% | 성공: 145 | 실패: 50 | 예상 남은 시간: 3분 3.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 🔄 처리 시작: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 75.4% | 성공: 145 | 실패: 51 | 예상 남은 시간: 3분 0.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 파일 병합 중 오류 (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 75.8% | 성공: 146 | 실패: 51 | 예상 남은 시간: 2분 56.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 76.2% | 성공: 147 | 실패: 51 | 예상 남은 시간: 2분 53.1초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 76.5% | 성공: 148 | 실패: 51 | 예상 남은 시간: 2분 49.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78731)\u001b[0m ✅ ldw8482_EV6 LONGRANGE_202204.csv: 완료 (35,215행, 1분 2.2초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 🔄 처리 시작: lotteglogis-dg-31_PORTER2_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78731)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 📦 lotteglogis-dg-31_PORTER2_202401.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 파일 병합 중 오류 (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79135)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 myhkk1797_EV3 LONGRANGE_202402.csv: 5개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m 🔄 처리 시작: ssa1011_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 파일 병합 중 오류 (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 76.9% | 성공: 149 | 실패: 51 | 예상 남은 시간: 2분 50.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ✅ kepco-1_IONIQ5 LONGRANGE_202110.csv: 완료 (31,243행, 24.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 🔄 처리 시작: ltgdg-33_PORTER2_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2140 MiB, 54 objects, write throughput 436 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m 📦 ssa1011_KONA LONGRANGE 2세대_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 📦 ltgdg-33_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m 🔄 처리 시작: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79200)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 파일 병합 중 오류 (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m 📦 revu-n-38_IONIQ5 LONGRANGE 2022.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79161)\u001b[0m ✅ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 완료 (18,047행, 18.6초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 77.3% | 성공: 150 | 실패: 51 | 예상 남은 시간: 2분 52.2초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 77.7% | 성공: 151 | 실패: 51 | 예상 남은 시간: 2분 48.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ✅ lotteglogis-dg-31_PORTER2_202401.csv: 완료 (73,558행, 33.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 🔄 처리 시작: ky80901_ST1_202406.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 78.1% | 성공: 152 | 실패: 51 | 예상 남은 시간: 2분 45.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ revu-n-22_EV6 LONGRANGE.csv: 완료 (58,747행, 55.7초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 78.5% | 성공: 152 | 실패: 52 | 예상 남은 시간: 2분 41.6초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 78.8% | 성공: 153 | 실패: 52 | 예상 남은 시간: 2분 38.1초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 79.2% | 성공: 153 | 실패: 53 | 예상 남은 시간: 2분 34.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m 🔄 처리 시작: dlcksgh3595_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 79.6% | 성공: 154 | 실패: 53 | 예상 남은 시간: 2분 31.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m 📦 hophip5677_CASPER LONGRANGE_202408.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 파일 병합 중 오류 (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ✅ ssa1011_KONA LONGRANGE 2세대_202301.csv: 완료 (44,011행, 23.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79022)\u001b[0m ✅ ltgdg-33_PORTER2_2023.csv: 완료 (37,026행, 23.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m 🔄 처리 시작: hophip5677_CASPER LONGRANGE_202408.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 ddtaxi-5_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 📦 ky80901_ST1_202406.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m 🔄 처리 시작: ignatius9107_IONIQ5 N NE_202502.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79022)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 80.0% | 성공: 155 | 실패: 53 | 예상 남은 시간: 2분 31.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79135)\u001b[0m ✅ hophip5677_CASPER LONGRANGE_202408.csv: 완료 (26,141행, 16.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 파일 병합 중 오류 (Client V004BA0030): time data \"2025-07-16 00:00:00.965\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m 📦 ignatius9107_IONIQ5 N NE_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 80.4% | 성공: 156 | 실패: 53 | 예상 남은 시간: 2분 28.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 🔄 처리 시작: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m 🔄 처리 시작: revu-n-27_EV9.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79135)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m 📦 revu-n-27_EV9.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ✅ joiltaxi-26_EV6 LONGRANGE_202201.csv: 완료 (116,046행, 57.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 📦 yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79450)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=79487)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 80.8% | 성공: 157 | 실패: 53 | 예상 남은 시간: 2분 30.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 완료 (52,762행, 1분 18.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: kgs0002_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 kgs0002_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 81.2% | 성공: 158 | 실패: 53 | 예상 남은 시간: 2분 28.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ ddongkolip_ST1_202405.csv: 완료 (105,559행, 1분 57.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: ltgdg-5_PORTER2_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m 파일 병합 중 오류 (Client V021BE0000): time data \"2025-07-16 00:27:35.894\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 81.5% | 성공: 159 | 실패: 53 | 예상 남은 시간: 2분 25.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 ltgdg-5_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 81.9% | 성공: 159 | 실패: 54 | 예상 남은 시간: 2분 22.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 🔄 처리 시작: revu-n-4_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79612)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79317)\u001b[0m ✅ ignatius9107_IONIQ5 N NE_202502.csv: 완료 (42,337행, 46.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79410)\u001b[0m ✅ revu-n-27_EV9.csv: 완료 (44,570행, 32.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 🔄 처리 시작: lotteglogis-dg-33_PORTER2_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 82.3% | 성공: 160 | 실패: 54 | 예상 남은 시간: 2분 19.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 📦 revu-n-4_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79650)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m 🔄 처리 시작: adreamcar_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 파일 병합 중 오류 (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ ltgdg-5_PORTER2_2023.csv: 완료 (42,482행, 13.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 82.7% | 성공: 161 | 실패: 54 | 예상 남은 시간: 2분 16.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m 📦 adreamcar_PORTER2_202301.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 hyisjung_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 83.1% | 성공: 162 | 실패: 54 | 예상 남은 시간: 2분 13.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ✅ yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (94,679행, 49.2초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 83.5% | 성공: 163 | 실패: 54 | 예상 남은 시간: 2분 10.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 🔄 처리 시작: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m 파일 병합 중 오류 (Client V011AI0001): time data \"2025-07-16 00:55:01.025\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19216. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79650)\u001b[0m ✅ adreamcar_PORTER2_202301.csv: 완료 (19,216행, 5.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79676)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 🔄 처리 시작: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 📦 ksjksj87_EV3 LONGRANGE_202409.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ hyisjung_NIRO LONGRANGE_201808.csv: 완료 (13,350행, 7.7초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 83.8% | 성공: 164 | 실패: 54 | 예상 남은 시간: 2분 7.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 🔄 처리 시작: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 84.2% | 성공: 165 | 실패: 54 | 예상 남은 시간: 2분 3.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: jhs3101_PORTER2_202002.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 📦 ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 jhs3101_PORTER2_202002.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 파일 병합 중 오류 (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13350. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ✅ myhkk1797_EV3 LONGRANGE_202402.csv: 완료 (135,275행, 1분 49.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m 📦 revu-n-58_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79738)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 84.6% | 성공: 166 | 실패: 54 | 예상 남은 시간: 2분 2.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 파일 병합 중 오류 (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m ✅ ksjksj87_EV3 LONGRANGE_202409.csv: 완료 (39,752행, 14.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 🔄 처리 시작: ltgdg-3_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 85.0% | 성공: 167 | 실패: 54 | 예상 남은 시간: 1분 58.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ✅ revu-n-4_EV6 LONGRANGE.csv: 완료 (50,873행, 28.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79738)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 85.4% | 성공: 168 | 실패: 54 | 예상 남은 시간: 1분 55.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 📦 ltgdg-3_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ ddtaxi-5_EV6 LONGRANGE_202201.csv: 완료 (78,401행, 1분 25.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 🔄 처리 시작: ltgdg-6_PORTER2_2024.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78283)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: joiltaxi-1_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 85.8% | 성공: 168 | 실패: 55 | 예상 남은 시간: 1분 52.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: revu-u-5_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 revu-u-5_IONIQ5 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 파일 병합 중 오류 (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ✅ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 완료 (30,521행, 28.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 86.2% | 성공: 169 | 실패: 55 | 예상 남은 시간: 1분 50.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79676)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 🔄 처리 시작: vitadoice11_IONIQ5 LONGRANGE_202106.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 📦 vitadoice11_IONIQ5 LONGRANGE_202106.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 86.5% | 성공: 170 | 실패: 55 | 예상 남은 시간: 1분 47.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78555)\u001b[0m ✅ revu-n-58_EV6 LONGRANGE.csv: 완료 (38,846행, 30.7초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 86.9% | 성공: 171 | 실패: 55 | 예상 남은 시간: 1분 44.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ✅ ltgdg-6_PORTER2_2024.csv: 완료 (80,996행, 21.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 🔄 처리 시작: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79853)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 87.3% | 성공: 171 | 실패: 56 | 예상 남은 시간: 1분 40.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 87.7% | 성공: 171 | 실패: 57 | 예상 남은 시간: 1분 37.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 📦 js5540810_IONIQ 2019_201607.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 88.1% | 성공: 172 | 실패: 57 | 예상 남은 시간: 1분 34.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 파일 병합 중 오류 (Client V000CA0025): time data \"2025-07-16 19:03:40.895\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 3966. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 88.5% | 성공: 173 | 실패: 57 | 예상 남은 시간: 1분 31.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 📦 ntragic_EV6 LONGRANGE_202005.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ kgs0002_EV6 LONGRANGE_202205.csv: 완료 (51,054행, 1분 8.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 🔄 처리 시작: ntragic_EV6 LONGRANGE_202005.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 88.8% | 성공: 174 | 실패: 57 | 예상 남은 시간: 1분 27.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 89.2% | 성공: 175 | 실패: 57 | 예상 남은 시간: 1분 24.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78465)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 파일 병합 중 오류 (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 📦 yaa7890_PORTER2_202003.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 파일 병합 중 오류 (Client V000BE0032): time data \"2025-07-18 08:44:22.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 89.6% | 성공: 176 | 실패: 57 | 예상 남은 시간: 1분 21.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ revu-u-5_IONIQ5 LONGRANGE_202201.csv: 완료 (50,362행, 23.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 90.0% | 성공: 177 | 실패: 57 | 예상 남은 시간: 1분 18.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 lotteglogis-dg-10_PORTER2_202310.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 파일 병합 중 오류 (Client V000CC0085): time data \"2025-07-16 00:19:02.185\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 90.4% | 성공: 178 | 실패: 57 | 예상 남은 시간: 1분 15.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79977)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 90.8% | 성공: 179 | 실패: 57 | 예상 남은 시간: 1분 12.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79676)\u001b[0m ✅ vitadoice11_IONIQ5 LONGRANGE_202106.csv: 완료 (38,330행, 23.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 🔄 처리 시작: norchia_IONIQ5 LONGRANGE_202203.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 📦 norchia_IONIQ5 LONGRANGE_202203.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 91.2% | 성공: 180 | 실패: 57 | 예상 남은 시간: 1분 9.5초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 91.5% | 성공: 181 | 실패: 57 | 예상 남은 시간: 1분 6.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78555)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=79978)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 91.9% | 성공: 182 | 실패: 57 | 예상 남은 시간: 1분 3.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 파일 병합 중 오류 (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6954. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79878)\u001b[0m ✅ lotteglogis-dg-1_PORTER2_202306.csv: 완료 (6,954행, 3.2초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79021)\u001b[0m 🔄 처리 시작: cjosooo_ST1_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79977)\u001b[0m 📦 cjawl74_PORTER2_202412.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ✅ norchia_IONIQ5 LONGRANGE_202203.csv: 완료 (15,081행, 11.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m 🔄 처리 시작: lotteglogis-dg-7_PORTER2_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m 📦 lotteglogis-dg-7_PORTER2_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80131)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 20x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 파일 병합 중 오류 (Client V011BD0005): time data \"2025-07-16 08:49:29.144\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 📦 testev9_EV9_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 92.3% | 성공: 183 | 실패: 57 | 예상 남은 시간: 1분 1.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ lotteglogis-dg-10_PORTER2_202310.csv: 완료 (59,777행, 34.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 🔄 처리 시작: gildagray_EV3 LONGRANGE_202411.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m 📦 gildagray_EV3 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 🔄 처리 시작: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 📦 yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 파일 병합 중 오류 (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 92.7% | 성공: 184 | 실패: 57 | 예상 남은 시간: 59.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78946)\u001b[0m ✅ testev9_EV9_2023.csv: 완료 (60,096행, 28.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=78946)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 93.1% | 성공: 185 | 실패: 57 | 예상 남은 시간: 56.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 🔄 처리 시작: kor87_NIRO PLUS_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 93.5% | 성공: 186 | 실패: 57 | 예상 남은 시간: 53.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m 📦 kor87_NIRO PLUS_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m 파일 병합 중 오류 (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ✅ lotteglogis-dg-7_PORTER2_202311.csv: 완료 (56,141행, 32.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ✅ yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (8,599행, 11.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 93.8% | 성공: 187 | 실패: 57 | 예상 남은 시간: 49.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 🔄 처리 시작: wntjdgml_CASPER LONGRANGE_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80144)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 94.2% | 성공: 188 | 실패: 57 | 예상 남은 시간: 46.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 📦 wntjdgml_CASPER LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m 🔄 처리 시작: lotteglogis-dg-8_PORTER2_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m 📦 emr4540_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78283)\u001b[0m ✅ gildagray_EV3 LONGRANGE_202411.csv: 완료 (38,865행, 23.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79978)\u001b[0m ✅ emr4540_CASPER LONGRANGE_202410.csv: 완료 (14,724행, 9.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 94.6% | 성공: 189 | 실패: 57 | 예상 남은 시간: 43.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=79978)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 파일 병합 중 오류 (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 95.0% | 성공: 190 | 실패: 57 | 예상 남은 시간: 40.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ✅ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 완료 (108,798행, 1분 8.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m 📦 lotteglogis-dg-8_PORTER2_202308.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 🔄 처리 시작: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 95.4% | 성공: 191 | 실패: 57 | 예상 남은 시간: 37.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 🔄 처리 시작: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ jsmtnaud_IONIQ5 LONGRANGE_202201.csv: 완료 (35,498행, 1분 8.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 📦 beston_IONIQ6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 📦 bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m 🔄 처리 시작: musein_EV9_202404.csv\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 95.8% | 성공: 192 | 실패: 57 | 예상 남은 시간: 34.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79572)\u001b[0m ✅ kor87_NIRO PLUS_202207.csv: 완료 (17,267행, 17.4초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 96.2% | 성공: 193 | 실패: 57 | 예상 남은 시간: 31.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 파일 병합 중 오류 (Client V000CA0008): time data \"2025-07-16 06:32:03.805\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ✅ wntjdgml_CASPER LONGRANGE_202408.csv: 완료 (32,987행, 14.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 🔄 처리 시작: cjl-gbyc-010_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m 📦 cjl-gbyc-010_BONGO3.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 96.5% | 성공: 193 | 실패: 58 | 예상 남은 시간: 27.9초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 96.9% | 성공: 193 | 실패: 59 | 예상 남은 시간: 24.7초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 97.3% | 성공: 193 | 실패: 60 | 예상 남은 시간: 21.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80375)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 97.7% | 성공: 194 | 실패: 60 | 예상 남은 시간: 18.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80144)\u001b[0m ✅ cjl-gbyc-010_BONGO3.csv: 완료 (68행, 1.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m 파일 병합 중 오류 (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80374)\u001b[0m 🔄 처리 시작: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m 📦 musein_EV9_202404.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 98.1% | 성공: 195 | 실패: 60 | 예상 남은 시간: 15.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80281)\u001b[0m ✅ lotteglogis-dg-8_PORTER2_202308.csv: 완료 (84,620행, 23.5초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 98.5% | 성공: 196 | 실패: 60 | 예상 남은 시간: 12.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 파일 병합 중 오류 (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m ✅ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (49,756행, 20.3초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 98.8% | 성공: 197 | 실패: 60 | 예상 남은 시간: 9.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78465)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=79977)\u001b[0m ✅ cjawl74_PORTER2_202412.csv: 완료 (135,761행, 1분 14.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80344)\u001b[0m ✅ musein_EV9_202404.csv: 완료 (47,696행, 18.6초)\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 99.2% | 성공: 198 | 실패: 60 | 예상 남은 시간: 6.1초\n",
      "\u001b[36m(ProgressTracker pid=75783)\u001b[0m 📊 진행률: 99.6% | 성공: 199 | 실패: 60 | 예상 남은 시간: 3.1초\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 200개 | ❌ 실패: 60개\n",
      "📊 총 처리 행 수: 9,688,061행\n",
      "⏱️  총 소요시간: 13분 17.4초\n",
      "⚡ 평균 파일당: 3.1초\n",
      "\n",
      "❌ 실패한 파일들:\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 13분 17.4초\n",
      "   - 파일당 평균: 3.1초\n",
      "   - 성공률: 76.9%\n",
      "   - 총 처리 행 수: 9,688,061행\n",
      "   - 시간당 처리량: 43739129행/시간\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 파일 병합 중 오류 (Client V013AK0001): time data \"2025-07-16 00:00:02.935\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=78778)\u001b[0m ✅ beston_IONIQ6 LONGRANGE_202201.csv: 완료 (40,009행, 22.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80388)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:44:06,463\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 200개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m 🔄 처리 시작: ekfmd3152_KONA LONGRANGE_202004.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m 🔄 처리 시작: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 0.5% | 성공: 0 | 실패: 1 | 예상 남은 시간: 3분 35.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 1.0% | 성공: 0 | 실패: 2 | 예상 남은 시간: 1분 49.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 1.5% | 성공: 0 | 실패: 3 | 예상 남은 시간: 1분 16.1초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 2.0% | 성공: 0 | 실패: 4 | 예상 남은 시간: 1분 2.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 rlaxo120_KONA LONGRANGE_201811.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=80554)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 📦 emob-1_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m 🔄 처리 시작: revu-n-34_GV70.csv\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 🔄 처리 시작: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m 📦 revu-n-34_GV70.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m 파일 병합 중 오류 (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13550. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80524)\u001b[0m ✅ ekfmd3152_KONA LONGRANGE_202004.csv: 완료 (13,550행, 7.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 2.5% | 성공: 1 | 실패: 4 | 예상 남은 시간: 5분 40.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m 📦 pgtaxi-15_IONIQ6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 3.0% | 성공: 2 | 실패: 4 | 예상 남은 시간: 5분 43.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 cjl-dgds-006_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80574)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 3.5% | 성공: 3 | 실패: 4 | 예상 남은 시간: 9분 2.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 파일 병합 중 오류 (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ rlaxo120_KONA LONGRANGE_201811.csv: 완료 (38,620행, 9.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80519)\u001b[0m ✅ ajutaxi-9_IONIQ 2019_201701.csv: 완료 (71,425행, 18.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 4.0% | 성공: 4 | 실패: 4 | 예상 남은 시간: 8분 4.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80525)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m 🔄 처리 시작: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 파일 병합 중 오류 (Client V000BD0002): time data \"2025-07-16 08:00:34.338\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 4.5% | 성공: 5 | 실패: 4 | 예상 남은 시간: 7분 25.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ✅ emob-1_IONIQ5 LONGRANGE.csv: 완료 (43,419행, 19.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 🔄 처리 시작: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 ltgdg-14_BONGO3_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ alice2235_PORTER2_202201.csv: 완료 (69,458행, 19.1초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 5.0% | 성공: 6 | 실패: 4 | 예상 남은 시간: 8분 4.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: ltgdg-14_BONGO3_2022.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80663)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 5.5% | 성공: 7 | 실패: 4 | 예상 남은 시간: 7분 45.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m 파일 병합 중 오류 (Client V013BL0002): time data \"2025-07-16 10:31:35.120\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80526)\u001b[0m ✅ pgtaxi-15_IONIQ6 LONGRANGE.csv: 완료 (58,846행, 24.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ✅ revu-n-68_EV6 LONGRANGE.csv: 완료 (37,780행, 25.2초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 6.0% | 성공: 8 | 실패: 4 | 예상 남은 시간: 7분 24.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m 📦 ajutaxi-27_IONIQ 2019_201701.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 파일 병합 중 오류 (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ cjl-dgds-006_PORTER2.csv: 완료 (69,957행, 17.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 📦 revu-n-32_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 6.5% | 성공: 9 | 실패: 4 | 예상 남은 시간: 7분 13.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80523)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 sihehe_NIRO2_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m ✅ revu-n-34_GV70.csv: 완료 (81,578행, 28.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80663)\u001b[0m 🔄 처리 시작: yitaxi-8_EV6 LONGRANGE_202209.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ ltgdg-14_BONGO3_2022.csv: 완료 (30,281행, 14.1초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 7.0% | 성공: 10 | 실패: 4 | 예상 남은 시간: 7분 41.9초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 7.5% | 성공: 11 | 실패: 4 | 예상 남은 시간: 8분 8.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 jct4589_SOUL LONGRANGE_201903.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: jct4589_SOUL LONGRANGE_201903.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 🔄 처리 시작: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80574)\u001b[0m ✅ ajutaxi-27_IONIQ 2019_201701.csv: 완료 (80,948행, 19.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 📦 revu-n-48_NIRO LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 8.0% | 성공: 12 | 실패: 4 | 예상 남은 시간: 8분 10.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ sihehe_NIRO2_202207.csv: 완료 (53,601행, 14.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: pity2002_IONIQ5 LONGRANGE_202111.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 8.5% | 성공: 13 | 실패: 4 | 예상 남은 시간: 8분 2.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 pity2002_IONIQ5 LONGRANGE_202111.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ pity2002_IONIQ5 LONGRANGE_202111.csv: 완료 (667행, 2.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: junghun1155_EV6 LONGRANGE_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 9.0% | 성공: 13 | 실패: 5 | 예상 남은 시간: 7분 34.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: stock_EV9_202307.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 9.5% | 성공: 14 | 실패: 5 | 예상 남은 시간: 7분 24.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 파일 병합 중 오류 (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ jct4589_SOUL LONGRANGE_201903.csv: 완료 (26,020행, 11.8초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 10.0% | 성공: 15 | 실패: 5 | 예상 남은 시간: 7분 9.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: caifa0622_IONIQ5 LONGRANGE_202107.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ✅ ltgdg-18_PORTER2_2023.csv: 완료 (56,124행, 19.5초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 10.5% | 성공: 16 | 실패: 5 | 예상 남은 시간: 7분 2.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 caifa0622_IONIQ5 LONGRANGE_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80528)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 🔄 처리 시작: j227_KONA LONGRANGE 2세대_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 11.0% | 성공: 17 | 실패: 5 | 예상 남은 시간: 7분 7.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m 파일 병합 중 오류 (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80523)\u001b[0m ✅ man8243_IONIQ5 LONGRANGE_202204.csv: 완료 (34,286행, 16.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ revu-n-48_NIRO LONGRANGE.csv: 완료 (32,613행, 12.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 🔄 처리 시작: cjl-gbyc-003_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 11.5% | 성공: 17 | 실패: 6 | 예상 남은 시간: 6분 48.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 🔄 처리 시작: cjl-dgea-016_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 파일 병합 중 오류 (Client V004BE0011): time data \"2025-07-16 04:35:21.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 stock_EV9_202307.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 12.0% | 성공: 18 | 실패: 6 | 예상 남은 시간: 6분 46.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 12.5% | 성공: 19 | 실패: 6 | 예상 남은 시간: 6분 28.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80663)\u001b[0m ✅ yitaxi-8_EV6 LONGRANGE_202209.csv: 완료 (29,325행, 21.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 📦 j227_KONA LONGRANGE 2세대_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 13.0% | 성공: 19 | 실패: 7 | 예상 남은 시간: 6분 16.0초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 13.5% | 성공: 19 | 실패: 8 | 예상 남은 시간: 6분 1.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80663)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 📦 ajutaxi-14_IONIQ5 STANDARD_202202.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ✅ revu-n-32_EV6 LONGRANGE.csv: 완료 (89,842행, 34.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m 🔄 처리 시작: ajutaxi-14_IONIQ5 STANDARD_202202.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80893)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 📦 cjl-dgss-013_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 🔄 처리 시작: cjl-dgss-013_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ caifa0622_IONIQ5 LONGRANGE_202107.csv: 완료 (46,816행, 23.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 14.0% | 성공: 20 | 실패: 8 | 예상 남은 시간: 7분 10.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 파일 병합 중 오류 (Client V022BL0000): time data \"2025-07-16 01:17:05.000\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 14.5% | 성공: 21 | 실패: 8 | 예상 남은 시간: 7분 1.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ✅ j227_KONA LONGRANGE 2세대_202311.csv: 완료 (63,987행, 19.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 15.0% | 성공: 22 | 실패: 8 | 예상 남은 시간: 6분 51.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 15.5% | 성공: 23 | 실패: 8 | 예상 남은 시간: 6분 37.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m 🔄 처리 시작: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 16.0% | 성공: 23 | 실패: 9 | 예상 남은 시간: 6분 24.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m 🔄 처리 시작: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 16.5% | 성공: 24 | 실패: 9 | 예상 남은 시간: 6분 11.0초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 17.0% | 성공: 24 | 실패: 10 | 예상 남은 시간: 5분 58.5초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 17.5% | 성공: 25 | 실패: 10 | 예상 남은 시간: 5분 48.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 📦 jmmath_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 revu-n-23_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80520)\u001b[0m ✅ ajutaxi-14_IONIQ5 STANDARD_202202.csv: 완료 (27,931행, 17.5초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m 🔄 처리 시작: ha8519_EV9_202401.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 파일 병합 중 오류 (Client V021BI0001): time data \"2025-07-16 00:06:47.085\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 🔄 처리 시작: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 📦 s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: revu-n-23_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81007)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m 📦 ha8519_EV9_202401.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 파일 병합 중 오류 (Client V011BE0014): time data \"2025-07-16 00:19:12.266\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 18.0% | 성공: 26 | 실패: 10 | 예상 남은 시간: 6분 17.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ✅ cjl-dgss-013_PORTER2.csv: 완료 (60,030행, 19.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 🔄 처리 시작: testbongo_BONGO3_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 파일 병합 중 오류 (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21002. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 18.5% | 성공: 27 | 실패: 10 | 예상 남은 시간: 6분 14.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ revu-n-23_EV6 LONGRANGE.csv: 완료 (21,002행, 11.4초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 19.0% | 성공: 28 | 실패: 10 | 예상 남은 시간: 6분 3.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ✅ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 완료 (3,076행, 7.8초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 19.5% | 성공: 29 | 실패: 10 | 예상 남은 시간: 5분 57.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 📦 testbongo_BONGO3_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ cjl-dgea-016_PORTER2.csv: 완료 (124,755행, 33.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 🔄 처리 시작: cyberlmk_EV9_202308.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 20.0% | 성공: 29 | 실패: 11 | 예상 남은 시간: 5분 59.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 파일 병합 중 오류 (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: revu-n-15_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 20.5% | 성공: 29 | 실패: 12 | 예상 남은 시간: 5분 52.2초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 21.0% | 성공: 30 | 실패: 12 | 예상 남은 시간: 5분 41.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m ✅ ha8519_EV9_202401.csv: 완료 (55,813행, 15.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 21.5% | 성공: 30 | 실패: 13 | 예상 남은 시간: 5분 32.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 📦 cyberlmk_EV9_202308.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80576)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: test01_NIRO PLUS_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 22.0% | 성공: 31 | 실패: 13 | 예상 남은 시간: 5분 34.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 🔄 처리 시작: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 22.5% | 성공: 32 | 실패: 13 | 예상 남은 시간: 5분 27.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m 파일 병합 중 오류 (Client V012BD0001): time data \"2025-07-16 02:43:45.074\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ✅ lotteglogis-dg-2_BONGO3.csv: 완료 (64,872행, 21.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 23.0% | 성공: 33 | 실패: 13 | 예상 남은 시간: 5분 23.9초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 23.5% | 성공: 34 | 실패: 13 | 예상 남은 시간: 5분 19.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 📦 ddtaxi-1_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m 🔄 처리 시작: ltgyc-4_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 파일 병합 중 오류 (Client TESTNIRO01): time data \"2025-07-16 11:29:15.204\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 524. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m 📦 ltgyc-4_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m 📦 revu-n-57_IONIQ5 LONGRANGE 2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m 파일 병합 중 오류 (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 24.0% | 성공: 35 | 실패: 13 | 예상 남은 시간: 5분 20.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80894)\u001b[0m ✅ testbongo_BONGO3_202201.csv: 완료 (97,387행, 18.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 파일 병합 중 오류 (Client HANIONIQ5): time data \"2025-07-17 09:06:39.046\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19006. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 24.5% | 성공: 36 | 실패: 13 | 예상 남은 시간: 5분 15.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m 🔄 처리 시작: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81162)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: ltgdg-23_BONGO3_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 📦 dibidib_EV9_202407.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m 📦 kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ✅ test01_IONIQ5 LONGRANGE_202201.csv: 완료 (19,006행, 17.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 ltgdg-23_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 파일 병합 중 오류 (Client V021BJ0001): time data \"2025-07-16 00:00:02.685\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 25.0% | 성공: 37 | 실패: 13 | 예상 남은 시간: 5분 30.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m ✅ cyberlmk_EV9_202308.csv: 완료 (74,944행, 22.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 25.5% | 성공: 38 | 실패: 13 | 예상 남은 시간: 5분 39.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80522)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 📦 relier_NIRO2_202207.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80840)\u001b[0m ✅ ltgyc-4_BONGO3.csv: 완료 (81,156행, 20.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 파일 병합 중 오류 (Client V021BJ0002): time data \"2025-07-16 00:00:00.728\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 4366. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 26.0% | 성공: 39 | 실패: 13 | 예상 남은 시간: 5분 32.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 esm3100_BONGO3_202304.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m 🔄 처리 시작: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ✅ dibidib_EV9_202407.csv: 완료 (4,366행, 14.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 파일 병합 중 오류 (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81256)\u001b[0m 🔄 처리 시작: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 📦 sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 26.5% | 성공: 40 | 실패: 13 | 예상 남은 시간: 5분 39.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ ddtaxi-1_EV6 LONGRANGE_202201.csv: 완료 (60,172행, 28.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81256)\u001b[0m 📦 woojukjk_EV6 LONGRANGE_202304.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 27.0% | 성공: 41 | 실패: 13 | 예상 남은 시간: 5분 33.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: ltgdg-13_PORTER2_2024.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m 📦 boxing0217_IONIQ5 N NE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 27.5% | 성공: 42 | 실패: 13 | 예상 남은 시간: 5분 32.1초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 28.0% | 성공: 43 | 실패: 13 | 예상 남은 시간: 5분 24.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80528)\u001b[0m ✅ revu-n-57_IONIQ5 LONGRANGE 2022.csv: 완료 (76,839행, 31.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 파일 병합 중 오류 (Client V018AL0000): time data \"2025-07-16 01:03:37.076\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ✅ relier_NIRO2_202207.csv: 완료 (110,300행, 23.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 📦 ltgdg-13_PORTER2_2024.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 28.5% | 성공: 44 | 실패: 13 | 예상 남은 시간: 5분 22.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 jtkim0601_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: jtkim0601_NIRO LONGRANGE_201808.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 29.0% | 성공: 45 | 실패: 13 | 예상 남은 시간: 5분 16.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: revu-n-41_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 29.5% | 성공: 46 | 실패: 13 | 예상 남은 시간: 5분 14.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m ✅ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (33,383행, 27.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 📦 revu-n-41_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 30.0% | 성공: 46 | 실패: 14 | 예상 남은 시간: 5분 11.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m 파일 병합 중 오류 (Client V003BL0001): time data \"2025-07-16 00:00:01.651\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ esm3100_BONGO3_202304.csv: 완료 (82,853행, 17.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81155)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 30.5% | 성공: 47 | 실패: 14 | 예상 남은 시간: 5분 7.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 📦 ajutaxi-25_IONIQ 2019_201701.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: lotteglogis-dg-28_BONGO3_202309.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 📦 kung417s_EV6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 31.0% | 성공: 48 | 실패: 14 | 예상 남은 시간: 5분 5.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80525)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 31.5% | 성공: 49 | 실패: 14 | 예상 남은 시간: 5분 0.9초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 32.0% | 성공: 49 | 실패: 15 | 예상 남은 시간: 4분 54.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 파일 병합 중 오류 (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ✅ ltgdg-13_PORTER2_2024.csv: 완료 (58,321행, 15.0초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 📦 revu-n-20_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 🔄 처리 시작: 48625ff_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 lotteglogis-dg-28_BONGO3_202309.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 cjl-gbyc-013_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 32.5% | 성공: 50 | 실패: 15 | 예상 남은 시간: 4분 58.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ ajutaxi-25_IONIQ 2019_201701.csv: 완료 (71,948행, 16.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 파일 병합 중 오류 (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 🔄 처리 시작: 628dani_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ✅ revu-n-41_EV6 LONGRANGE.csv: 완료 (47,455행, 16.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 33.0% | 성공: 51 | 실패: 15 | 예상 남은 시간: 4분 56.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 33.5% | 성공: 51 | 실패: 16 | 예상 남은 시간: 4분 50.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: wsjung21_IONIQ6 LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 34.0% | 성공: 52 | 실패: 16 | 예상 남은 시간: 4분 45.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81263)\u001b[0m ✅ boxing0217_IONIQ5 N NE_202410.csv: 완료 (46,180행, 25.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 34.5% | 성공: 53 | 실패: 16 | 예상 남은 시간: 4분 43.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 📦 628dani_CASPER LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ lotteglogis-dg-28_BONGO3_202309.csv: 완료 (64,149행, 15.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 35.0% | 성공: 53 | 실패: 17 | 예상 남은 시간: 4분 37.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 pgtaxi-5_NIRO LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 🔄 처리 시작: revu-n-8_GV70.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 파일 병합 중 오류 (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 35.5% | 성공: 54 | 실패: 17 | 예상 남은 시간: 4분 39.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 36.0% | 성공: 55 | 실패: 17 | 예상 남은 시간: 4분 37.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80985)\u001b[0m ✅ kung417s_EV6 LONGRANGE_202201.csv: 완료 (51,495행, 21.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 🔄 처리 시작: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ✅ revu-n-20_IONIQ5 LONGRANGE.csv: 완료 (26,489행, 17.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 🔄 처리 시작: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 📦 pgtaxi-4_IONIQ6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ cjl-gbyc-013_BONGO3.csv: 완료 (95,109행, 20.4초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 36.5% | 성공: 56 | 실패: 17 | 예상 남은 시간: 4분 34.9초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 37.0% | 성공: 57 | 실패: 17 | 예상 남은 시간: 4분 30.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 🔄 처리 시작: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 파일 병합 중 오류 (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26489. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 📦 bbs001_IONIQ 2019_201710.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 37.5% | 성공: 58 | 실패: 17 | 예상 남은 시간: 4분 27.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 📦 kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ pgtaxi-5_NIRO LONGRANGE.csv: 완료 (39,827행, 11.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81500)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 33x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 🔄 처리 시작: sitestev6_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ 628dani_CASPER LONGRANGE_202410.csv: 완료 (44,948행, 13.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 ltgdg-12_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 📦 sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 joiltaxi-21_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 38.0% | 성공: 59 | 실패: 17 | 예상 남은 시간: 4분 42.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 파일 병합 중 오류 (Client V020CA0000): time data \"2025-07-16 07:02:00.351\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81067)\u001b[0m ✅ bbs001_IONIQ 2019_201710.csv: 완료 (37,427행, 15.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81067)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 🔄 처리 시작: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 📦 sitestev6_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 파일 병합 중 오류 (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ✅ 48625ff_EV6 LONGRANGE_202210.csv: 완료 (65,905행, 39.5초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 38.5% | 성공: 60 | 실패: 17 | 예상 남은 시간: 4분 45.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 📦 cjl-dgwe-005_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81363)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m 🔄 처리 시작: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 🔄 처리 시작: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 📦 ajutaxi-1_IONIQ 2019_201701.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 파일 병합 중 오류 (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 39.0% | 성공: 61 | 실패: 17 | 예상 남은 시간: 4분 55.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ✅ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (132,781행, 42.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 39.5% | 성공: 62 | 실패: 17 | 예상 남은 시간: 4분 51.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ ltgdg-12_PORTER2.csv: 완료 (84,821행, 29.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m 📦 revu-n-39_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 40.0% | 성공: 63 | 실패: 17 | 예상 남은 시간: 4분 48.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: ltgdg-24_BONGO3_2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 40.5% | 성공: 63 | 실패: 18 | 예상 남은 시간: 4분 44.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V011BE0001): time data \"2025-07-16 09:25:52.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 📦 ltgdg-24_BONGO3_2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ✅ cjl-dgwe-005_PORTER2.csv: 완료 (51,481행, 15.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 🔄 처리 시작: mkj2449_IONIQ5 LONGRANGE_202110.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 파일 병합 중 오류 (Client V013BL0001): time data \"2025-07-16 07:42:10.301\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 41.0% | 성공: 64 | 실패: 18 | 예상 남은 시간: 4분 47.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ✅ pgtaxi-4_IONIQ6 LONGRANGE.csv: 완료 (69,877행, 50.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 revu-n-54_EV6 LONGRANGE_2023.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 41.5% | 성공: 65 | 실패: 18 | 예상 남은 시간: 4분 47.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: revu-n-54_EV6 LONGRANGE_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ✅ ltgdg-24_BONGO3_2022.csv: 완료 (45,327행, 11.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 42.0% | 성공: 65 | 실패: 19 | 예상 남은 시간: 4분 41.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: aim21c_NIRO LONGRANGE_201801.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81722)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 42.5% | 성공: 65 | 실패: 20 | 예상 남은 시간: 4분 38.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 파일 병합 중 오류 (Client V012BE0023): time data \"2025-07-16 00:11:04.962\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 파일 병합 중 오류 (Client V003CA0001): time data \"2025-07-16 00:00:02.491\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80757)\u001b[0m ✅ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (82,565행, 47.3초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 43.0% | 성공: 66 | 실패: 20 | 예상 남은 시간: 4분 33.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 📦 aim21c_NIRO LONGRANGE_201801.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 43.5% | 성공: 67 | 실패: 20 | 예상 남은 시간: 4분 30.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 44.0% | 성공: 68 | 실패: 20 | 예상 남은 시간: 4분 25.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 44.5% | 성공: 68 | 실패: 21 | 예상 남은 시간: 4분 20.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ revu-n-54_EV6 LONGRANGE_2023.csv: 완료 (7,593행, 8.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 🔄 처리 시작: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: pgtaxi-16_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=80757)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 📦 ltgdg-32_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 📦 hahakuhyun_EV6 LONGRANGE_202401.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 파일 병합 중 오류 (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 45.0% | 성공: 69 | 실패: 21 | 예상 남은 시간: 4분 22.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ✅ mkj2449_IONIQ5 LONGRANGE_202110.csv: 완료 (50,553행, 21.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 45.5% | 성공: 70 | 실패: 21 | 예상 남은 시간: 4분 22.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 46.0% | 성공: 71 | 실패: 21 | 예상 남은 시간: 4분 17.3초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 46.5% | 성공: 71 | 실패: 22 | 예상 남은 시간: 4분 12.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 pgtaxi-16_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 🔄 처리 시작: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 파일 병합 중 오류 (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ✅ sitestev6_EV6 LONGRANGE_202201.csv: 완료 (97,301행, 58.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 47.0% | 성공: 72 | 실패: 22 | 예상 남은 시간: 4분 9.0초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 47.5% | 성공: 73 | 실패: 22 | 예상 남은 시간: 4분 6.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81576)\u001b[0m ✅ revu-n-39_EV6 LONGRANGE.csv: 완료 (69,658행, 40.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81834)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 tsiyhj_EV6 LONGRANGE_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: sl-ev-1_EV6 LONGRANGE_2022.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 📦 revu-n-64_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ✅ aim21c_NIRO LONGRANGE_201801.csv: 완료 (30,452행, 16.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81576)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 파일 병합 중 오류 (Client V004BI0000): time data \"2025-07-16 06:37:08.097\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 📦 sl-ev-1_EV6 LONGRANGE_2022.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 48.0% | 성공: 74 | 실패: 22 | 예상 남은 시간: 4분 8.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ✅ hahakuhyun_EV6 LONGRANGE_202401.csv: 완료 (52,104행, 23.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 🔄 처리 시작: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 📦 revu-n-63_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 🔄 처리 시작: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81931)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 파일 병합 중 오류 (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 48.5% | 성공: 75 | 실패: 22 | 예상 남은 시간: 4분 14.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81363)\u001b[0m ✅ ltgdg-32_PORTER2_2023.csv: 완료 (37,855행, 30.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81931)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 49.0% | 성공: 76 | 실패: 22 | 예상 남은 시간: 4분 14.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V004BL0002): time data \"2025-07-16 00:00:00.737\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ pgtaxi-16_EV6 LONGRANGE.csv: 완료 (67,811행, 35.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: revu-n-11_KONA LONGRANGE_202104.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ tsiyhj_EV6 LONGRANGE_202407.csv: 완료 (48,953행, 26.0초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 49.5% | 성공: 77 | 실패: 22 | 예상 남은 시간: 4분 10.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 파일 병합 중 오류 (Client V004BG0004): time data \"2025-07-16 07:46:12.295\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ✅ revu-n-64_EV6 LONGRANGE.csv: 완료 (43,765행, 31.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 🔄 처리 시작: ltgdg-34_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 50.0% | 성공: 78 | 실패: 22 | 예상 남은 시간: 4분 10.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 revu-n-11_KONA LONGRANGE_202104.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81544)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 50.5% | 성공: 79 | 실패: 22 | 예상 남은 시간: 4분 11.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 🔄 처리 시작: cjl-dgds-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 ltgyc-3_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 파일 병합 중 오류 (Client V004BE0009): time data \"2025-07-16 06:46:29.745\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23043. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m ✅ sl-ev-1_EV6 LONGRANGE_2022.csv: 완료 (23,043행, 35.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81308)\u001b[0m 🔄 처리 시작: ltgdg-22_BONGO3_2023.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82160)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 51.0% | 성공: 80 | 실패: 22 | 예상 남은 시간: 4분 10.9초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 51.5% | 성공: 80 | 실패: 23 | 예상 남은 시간: 4분 6.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 📦 cjl-dgds-011_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 파일 병합 중 오류 (Client V004AK0000): time data \"2025-07-16 00:00:02.983\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ✅ xlos20_EV6 LONGRANGE_202101.csv: 완료 (31,584행, 41.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 🔄 처리 시작: joiltaxi-10_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 🔄 처리 시작: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 52.0% | 성공: 80 | 실패: 24 | 예상 남은 시간: 4분 1.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 🔄 처리 시작: maxcom3_EV9_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 파일 병합 중 오류 (Client V000BG0012): time data \"2025-07-16 00:21:41.216\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 25199. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ✅ revu-n-63_IONIQ5 LONGRANGE.csv: 완료 (25,199행, 35.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 52.5% | 성공: 81 | 실패: 24 | 예상 남은 시간: 3분 59.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 53.0% | 성공: 82 | 실패: 24 | 예상 남은 시간: 3분 57.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m 📦 maxcom3_EV9_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ✅ ltgdg-34_BONGO3.csv: 완료 (44,161행, 21.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 🔄 처리 시작: cjl-dgno-004_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 53.5% | 성공: 83 | 실패: 24 | 예상 남은 시간: 3분 53.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 54.0% | 성공: 84 | 실패: 24 | 예상 남은 시간: 3분 49.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 🔄 처리 시작: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 54.5% | 성공: 84 | 실패: 25 | 예상 남은 시간: 3분 45.1초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 55.0% | 성공: 84 | 실패: 26 | 예상 남은 시간: 3분 40.6초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 55.5% | 성공: 84 | 실패: 27 | 예상 남은 시간: 3분 36.3초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 56.0% | 성공: 85 | 실패: 27 | 예상 남은 시간: 3분 33.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 📦 cjl-dgno-004_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 56.5% | 성공: 86 | 실패: 27 | 예상 남은 시간: 3분 29.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m ✅ cjl-dgds-011_PORTER2.csv: 완료 (47,445행, 17.4초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81308)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 57.0% | 성공: 87 | 실패: 27 | 예상 남은 시간: 3분 27.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 🔄 처리 시작: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 57.5% | 성공: 87 | 실패: 28 | 예상 남은 시간: 3분 23.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 파일 병합 중 오류 (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81544)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 cjl-dgss-012_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ revu-n-25_NIRO2_202401.csv: 완료 (23,982행, 9.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 🔄 처리 시작: helleus77_EV6 STANDARD_202108.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 58.0% | 성공: 88 | 실패: 28 | 예상 남은 시간: 3분 22.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82327)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 58.5% | 성공: 89 | 실패: 28 | 예상 남은 시간: 3분 22.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23982. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 📦 ltgdg-17_BONGO3_2024.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: joiltaxi-3_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ✅ cjl-dgno-004_PORTER2.csv: 완료 (59,190행, 16.8초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 59.0% | 성공: 90 | 실패: 28 | 예상 남은 시간: 3분 18.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 📦 joiltaxi-3_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82072)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 🔄 처리 시작: revu-n-18_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 파일 병합 중 오류 (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21146. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81455)\u001b[0m ✅ maxcom3_EV9_202312.csv: 완료 (43,505행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 59.5% | 성공: 91 | 실패: 28 | 예상 남은 시간: 3분 17.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ✅ helleus77_EV6 STANDARD_202108.csv: 완료 (21,146행, 14.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 60.0% | 성공: 91 | 실패: 29 | 예상 남은 시간: 3분 13.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 📦 revu-n-18_BONGO3.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 📦 lotteglogis-dg-22_PORTER2_202301.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 60.5% | 성공: 92 | 실패: 29 | 예상 남은 시간: 3분 12.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 🔄 처리 시작: lotteglogis-dg-22_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 61.0% | 성공: 93 | 실패: 29 | 예상 남은 시간: 3분 8.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V004BI0002): time data \"2025-07-16 07:00:57.870\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82455)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ needman_EV6 LONGRANGE_202403.csv: 완료 (31,768행, 26.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 61.5% | 성공: 94 | 실패: 29 | 예상 남은 시간: 3분 5.5초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 62.0% | 성공: 94 | 실패: 30 | 예상 남은 시간: 3분 1.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 🔄 처리 시작: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m 📦 reviewshare-4_KONA LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 eric_IONIQ5 LONGRANGE_202205.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82475)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 62.5% | 성공: 95 | 실패: 30 | 예상 남은 시간: 3분 1.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 🔄 처리 시작: eric_IONIQ5 LONGRANGE_202205.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ✅ ltgdg-17_BONGO3_2024.csv: 완료 (124,788행, 26.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 파일 병합 중 오류 (Client V011BD0008): time data \"2025-07-16 00:16:14.729\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28652. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82330)\u001b[0m ✅ lotteglogis-dg-22_PORTER2_202301.csv: 완료 (28,652행, 11.2초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 63.0% | 성공: 95 | 실패: 31 | 예상 남은 시간: 2분 57.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m 🔄 처리 시작: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m \n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 63.5% | 성공: 96 | 실패: 31 | 예상 남은 시간: 2분 54.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m 📦 giugi_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 📦 zoh71z_KONA LONGRANGE_201810.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 64.0% | 성공: 97 | 실패: 31 | 예상 남은 시간: 2분 51.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m ✅ giugi_EV6 LONGRANGE.csv: 완료 (4,834행, 2.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 64.5% | 성공: 98 | 실패: 31 | 예상 남은 시간: 2분 49.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 🔄 처리 시작: zoh71z_KONA LONGRANGE_201810.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 파일 병합 중 오류 (Client V012BE0040): time data \"2025-07-16 06:01:20.518\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ✅ revu-n-18_BONGO3.csv: 완료 (51,055행, 14.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 🔄 처리 시작: bbotti_IONIQ5 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82475)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 bbotti_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 65.0% | 성공: 99 | 실패: 31 | 예상 남은 시간: 2분 48.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81428)\u001b[0m ✅ reviewshare-4_KONA LONGRANGE.csv: 완료 (27,455행, 11.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ✅ eric_IONIQ5 LONGRANGE_202205.csv: 완료 (26,443행, 15.4초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 65.5% | 성공: 100 | 실패: 31 | 예상 남은 시간: 2분 44.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m 🔄 처리 시작: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: cjl-dgno-005_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv: 완료 (70,838행, 33.4초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 66.0% | 성공: 101 | 실패: 31 | 예상 남은 시간: 2분 41.2초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 66.5% | 성공: 101 | 실패: 32 | 예상 남은 시간: 2분 37.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 파일 병합 중 오류 (Client V009BL0000): time data \"2025-07-16 00:00:02.657\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 67.0% | 성공: 102 | 실패: 32 | 예상 남은 시간: 2분 34.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 🔄 처리 시작: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 ajutaxi-18_IONIQ 2019_201801.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81934)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m 📦 shome_SOUL LONGRANGE_201901.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ✅ zoh71z_KONA LONGRANGE_201810.csv: 완료 (38,664행, 10.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: mxri13_GV60_202307.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m 파일 병합 중 오류 (Client V004BH0002): time data \"2025-07-16 01:08:28.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 67.5% | 성공: 103 | 실패: 32 | 예상 남은 시간: 2분 34.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 🔄 처리 시작: revu-n-49_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 68.0% | 성공: 104 | 실패: 32 | 예상 남은 시간: 2분 30.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 heo3252_KONA LONGRANGE_201901.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82586)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 revu-n-49_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ joiltaxi-8_IONIQ5 LONGRANGE_202201.csv: 완료 (71,479행, 30.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 🔄 처리 시작: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V000BE0017): time data \"2025-07-16 00:00:01.186\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m 📦 pyh8965_EV6 LONGRANGE_202406.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ bbotti_IONIQ5 LONGRANGE.csv: 완료 (48,990행, 20.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 68.5% | 성공: 105 | 실패: 32 | 예상 남은 시간: 2분 30.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 파일 병합 중 오류 (Client V015BK0000): time data \"2025-07-16 00:00:02.714\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9676. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 69.0% | 성공: 106 | 실패: 32 | 예상 남은 시간: 2분 27.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: lee5957_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 69.5% | 성공: 107 | 실패: 32 | 예상 남은 시간: 2분 24.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 📦 emob-2_IONIQ 2019.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 70.0% | 성공: 108 | 실패: 32 | 예상 남은 시간: 2분 21.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 📦 lee5957_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ ajutaxi-18_IONIQ 2019_201801.csv: 완료 (36,931행, 17.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 🔄 처리 시작: 1357rqwe_IONIQ5 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82646)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 70.5% | 성공: 109 | 실패: 32 | 예상 남은 시간: 2분 19.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82072)\u001b[0m ✅ shome_SOUL LONGRANGE_201901.csv: 완료 (84,721행, 18.3초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 71.0% | 성공: 109 | 실패: 33 | 예상 남은 시간: 2분 15.8초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 71.5% | 성공: 109 | 실패: 34 | 예상 남은 시간: 2분 12.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 파일 병합 중 오류 (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20598. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 cjl-dgea-008_BONGO3.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 📦 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V020BD0000): time data \"2025-07-16 17:13:12.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 72.0% | 성공: 110 | 실패: 34 | 예상 남은 시간: 2분 10.5초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82705)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m ✅ emob-2_IONIQ 2019.csv: 완료 (32,969행, 9.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: revu-n-21_EV9.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82475)\u001b[0m ✅ daegitaxi-2_IONIQ5 LONGRANGE_202207.csv: 완료 (70,019행, 30.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 72.5% | 성공: 111 | 실패: 34 | 예상 남은 시간: 2분 8.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 📦 revu-n-21_EV9.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 파일 병합 중 오류 (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ✅ lee5957_IONIQ5 LONGRANGE.csv: 완료 (52,974행, 16.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 73.0% | 성공: 112 | 실패: 34 | 예상 남은 시간: 2분 7.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 🔄 처리 시작: revu-n-22_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82734)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 73.5% | 성공: 113 | 실패: 34 | 예상 남은 시간: 2분 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ cjl-dgea-008_BONGO3.csv: 완료 (51,105행, 13.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 74.0% | 성공: 113 | 실패: 35 | 예상 남은 시간: 2분 1.2초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 74.5% | 성공: 114 | 실패: 35 | 예상 남은 시간: 1분 58.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 75.0% | 성공: 115 | 실패: 35 | 예상 남은 시간: 1분 55.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 75.5% | 성공: 116 | 실패: 35 | 예상 남은 시간: 1분 52.6초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 76.0% | 성공: 116 | 실패: 36 | 예상 남은 시간: 1분 49.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 kepco-1_IONIQ5 LONGRANGE_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 파일 병합 중 오류 (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81206)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ✅ revu-n-49_EV6 LONGRANGE.csv: 완료 (42,100행, 26.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m 🔄 처리 시작: joiltaxi-26_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82455)\u001b[0m ✅ pyh8965_EV6 LONGRANGE_202406.csv: 완료 (32,252행, 27.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=81206)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 📦 revu-n-22_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m 🔄 처리 시작: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 76.5% | 성공: 116 | 실패: 37 | 예상 남은 시간: 1분 48.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 파일 병합 중 오류 (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 📦 ddtaxi-4_KONA LONGRANGE_201901.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m 🔄 처리 시작: myhkk1797_EV3 LONGRANGE_202402.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 77.0% | 성공: 117 | 실패: 37 | 예상 남은 시간: 1분 46.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ✅ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 완료 (39,937행, 25.8초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82799)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 yitaxi-3_EV6 LONGRANGE_202209.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 77.5% | 성공: 118 | 실패: 37 | 예상 남은 시간: 1분 44.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 🔄 처리 시작: lotteglogis-dg-31_PORTER2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 🔄 처리 시작: ssa1011_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 📦 ssa1011_KONA LONGRANGE 2세대_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V021BE0004): time data \"2025-07-16 01:14:58.627\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ revu-n-21_EV9.csv: 완료 (92,884행, 24.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 파일 병합 중 오류 (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ kepco-1_IONIQ5 LONGRANGE_202110.csv: 완료 (58,040행, 21.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m 📦 myhkk1797_EV3 LONGRANGE_202402.csv: 5개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 🔄 처리 시작: ltgdg-33_PORTER2_2023.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 78.0% | 성공: 119 | 실패: 37 | 예상 남은 시간: 1분 43.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82420)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 🔄 처리 시작: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 78.5% | 성공: 120 | 실패: 37 | 예상 남은 시간: 1분 41.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 revu-n-38_IONIQ5 LONGRANGE 2022.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82918)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m 🔄 처리 시작: endy11_PORTER2_202306.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ✅ ddtaxi-4_KONA LONGRANGE_201901.csv: 완료 (117,328행, 24.4초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 79.0% | 성공: 120 | 실패: 38 | 예상 남은 시간: 1분 39.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: dlcksgh3595_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 79.5% | 성공: 120 | 실패: 39 | 예상 남은 시간: 1분 36.6초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 80.0% | 성공: 120 | 실패: 40 | 예상 남은 시간: 1분 33.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 파일 병합 중 오류 (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ✅ ltgdg-33_PORTER2_2023.csv: 완료 (42,696행, 16.3초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 80.5% | 성공: 121 | 실패: 40 | 예상 남은 시간: 1분 31.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m 📦 endy11_PORTER2_202306.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 완료 (40,151행, 12.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: revu-n-27_EV9.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 81.0% | 성공: 122 | 실패: 40 | 예상 남은 시간: 1분 29.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82420)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 81.5% | 성공: 123 | 실패: 40 | 예상 남은 시간: 1분 26.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 파일 병합 중 오류 (Client V022AK0000): time data \"2025-07-16 07:36:20.441\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 📦 ltgdg-5_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m ✅ ssa1011_KONA LONGRANGE 2세대_202301.csv: 완료 (41,527행, 20.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 🔄 처리 시작: lotteglogis-dg-33_PORTER2_202301.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m ✅ lotteglogis-dg-31_PORTER2_202401.csv: 완료 (60,149행, 26.8초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 82.0% | 성공: 124 | 실패: 40 | 예상 남은 시간: 1분 25.0초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 82.5% | 성공: 125 | 실패: 40 | 예상 남은 시간: 1분 22.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 파일 병합 중 오류 (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=80525)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 🔄 처리 시작: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82671)\u001b[0m 📦 lotteglogis-dg-33_PORTER2_202301.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 파일 병합 중 오류 (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 83.0% | 성공: 126 | 실패: 40 | 예상 남은 시간: 1분 19.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ✅ revu-n-22_EV6 LONGRANGE.csv: 완료 (76,389행, 44.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 🔄 처리 시작: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 📦 hyisjung_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 🔄 처리 시작: adreamcar_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ✅ yitaxi-3_EV6 LONGRANGE_202209.csv: 완료 (100,213행, 40.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82918)\u001b[0m ✅ endy11_PORTER2_202306.csv: 완료 (61,859행, 19.3초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 83.5% | 성공: 127 | 실패: 40 | 예상 남은 시간: 1분 17.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m 📦 revu-n-4_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 adreamcar_PORTER2_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83036)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m 🔄 처리 시작: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 84.0% | 성공: 128 | 실패: 40 | 예상 남은 시간: 1분 15.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 파일 병합 중 오류 (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82799)\u001b[0m ✅ ltgdg-5_PORTER2_2023.csv: 완료 (43,304행, 17.2초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 84.5% | 성공: 129 | 실패: 40 | 예상 남은 시간: 1분 13.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m 📦 ksjksj87_EV3 LONGRANGE_202409.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 🔄 처리 시작: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 85.0% | 성공: 130 | 실패: 40 | 예상 남은 시간: 1분 10.6초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 85.5% | 성공: 131 | 실패: 40 | 예상 남은 시간: 1분 7.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82799)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m 🔄 처리 시작: ltgdg-6_PORTER2_2024.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 86.0% | 성공: 132 | 실패: 40 | 예상 남은 시간: 1분 5.3초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 86.5% | 성공: 132 | 실패: 41 | 예상 남은 시간: 1분 2.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ✅ hyisjung_NIRO LONGRANGE_201808.csv: 완료 (17,591행, 11.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 📦 ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 파일 병합 중 오류 (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17591. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m ✅ myhkk1797_EV3 LONGRANGE_202402.csv: 완료 (120,791행, 47.2초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 87.0% | 성공: 133 | 실패: 41 | 예상 남은 시간: 1분 0.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 📦 revu-n-58_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82797)\u001b[0m 📦 ltgdg-6_PORTER2_2024.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 🔄 처리 시작: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 87.5% | 성공: 134 | 실패: 41 | 예상 남은 시간: 58.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m 파일 병합 중 오류 (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m ✅ ksjksj87_EV3 LONGRANGE_202409.csv: 완료 (60,054행, 12.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 88.0% | 성공: 134 | 실패: 42 | 예상 남은 시간: 55.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 88.5% | 성공: 135 | 실패: 42 | 예상 남은 시간: 53.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m 파일 병합 중 오류 (Client V000CA0025): time data \"2025-07-16 19:03:40.895\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 4088. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 36x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 📦 ntragic_EV6 LONGRANGE_202005.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 🔄 처리 시작: ntragic_EV6 LONGRANGE_202005.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83109)\u001b[0m ✅ js5540810_IONIQ 2019_201607.csv: 완료 (4,088행, 2.9초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 89.0% | 성공: 136 | 실패: 42 | 예상 남은 시간: 51.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=81934)\u001b[0m ✅ revu-n-4_EV6 LONGRANGE.csv: 완료 (57,548행, 28.4초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83203)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 파일 병합 중 오류 (Client V011BE0005): time data \"2025-07-16 00:00:25.609\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 89.5% | 성공: 137 | 실패: 42 | 예상 남은 시간: 49.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ ltgdg-3_PORTER2_2023.csv: 완료 (49,563행, 18.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 🔄 처리 시작: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 90.0% | 성공: 138 | 실패: 42 | 예상 남은 시간: 46.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 📦 yaa7890_PORTER2_202003.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83227)\u001b[0m 🔄 처리 시작: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 90.5% | 성공: 139 | 실패: 42 | 예상 남은 시간: 44.5초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 91.0% | 성공: 140 | 실패: 42 | 예상 남은 시간: 41.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 파일 병합 중 오류 (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ✅ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 완료 (51,682행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 91.5% | 성공: 141 | 실패: 42 | 예상 남은 시간: 39.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83036)\u001b[0m ✅ cjl-dgds-007_PORTER2.csv: 완료 (68,132행, 15.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83203)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 📦 lotteglogis-dg-1_PORTER2_202306.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 92.0% | 성공: 142 | 실패: 42 | 예상 남은 시간: 37.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ✅ revu-n-58_EV6 LONGRANGE.csv: 완료 (43,837행, 26.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 🔄 처리 시작: lotteglogis-dg-7_PORTER2_202311.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 92.5% | 성공: 143 | 실패: 42 | 예상 남은 시간: 34.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 파일 병합 중 오류 (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 3053. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 93.0% | 성공: 144 | 실패: 42 | 예상 남은 시간: 32.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 파일 병합 중 오류 (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m ✅ ntragic_EV6 LONGRANGE_202005.csv: 완료 (51,191행, 18.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 🔄 처리 시작: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 93.5% | 성공: 144 | 실패: 43 | 예상 남은 시간: 29.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83110)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 📦 testev9_EV9_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 🔄 처리 시작: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 📦 yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m 🔄 처리 시작: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 🔄 처리 시작: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m 📦 wntjdgml_CASPER LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 94.0% | 성공: 145 | 실패: 43 | 예상 남은 시간: 27.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m 🔄 처리 시작: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 파일 병합 중 오류 (Client V000BB0000): time data \"2025-07-16 00:25:46.182\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=82734)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ✅ koreataxi-1_IONIQ5 LONGRANGE_202204.csv: 완료 (71,960행, 33.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 📦 lotteglogis-dg-8_PORTER2_202308.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m 📦 bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 파일 병합 중 오류 (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 94.5% | 성공: 146 | 실패: 43 | 예상 남은 시간: 25.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m ✅ testev9_EV9_2023.csv: 완료 (61,460행, 14.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m 📦 revu-n-35_GV70.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82326)\u001b[0m 🔄 처리 시작: cjl-gbyc-010_BONGO3.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83350)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 95.0% | 성공: 147 | 실패: 43 | 예상 남은 시간: 23.4초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 95.5% | 성공: 148 | 실패: 43 | 예상 남은 시간: 20.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83203)\u001b[0m ✅ wntjdgml_CASPER LONGRANGE_202408.csv: 완료 (36,282행, 12.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 파일 병합 중 오류 (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83227)\u001b[0m ✅ lotteglogis-dg-10_PORTER2_202310.csv: 완료 (66,333행, 21.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m 📦 beston_IONIQ6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 96.0% | 성공: 149 | 실패: 43 | 예상 남은 시간: 18.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ✅ lotteglogis-dg-7_PORTER2_202311.csv: 완료 (63,646행, 18.5초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 96.5% | 성공: 150 | 실패: 43 | 예상 남은 시간: 16.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 🔄 처리 시작: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83227)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=83351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m 파일 병합 중 오류 (Client V019CA0000): time data \"2025-07-16 07:45:30.007\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m 📦 cody8406_IONIQ 2020_202007.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83350)\u001b[0m ✅ cody8406_IONIQ 2020_202007.csv: 완료 (47,422행, 10.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 97.0% | 성공: 151 | 실패: 43 | 예상 남은 시간: 14.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m 📦 joiltaxi-9_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 파일 병합 중 오류 (Client V011BD0003): time data \"2025-07-16 00:08:23.219\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83110)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 97.5% | 성공: 152 | 실패: 43 | 예상 남은 시간: 11.7초\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 98.0% | 성공: 153 | 실패: 43 | 예상 남은 시간: 9.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82734)\u001b[0m ✅ revu-n-35_GV70.csv: 완료 (24,186행, 20.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m 파일 병합 중 오류 (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 98.5% | 성공: 154 | 실패: 43 | 예상 남은 시간: 7.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83289)\u001b[0m ✅ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (53,476행, 28.5초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 99.0% | 성공: 155 | 실패: 43 | 예상 남은 시간: 4.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m 파일 병합 중 오류 (Client V013AK0001): time data \"2025-07-16 00:00:02.935\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 99.5% | 성공: 156 | 실패: 43 | 예상 남은 시간: 2.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m ✅ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 완료 (132,336행, 48.7초)\n",
      "\u001b[36m(ProgressTracker pid=80521)\u001b[0m 📊 진행률: 100.0% | 성공: 157 | 실패: 43 | 예상 남은 시간: 0.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83304)\u001b[0m ✅ beston_IONIQ6 LONGRANGE_202201.csv: 완료 (47,385행, 30.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83044)\u001b[0m ✅ joiltaxi-9_EV6 LONGRANGE_202201.csv: 완료 (85,968행, 22.2초)\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 157개 | ❌ 실패: 43개\n",
      "📊 총 처리 행 수: 8,414,617행\n",
      "⏱️  총 소요시간: 7분 48.5초\n",
      "⚡ 평균 파일당: 2.3초\n",
      "\n",
      "❌ 실패한 파일들:\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 7분 48.5초\n",
      "   - 파일당 평균: 2.3초\n",
      "   - 성공률: 78.5%\n",
      "   - 총 처리 행 수: 8,414,617행\n",
      "   - 시간당 처리량: 64659699행/시간\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m 파일 병합 중 오류 (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=82420)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:51:58,717\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 20개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m 🔄 처리 시작: jinsu7426_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 🔄 처리 시작: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m 🔄 처리 시작: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m 📦 sepira_ST1_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m 📦 wildseven_SOUL LONGRANGE_201906.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 📦 uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m 🔄 처리 시작: junhyuk0413_NIRO2_202209.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 5.0% | 성공: 1 | 실패: 0 | 예상 남은 시간: 2분 20.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m 파일 병합 중 오류 (Client V000CD0027): time data \"2025-07-16 07:39:24.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 6608. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83550)\u001b[0m ✅ wildseven_SOUL LONGRANGE_201906.csv: 완료 (6,608행, 6.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m 📦 wwweee_BONGO3_202304.csv: 5개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m 🔄 처리 시작: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83595)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 42x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m 📦 whote564_IONIQ5 LONGRANGE 2022_202311.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m 🔄 처리 시작: jinjinjw_IONIQ5 LONGRANGE_202202.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m 파일 병합 중 오류 (Client V000CD0029): time data \"2025-07-16 06:03:10.847\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24340. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 10.0% | 성공: 2 | 실패: 0 | 예상 남은 시간: 1분 58.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83560)\u001b[0m ✅ junhyuk0413_NIRO2_202209.csv: 완료 (24,340행, 11.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m 📦 jinjinjw_IONIQ5 LONGRANGE_202202.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m 파일 병합 중 오류 (Client V000CD0059): time data \"2025-07-16 00:00:09.733\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28872. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 15.0% | 성공: 3 | 실패: 0 | 예상 남은 시간: 1분 27.5초\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 20.0% | 성공: 4 | 실패: 0 | 예상 남은 시간: 1분 3.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m 🔄 처리 시작: jmjang2_ST1_202405.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83560)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m 📦 jmjang2_ST1_202405.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ✅ sepira_ST1_202407.csv: 완료 (31,165행, 14.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m 파일 병합 중 오류 (Client V000CD0041): time data \"2025-07-16 00:00:00.342\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 🔄 처리 시작: parksw7022_IONIQ6 STANDARD_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83547)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 25.0% | 성공: 5 | 실패: 0 | 예상 남은 시간: 1분 4.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83679)\u001b[0m 🔄 처리 시작: mamon_ST1_202408.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83552)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 📦 parksw7022_IONIQ6 STANDARD_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83551)\u001b[0m ✅ naeibbo_BONGO3_202406.csv: 완료 (95,964행, 22.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 30.0% | 성공: 6 | 실패: 0 | 예상 남은 시간: 56.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ✅ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 완료 (35,942행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 35.0% | 성공: 7 | 실패: 0 | 예상 남은 시간: 47.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m 📦 hmc1006_ST1_202504.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 40.0% | 성공: 8 | 실패: 0 | 예상 남은 시간: 39.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m 🔄 처리 시작: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 파일 병합 중 오류 (Client V000CD0037): time data \"2025-07-16 00:00:00.484\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 🔄 처리 시작: eha031_PORTER2_202211.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 45.0% | 성공: 9 | 실패: 0 | 예상 남은 시간: 34.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m ✅ jinjinjw_IONIQ5 LONGRANGE_202202.csv: 완료 (25,080행, 17.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 50.0% | 성공: 10 | 실패: 0 | 예상 남은 시간: 30.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83581)\u001b[0m ✅ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 완료 (41,557행, 21.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m 📦 eha031_PORTER2_202211.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 55.0% | 성공: 11 | 실패: 0 | 예상 남은 시간: 26.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 파일 병합 중 오류 (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 🔄 처리 시작: vitadoice11_IONIQ5 LONGRANGE_202106.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m 📦 jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 3개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83581)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ✅ parksw7022_IONIQ6 STANDARD_202502.csv: 완료 (34,112행, 14.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83546)\u001b[0m ✅ jmjang2_ST1_202405.csv: 완료 (41,861행, 20.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 📦 vitadoice11_IONIQ5 LONGRANGE_202106.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 60.0% | 성공: 12 | 실패: 0 | 예상 남은 시간: 24.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m 파일 병합 중 오류 (Client V000CD0036): time data \"2025-07-16 02:06:04.534\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 20066. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83552)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m 🔄 처리 시작: cjosooo_ST1_202407.csv\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 65.0% | 성공: 13 | 실패: 0 | 예상 남은 시간: 21.2초\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 70.0% | 성공: 14 | 실패: 0 | 예상 남은 시간: 16.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83764)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 75.0% | 성공: 15 | 실패: 0 | 예상 남은 시간: 14.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83548)\u001b[0m ✅ eha031_PORTER2_202211.csv: 완료 (23,743행, 13.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m 📦 cjosooo_ST1_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m 파일 병합 중 오류 (Client V000CD0065): time data \"2025-07-16 00:00:00.107\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83730)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 80.0% | 성공: 16 | 실패: 0 | 예상 남은 시간: 12.2초\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 85.0% | 성공: 17 | 실패: 0 | 예상 남은 시간: 8.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m ✅ vitadoice11_IONIQ5 LONGRANGE_202106.csv: 완료 (23,791행, 17.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 파일 병합 중 오류 (Client V000CC0085): time data \"2025-07-16 00:19:02.185\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 23791. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83651)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m 파일 병합 중 오류 (Client V000CD0032): time data \"2025-07-16 00:00:03.689\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 90.0% | 성공: 18 | 실패: 0 | 예상 남은 시간: 5.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83549)\u001b[0m ✅ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 완료 (70,718행, 23.8초)\n",
      "\u001b[36m(ProgressTracker pid=83545)\u001b[0m 📊 진행률: 95.0% | 성공: 19 | 실패: 0 | 예상 남은 시간: 2.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m ✅ cjosooo_ST1_202407.csv: 완료 (50,843행, 17.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m 파일 병합 중 오류 (Client V000CD0024): time data \"2025-07-16 00:59:23.925\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83763)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83595)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 20개 | ❌ 실패: 0개\n",
      "📊 총 처리 행 수: 948,634행\n",
      "⏱️  총 소요시간: 57.9초\n",
      "⚡ 평균 파일당: 2.9초\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 57.9초\n",
      "   - 파일당 평균: 2.9초\n",
      "   - 성공률: 100.0%\n",
      "   - 총 처리 행 수: 948,634행\n",
      "   - 시간당 처리량: 58999003행/시간\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83552)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 02:52:59,948\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 300개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 🔄 처리 시작: cjl-dgss-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m 🔄 처리 시작: emob-1_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 0.3% | 성공: 0 | 실패: 1 | 예상 남은 시간: 6분 34.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 0.7% | 성공: 0 | 실패: 2 | 예상 남은 시간: 3분 28.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 1.0% | 성공: 0 | 실패: 3 | 예상 남은 시간: 2분 32.3초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 1.3% | 성공: 0 | 실패: 4 | 예상 남은 시간: 3분 7.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 📦 ekfmd3152_KONA LONGRANGE_202004.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m 📦 emob-1_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 1.7% | 성공: 0 | 실패: 5 | 예상 남은 시간: 5분 10.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 파일 병합 중 오류 (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17804. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ ekfmd3152_KONA LONGRANGE_202004.csv: 완료 (17,804행, 4.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 2.0% | 성공: 1 | 실패: 5 | 예상 남은 시간: 4분 41.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 2.3% | 성공: 1 | 실패: 6 | 예상 남은 시간: 4분 2.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 🔄 처리 시작: sepira_ST1_202407.csv\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 🔄 처리 시작: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m 🔄 처리 시작: uk22da_IONIQ5 LONGRANGE 2022_202312.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m 📦 uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 📦 lostcity1_PORTER2_202412.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 📦 pgtaxi-15_IONIQ6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 2.7% | 성공: 2 | 실패: 6 | 예상 남은 시간: 6분 23.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m 파일 병합 중 오류 (Client V009BL0001): time data \"2025-07-16 07:29:00.303\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83929)\u001b[0m ✅ shcs111_KONA LONGRANGE_201809.csv: 완료 (31,481행, 9.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 3.0% | 성공: 3 | 실패: 6 | 예상 남은 시간: 6분 20.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 파일 병합 중 오류 (Client V015BL0000): time data \"2025-07-16 10:11:33.172\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 22460. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ✅ honeybto_GV60_202205.csv: 완료 (22,460행, 10.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 3.3% | 성공: 3 | 실패: 7 | 예상 남은 시간: 5분 45.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 3.7% | 성공: 3 | 실패: 8 | 예상 남은 시간: 5분 13.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 🔄 처리 시작: joiltaxi-11_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 🔄 처리 시작: jdisky_IONIQ5 LONGRANGE_202112.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 4.0% | 성공: 4 | 실패: 8 | 예상 남은 시간: 5분 12.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 4.3% | 성공: 5 | 실패: 8 | 예상 남은 시간: 5분 0.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 📦 jdisky_IONIQ5 LONGRANGE_202112.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 4.7% | 성공: 5 | 실패: 9 | 예상 남은 시간: 5분 23.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m 파일 병합 중 오류 (Client V009BL0003): time data \"2025-07-16 08:54:02.734\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m ✅ rlaxo120_KONA LONGRANGE_201811.csv: 완료 (32,241행, 12.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83927)\u001b[0m 🔄 처리 시작: ajutaxi-27_IONIQ 2019_201701.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 📦 cjl-dgds-006_PORTER2.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 5.0% | 성공: 6 | 실패: 9 | 예상 남은 시간: 6분 43.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83930)\u001b[0m ✅ emob-1_IONIQ5 LONGRANGE.csv: 완료 (36,771행, 20.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 🔄 처리 시작: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 5.3% | 성공: 7 | 실패: 9 | 예상 남은 시간: 6분 26.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 🔄 처리 시작: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m 파일 병합 중 오류 (Client V000CD0037): time data \"2025-07-16 00:00:00.484\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 25601. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ sepira_ST1_202407.csv: 완료 (77,329행, 16.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 🔄 처리 시작: ltgdg-14_BONGO3_2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 5.7% | 성공: 8 | 실패: 9 | 예상 남은 시간: 6분 55.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83939)\u001b[0m ✅ uk22da_IONIQ5 LONGRANGE 2022_202312.csv: 완료 (25,601행, 17.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 📦 dufdl1025_EV6 LONGRANGE_202404.csv: 5개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 📦 revu-n-32_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 📦 iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 6.0% | 성공: 9 | 실패: 9 | 예상 남은 시간: 7분 17.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ✅ pgtaxi-15_IONIQ6 LONGRANGE.csv: 완료 (53,531행, 26.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 🔄 처리 시작: ltgdg-18_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 파일 병합 중 오류 (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 📦 ltgdg-14_BONGO3_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 6.3% | 성공: 10 | 실패: 9 | 예상 남은 시간: 7분 46.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ✅ cjl-dgds-006_PORTER2.csv: 완료 (59,767행, 18.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 deeps7011_EV6 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: deeps7011_EV6 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 🔄 처리 시작: sihehe_NIRO2_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 6.7% | 성공: 11 | 실패: 9 | 예상 남은 시간: 8분 29.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83939)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 파일 병합 중 오류 (Client V012BE0013): time data \"2025-07-18 10:02:30.523\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ✅ ltgdg-14_BONGO3_2022.csv: 완료 (67,301행, 14.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 📦 man8243_IONIQ5 LONGRANGE_202204.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 🔄 처리 시작: man8243_IONIQ5 LONGRANGE_202204.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 7.0% | 성공: 12 | 실패: 9 | 예상 남은 시간: 9분 11.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m ✅ sihehe_NIRO2_202207.csv: 완료 (14,340행, 6.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 파일 병합 중 오류 (Client V000CE0010): time data \"2025-07-16 00:00:00.248\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 7.3% | 성공: 13 | 실패: 9 | 예상 남은 시간: 9분 11.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 🔄 처리 시작: yitaxi-8_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 7.7% | 성공: 13 | 실패: 10 | 예상 남은 시간: 8분 47.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 🔄 처리 시작: jct4589_SOUL LONGRANGE_201903.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84202)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 8.0% | 성공: 13 | 실패: 11 | 예상 남은 시간: 8분 26.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 🔄 처리 시작: revu-n-48_NIRO LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 8.3% | 성공: 13 | 실패: 12 | 예상 남은 시간: 8분 5.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 🔄 처리 시작: sosanamu_NIRO LONGRANGE_201902.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 8.7% | 성공: 14 | 실패: 12 | 예상 남은 시간: 8분 6.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m 📦 jct4589_SOUL LONGRANGE_201903.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ iamme77_IONIQ5 LONGRANGE 2022_202310.csv: 완료 (39,525행, 24.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 9.0% | 성공: 15 | 실패: 12 | 예상 남은 시간: 7분 51.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ✅ jdisky_IONIQ5 LONGRANGE_202112.csv: 완료 (38,572행, 31.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83923)\u001b[0m ✅ jct4589_SOUL LONGRANGE_201903.csv: 완료 (1,682행, 2.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 📦 sosanamu_NIRO LONGRANGE_201902.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m 📦 junghun1155_EV6 LONGRANGE_202302.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 파일 병합 중 오류 (Client V000CB0058): time data \"2025-07-16 07:40:10.950\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 🔄 처리 시작: stock_EV9_202307.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83923)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 📦 stock_EV9_202307.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 📦 jog5064_EV6 LONGRANGE_202307.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 파일 병합 중 오류 (Client V000BL0007): time data \"2025-07-16 11:24:25.798\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 9.3% | 성공: 16 | 실패: 12 | 예상 남은 시간: 9분 40.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84069)\u001b[0m ✅ man8243_IONIQ5 LONGRANGE_202204.csv: 완료 (34,473행, 23.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 9.7% | 성공: 17 | 실패: 12 | 예상 남은 시간: 9분 32.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 10.0% | 성공: 18 | 실패: 12 | 예상 남은 시간: 9분 15.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ✅ sosanamu_NIRO LONGRANGE_201902.csv: 완료 (42,717행, 17.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: ableautos_EV6 LONGRANGE_202206.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 10.3% | 성공: 18 | 실패: 13 | 예상 남은 시간: 8분 59.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 10.7% | 성공: 19 | 실패: 13 | 예상 남은 시간: 8분 43.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ✅ revu-n-32_EV6 LONGRANGE.csv: 완료 (43,133행, 40.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 🔄 처리 시작: j227_KONA LONGRANGE 2세대_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 11.0% | 성공: 20 | 실패: 13 | 예상 남은 시간: 8분 29.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 11.3% | 성공: 20 | 실패: 14 | 예상 남은 시간: 8분 13.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 📦 j227_KONA LONGRANGE 2세대_202311.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 ableautos_EV6 LONGRANGE_202206.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 파일 병합 중 오류 (Client V011BE0009): time data \"2025-07-16 08:16:22.807\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ✅ ltgdg-18_PORTER2_2023.csv: 완료 (94,032행, 34.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 11.7% | 성공: 21 | 실패: 14 | 예상 남은 시간: 8분 19.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84204)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m 🔄 처리 시작: hoya3838_IONIQ 2019_201807.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 📦 jinsu7426_EV6 LONGRANGE_202407.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m 파일 병합 중 오류 (Client V004AL0000): time data \"2025-07-16 07:30:40.451\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10776. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84204)\u001b[0m ✅ junghun1155_EV6 LONGRANGE_202302.csv: 완료 (10,776행, 19.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 📦 cjl-dgea-016_PORTER2.csv: 5개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84342)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m 🔄 처리 시작: pmkp37_IONIQ5 LONGRANGE 2022_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m 📦 pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m 📦 hoya3838_IONIQ 2019_201807.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m 파일 병합 중 오류 (Client V020BH0001): time data \"2025-07-16 09:01:45.580\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13118. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 12.0% | 성공: 22 | 실패: 14 | 예상 남은 시간: 9분 49.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84335)\u001b[0m ✅ hoya3838_IONIQ 2019_201807.csv: 완료 (13,118행, 8.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 12.3% | 성공: 23 | 실패: 14 | 예상 남은 시간: 9분 39.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 12.7% | 성공: 24 | 실패: 14 | 예상 남은 시간: 9분 22.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ✅ j227_KONA LONGRANGE 2세대_202311.csv: 완료 (26,953행, 19.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 🔄 처리 시작: lotteglogis-dg-19_BONGO3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83928)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 13.0% | 성공: 25 | 실패: 14 | 예상 남은 시간: 9분 20.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 13.3% | 성공: 25 | 실패: 15 | 예상 남은 시간: 9분 4.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 13.7% | 성공: 25 | 실패: 16 | 예상 남은 시간: 8분 50.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84335)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=83928)\u001b[0m 📦 cjl-dgss-015_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 파일 병합 중 오류 (Client V021BI0001): time data \"2025-07-16 00:06:47.085\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ stock_EV9_202307.csv: 완료 (49,322행, 34.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 🔄 처리 시작: cjl-dgss-013_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 14.0% | 성공: 26 | 실패: 16 | 예상 남은 시간: 9분 41.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 📦 cjl-dgss-013_PORTER2.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 파일 병합 중 오류 (Client V004BJ0000): time data \"2025-07-16 00:00:00.136\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ✅ jinsu7426_EV6 LONGRANGE_202407.csv: 완료 (36,324행, 32.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ✅ dufdl1025_EV6 LONGRANGE_202404.csv: 완료 (132,857행, 1분 24.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 14.3% | 성공: 27 | 실패: 16 | 예상 남은 시간: 9분 34.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 14.7% | 성공: 28 | 실패: 16 | 예상 남은 시간: 9분 23.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: ajutaxi-4_IONIQ 2019_201801.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 15.0% | 성공: 28 | 실패: 17 | 예상 남은 시간: 9분 9.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: jmmath_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 🔄 처리 시작: reviewshare-7_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 15.3% | 성공: 28 | 실패: 18 | 예상 남은 시간: 9분 5.3초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 15.7% | 성공: 28 | 실패: 19 | 예상 남은 시간: 8분 52.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 🔄 처리 시작: lbk5510_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 🔄 처리 시작: revu-n-23_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 📦 revu-n-23_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84534)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 jmmath_IONIQ5 LONGRANGE_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 파일 병합 중 오류 (Client V011BE0022): time data \"2025-07-16 00:00:01.028\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ ableautos_EV6 LONGRANGE_202206.csv: 완료 (37,944행, 34.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 🔄 처리 시작: lotteglogis-dg-2_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 16.0% | 성공: 29 | 실패: 19 | 예상 남은 시간: 9분 18.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m ✅ cjl-dgea-016_PORTER2.csv: 완료 (138,978행, 43.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 16.3% | 성공: 30 | 실패: 19 | 예상 남은 시간: 9분 5.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ✅ revu-n-23_EV6 LONGRANGE.csv: 완료 (12,353행, 7.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m 📦 lotteglogis-dg-2_BONGO3.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 🔄 처리 시작: ha8519_EV9_202401.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84540)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 16.7% | 성공: 31 | 실패: 19 | 예상 남은 시간: 9분 21.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 파일 병합 중 오류 (Client V004BE0004): time data \"2025-07-16 00:00:00.998\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12353. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 📦 ha8519_EV9_202401.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 🔄 처리 시작: naeibbo_BONGO3_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84342)\u001b[0m ✅ pmkp37_IONIQ5 LONGRANGE 2022_202309.csv: 완료 (39,332행, 37.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m 🔄 처리 시작: mailhera_PORTER2_202307.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 📦 naeibbo_BONGO3_202406.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 파일 병합 중 오류 (Client V021BI0003): time data \"2025-07-16 02:32:32.953\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 17090. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83987)\u001b[0m ✅ ha8519_EV9_202401.csv: 완료 (17,090행, 10.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 17.0% | 성공: 32 | 실패: 19 | 예상 남은 시간: 9분 31.3초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 17.3% | 성공: 33 | 실패: 19 | 예상 남은 시간: 9분 20.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 🔄 처리 시작: bluesky8571_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 17.7% | 성공: 34 | 실패: 19 | 예상 남은 시간: 9분 16.3초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 18.0% | 성공: 35 | 실패: 19 | 예상 남은 시간: 9분 6.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 🔄 처리 시작: s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 18.3% | 성공: 36 | 실패: 19 | 예상 남은 시간: 9분 2.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: test01_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 📦 s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 파일 병합 중 오류 (Client V000BD0000): time data \"2025-07-16 04:53:27.276\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24622. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ jmmath_IONIQ5 LONGRANGE_202207.csv: 완료 (24,622행, 24.8초)\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m 📦 mailhera_PORTER2_202307.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 18.7% | 성공: 37 | 실패: 19 | 예상 남은 시간: 8분 54.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83987)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 🔄 처리 시작: polarbar_IONIQ6 LONGRANGE_202207.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 파일 병합 중 오류 (Client V000CB0069): time data \"2025-07-16 07:20:25.466\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13393. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84202)\u001b[0m ✅ lotteglogis-dg-2_BONGO3.csv: 완료 (74,821행, 23.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 test01_IONIQ5 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 19.0% | 성공: 38 | 실패: 19 | 예상 남은 시간: 9분 5.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ✅ s2love1003_THE NEW IONIQ5 LONGRANGE_202409.csv: 완료 (13,393행, 7.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 19.3% | 성공: 39 | 실패: 19 | 예상 남은 시간: 9분 3.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ bluesky8571_EV3 LONGRANGE_202504.csv: 완료 (44,135행, 12.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 19.7% | 성공: 39 | 실패: 20 | 예상 남은 시간: 8분 52.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 🔄 처리 시작: revu-n-15_EV6 LONGRANGE.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=83979)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m 파일 병합 중 오류 (Client TESTBONGO): time data \"2025-07-22 12:21:36.167\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12347. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 20.0% | 성공: 40 | 실패: 20 | 예상 남은 시간: 8분 50.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 🔄 처리 시작: babaliian_ST1_202407.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 파일 병합 중 오류 (Client V000CD0059): time data \"2025-07-16 00:00:09.733\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84699)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m 📦 test01_NIRO PLUS_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 📦 revu-n-15_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 20.3% | 성공: 41 | 실패: 20 | 예상 남은 시간: 8분 47.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 파일 병합 중 오류 (Client V013BL0000): time data \"2025-07-17 15:18:16.078\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 16584. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 🔄 처리 시작: revu-n-57_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 20.7% | 성공: 41 | 실패: 21 | 예상 남은 시간: 8분 38.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84798)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ✅ polarbar_IONIQ6 LONGRANGE_202207.csv: 완료 (16,584행, 8.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 🔄 처리 시작: ty3951_EV6 LONGRANGE_202408.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 📦 babaliian_ST1_202407.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m 파일 병합 중 오류 (Client V000CE0019): time data \"2025-07-16 11:38:27.141\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84540)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 21.0% | 성공: 42 | 실패: 21 | 예상 남은 시간: 8분 47.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83924)\u001b[0m 파일 병합 중 오류 (Client V000CD0025): time data \"2025-07-16 00:02:13.084\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 21.3% | 성공: 43 | 실패: 21 | 예상 남은 시간: 8분 42.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 21.7% | 성공: 44 | 실패: 21 | 예상 남은 시간: 8분 32.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 📦 ty3951_EV6 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 22.0% | 성공: 45 | 실패: 21 | 예상 남은 시간: 8분 33.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83926)\u001b[0m ✅ test01_NIRO PLUS_202201.csv: 완료 (36,221행, 11.3초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ✅ revu-n-15_EV6 LONGRANGE.csv: 완료 (19,309행, 12.5초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 22.3% | 성공: 45 | 실패: 22 | 예상 남은 시간: 8분 24.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 🔄 처리 시작: ltgyc-4_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 🔄 처리 시작: dibidib_EV9_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 파일 병합 중 오류 (Client V021BJ0001): time data \"2025-07-16 00:00:02.685\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 📦 ddtaxi-1_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 22.7% | 성공: 46 | 실패: 22 | 예상 남은 시간: 8분 24.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 23.0% | 성공: 47 | 실패: 22 | 예상 남은 시간: 8분 19.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ test01_IONIQ5 LONGRANGE_202201.csv: 완료 (47,372행, 27.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m 🔄 처리 시작: ltgdg-23_BONGO3_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 23.3% | 성공: 48 | 실패: 22 | 예상 남은 시간: 8분 14.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 📦 relier_NIRO2_202207.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 🔄 처리 시작: kyh108_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 📦 kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m 파일 병합 중 오류 (Client V000CD0076): time data \"2025-07-16 00:00:03.051\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 8650. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=83979)\u001b[0m ✅ babaliian_ST1_202407.csv: 완료 (8,650행, 17.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: lotteglogis-dg-16_PORTER2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84899)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 🔄 처리 시작: esm3100_BONGO3_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 📦 dibidib_EV9_202407.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 📦 esm3100_BONGO3_202304.csv: 4개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 파일 병합 중 오류 (Client V000CC0070): time data \"2025-07-16 22:11:44.444\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 23.7% | 성공: 49 | 실패: 22 | 예상 남은 시간: 8분 51.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ✅ ty3951_EV6 LONGRANGE_202408.csv: 완료 (40,203행, 27.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84985)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 🔄 처리 시작: wwweee_BONGO3_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 24.0% | 성공: 49 | 실패: 23 | 예상 남은 시간: 8분 51.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 🔄 처리 시작: leejh824_GV70_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 24.3% | 성공: 49 | 실패: 24 | 예상 남은 시간: 8분 41.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 🔄 처리 시작: sinwootaxi-1_IONIQ5 STANDARD_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m 📦 sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m 파일 병합 중 오류 (Client V012BE0022): time data \"2025-07-16 05:57:27.864\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 24.7% | 성공: 50 | 실패: 24 | 예상 남은 시간: 8분 53.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84855)\u001b[0m ✅ ltgdg-23_BONGO3_2023.csv: 완료 (88,326행, 28.6초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 25.0% | 성공: 51 | 실패: 24 | 예상 남은 시간: 8분 44.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 25.3% | 성공: 52 | 실패: 24 | 예상 남은 시간: 8분 35.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: woojukjk_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 25.7% | 성공: 53 | 실패: 24 | 예상 남은 시간: 8분 26.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 26.0% | 성공: 53 | 실패: 25 | 예상 남은 시간: 8분 17.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: boxing0217_IONIQ5 N NE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 26.3% | 성공: 53 | 실패: 26 | 예상 남은 시간: 8분 9.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84848)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 26.7% | 성공: 53 | 실패: 27 | 예상 남은 시간: 8분 2.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 🔄 처리 시작: revu-n-70_KONA LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 📦 lee1174_EV6 LONGRANGE_202312.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 📦 revu-n-70_KONA LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85058)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 파일 병합 중 오류 (Client V004BA0001): time data \"2025-07-16 07:13:51.054\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ✅ ddtaxi-1_EV6 LONGRANGE_202201.csv: 완료 (63,688행, 39.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 🔄 처리 시작: ajutaxi-25_IONIQ 2019_201701.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m 🔄 처리 시작: revu-n-41_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 27.0% | 성공: 54 | 실패: 27 | 예상 남은 시간: 8분 12.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 ltgdg-13_PORTER2_2024.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 27.3% | 성공: 55 | 실패: 27 | 예상 남은 시간: 8분 5.3초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 27.7% | 성공: 56 | 실패: 27 | 예상 남은 시간: 7분 57.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ✅ kyh108_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (45,237행, 31.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m 📦 revu-n-41_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 28.0% | 성공: 57 | 실패: 27 | 예상 남은 시간: 7분 57.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 🔄 처리 시작: yitaxi-2_IONIQ5 LONGRANGE 2022_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 28.3% | 성공: 57 | 실패: 28 | 예상 남은 시간: 7분 50.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 파일 병합 중 오류 (Client V000CB0089): time data \"2025-07-16 05:32:26.702\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ✅ esm3100_BONGO3_202304.csv: 완료 (95,221행, 28.6초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: kimdajo_EV6 LONGRANGE_202210.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 📦 dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ✅ revu-n-70_KONA LONGRANGE.csv: 완료 (37,620행, 15.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 28.7% | 성공: 58 | 실패: 28 | 예상 남은 시간: 7분 53.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 파일 병합 중 오류 (Client V009BH0000): time data \"2025-07-16 02:56:13.968\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84798)\u001b[0m ✅ sinwootaxi-1_IONIQ5 STANDARD_202110.csv: 완료 (58,787행, 27.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 🔄 처리 시작: lotteglogis-dg-28_BONGO3_202309.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m 📦 lotteglogis-dg-28_BONGO3_202309.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 29.0% | 성공: 59 | 실패: 28 | 예상 남은 시간: 7분 59.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 파일 병합 중 오류 (Client V011BE0003): time data \"2025-07-16 04:57:47.997\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 29.3% | 성공: 60 | 실패: 28 | 예상 남은 시간: 7분 52.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ ltgdg-13_PORTER2_2024.csv: 완료 (80,230행, 21.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 🔄 처리 시작: cjl-gbyc-013_BONGO3.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 🔄 처리 시작: cjl-dgwe-001_BONGO3.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 29.7% | 성공: 60 | 실패: 29 | 예상 남은 시간: 7분 46.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 30.0% | 성공: 60 | 실패: 30 | 예상 남은 시간: 7분 39.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 30.3% | 성공: 61 | 실패: 30 | 예상 남은 시간: 7분 32.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: revu-n-20_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 30.7% | 성공: 62 | 실패: 30 | 예상 남은 시간: 7분 26.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ✅ revu-n-41_EV6 LONGRANGE.csv: 완료 (15,634행, 18.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 📦 kimdajo_EV6 LONGRANGE_202210.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 31.0% | 성공: 63 | 실패: 30 | 예상 남은 시간: 7분 25.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 revu-n-20_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m 파일 병합 중 오류 (Client V004BF0002): time data \"2025-07-16 02:18:47.401\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15634. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84848)\u001b[0m ✅ lotteglogis-dg-28_BONGO3_202309.csv: 완료 (14,188행, 9.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m 🔄 처리 시작: 628dani_CASPER LONGRANGE_202410.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 📦 48625ff_EV6 LONGRANGE_202210.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 31.3% | 성공: 64 | 실패: 30 | 예상 남은 시간: 7분 30.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m 🔄 처리 시작: azking_IONIQ5 LONGRANGE 2022_202207.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 31.7% | 성공: 64 | 실패: 31 | 예상 남은 시간: 7분 24.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m 📦 azking_IONIQ5 LONGRANGE 2022_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 파일 병합 중 오류 (Client V000CC0016): time data \"2025-07-16 00:36:24.196\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26858. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 32.0% | 성공: 65 | 실패: 31 | 예상 남은 시간: 7분 24.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ✅ dnwjdals1_IONIQ5 LONGRANGE_202107.csv: 완료 (26,858행, 19.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m 🔄 처리 시작: kimzizone2_IONIQ5 LONGRANGE_202203.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85048)\u001b[0m ✅ 628dani_CASPER LONGRANGE_202410.csv: 완료 (15,485행, 11.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 32.3% | 성공: 66 | 실패: 31 | 예상 남은 시간: 7분 24.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 📦 korea1736_IONIQ5 LONGRANGE_202203.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 파일 병합 중 오류 (Client V004AK0001): time data \"2025-07-16 00:00:01.247\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85226)\u001b[0m ✅ azking_IONIQ5 LONGRANGE 2022_202207.csv: 완료 (8,729행, 7.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m 📦 kimzizone2_IONIQ5 LONGRANGE_202203.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 32.7% | 성공: 67 | 실패: 31 | 예상 남은 시간: 7분 18.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 🔄 처리 시작: kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 🔄 처리 시작: pgtaxi-5_NIRO LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ✅ kung417s_EV6 LONGRANGE_202201.csv: 완료 (42,750행, 29.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 📦 pgtaxi-5_NIRO LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 33.0% | 성공: 68 | 실패: 31 | 예상 남은 시간: 7분 30.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 파일 병합 중 오류 (Client V000BE0020): time data \"2025-07-16 07:50:33.690\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ revu-n-20_IONIQ5 LONGRANGE.csv: 완료 (45,130행, 25.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 33.3% | 성공: 69 | 실패: 31 | 예상 남은 시간: 7분 32.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85314)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 🔄 처리 시작: revu-n-8_GV70.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 파일 병합 중 오류 (Client V007BL0000): time data \"2025-07-16 04:47:57.256\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28335. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ✅ pgtaxi-5_NIRO LONGRANGE.csv: 완료 (28,335행, 10.6초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 33.7% | 성공: 69 | 실패: 32 | 예상 남은 시간: 7분 28.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 🔄 처리 시작: pgtaxi-4_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 📦 pgtaxi-4_IONIQ6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 파일 병합 중 오류 (Client V000CA0038): time data \"2025-07-16 00:00:06.904\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84776)\u001b[0m ✅ lijingice007_ST1_202411.csv: 완료 (62,311행, 34.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 34.0% | 성공: 70 | 실패: 32 | 예상 남은 시간: 7분 28.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 📦 kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 5개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: bjgjw2579_EV6 LONGRANGE_202109.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 bjgjw2579_EV6 LONGRANGE_202109.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 34.3% | 성공: 71 | 실패: 32 | 예상 남은 시간: 7분 26.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 34.7% | 성공: 72 | 실패: 32 | 예상 남은 시간: 7분 20.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: bbs001_IONIQ 2019_201710.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 35.0% | 성공: 72 | 실패: 33 | 예상 남은 시간: 7분 14.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 35.3% | 성공: 72 | 실패: 34 | 예상 남은 시간: 7분 8.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: sbk5611_IONIQ5 LONGRANGE 2022_202303.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 파일 병합 중 오류 (Client V000CE0007): time data \"2025-07-16 00:07:43.773\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ✅ kimdajo_EV6 LONGRANGE_202210.csv: 완료 (90,937행, 47.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 35.7% | 성공: 73 | 실패: 34 | 예상 남은 시간: 7분 6.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 🔄 처리 시작: woojoov_CASPER LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 36.0% | 성공: 73 | 실패: 35 | 예상 남은 시간: 7분 0.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 📦 sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 🔄 처리 시작: ltgdg-12_PORTER2.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ✅ korea1736_IONIQ5 LONGRANGE_202203.csv: 완료 (38,001행, 30.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 📦 ltgdg-12_PORTER2.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84776)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 파일 병합 중 오류 (Client V004CA0001): time data \"2025-07-16 00:00:00.128\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 36.3% | 성공: 74 | 실패: 35 | 예상 남은 시간: 7분 13.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84737)\u001b[0m ✅ 48625ff_EV6 LONGRANGE_202210.csv: 완료 (79,907행, 50.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 36.7% | 성공: 75 | 실패: 35 | 예상 남은 시간: 7분 7.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85535)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 🔄 처리 시작: wildseven_SOUL LONGRANGE_201906.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 📦 sitestev6_EV6 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: cjl-dgwe-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 37.0% | 성공: 75 | 실패: 36 | 예상 남은 시간: 7분 6.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 37.3% | 성공: 75 | 실패: 37 | 예상 남은 시간: 7분 0.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: ajutaxi-1_IONIQ 2019_201701.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: revu-n-39_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 37.7% | 성공: 75 | 실패: 38 | 예상 남은 시간: 6분 54.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: day9672_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 📦 wildseven_SOUL LONGRANGE_201906.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 38.0% | 성공: 75 | 실패: 39 | 예상 남은 시간: 6분 49.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: clausewitx_GV70_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ✅ wildseven_SOUL LONGRANGE_201906.csv: 완료 (13,040행, 4.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 파일 병합 중 오류 (Client V000CD0027): time data \"2025-07-16 07:39:24.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 13040. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ bjgjw2579_EV6 LONGRANGE_202109.csv: 완료 (38,446행, 20.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 38.3% | 성공: 76 | 실패: 39 | 예상 남은 시간: 6분 49.2초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 38.7% | 성공: 76 | 실패: 40 | 예상 남은 시간: 6분 43.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 clausewitx_GV70_202210.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 🔄 처리 시작: ltgdg-24_BONGO3_2022.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 39.0% | 성공: 76 | 실패: 41 | 예상 남은 시간: 6분 45.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84737)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 파일 병합 중 오류 (Client V003CA0000): time data \"2025-07-16 00:07:31.417\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 📦 ltgdg-24_BONGO3_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85616)\u001b[0m 🔄 처리 시작: yitaxi-1_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ✅ kjyzeal_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (127,935행, 53.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 39.3% | 성공: 77 | 실패: 41 | 예상 남은 시간: 6분 52.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 🔄 처리 시작: mkj2449_IONIQ5 LONGRANGE_202110.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 39.7% | 성공: 78 | 실패: 41 | 예상 남은 시간: 6분 47.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ✅ ltgdg-24_BONGO3_2022.csv: 완료 (62,736행, 13.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 📦 junhyuk0413_NIRO2_202209.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m ✅ pgtaxi-4_IONIQ6 LONGRANGE.csv: 완료 (14,337행, 42.8초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 40.0% | 성공: 79 | 실패: 41 | 예상 남은 시간: 6분 45.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 40.3% | 성공: 79 | 실패: 42 | 예상 남은 시간: 6분 40.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 40.7% | 성공: 79 | 실패: 43 | 예상 남은 시간: 6분 35.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 🔄 처리 시작: kepco-3_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 41.0% | 성공: 80 | 실패: 43 | 예상 남은 시간: 6분 30.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 🔄 처리 시작: whote564_IONIQ5 LONGRANGE 2022_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 파일 병합 중 오류 (Client V000CB0063): time data \"2025-07-16 03:44:01.670\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29473. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 🔄 처리 시작: aim21c_NIRO LONGRANGE_201801.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 41.3% | 성공: 81 | 실패: 43 | 예상 남은 시간: 6분 26.9초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85691)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ clausewitx_GV70_202210.csv: 완료 (29,473행, 21.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 📦 whote564_IONIQ5 LONGRANGE 2022_202311.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 📦 aim21c_NIRO LONGRANGE_201801.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 41.7% | 성공: 82 | 실패: 43 | 예상 남은 시간: 6분 27.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85692)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 파일 병합 중 오류 (Client V000CD0029): time data \"2025-07-16 06:03:10.847\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10476. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 🔄 처리 시작: hahakuhyun_EV6 LONGRANGE_202401.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85535)\u001b[0m ✅ junhyuk0413_NIRO2_202209.csv: 완료 (10,476행, 8.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 📦 cjl-gbyc-016_BONGO3.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 파일 병합 중 오류 (Client V000BL0009): time data \"2025-07-16 06:14:33.476\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15242. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84736)\u001b[0m ✅ mkj2449_IONIQ5 LONGRANGE_202110.csv: 완료 (15,242행, 14.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 42.0% | 성공: 83 | 실패: 43 | 예상 남은 시간: 6분 28.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 jinjinjw_IONIQ5 LONGRANGE_202202.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 42.3% | 성공: 84 | 실패: 43 | 예상 남은 시간: 6분 23.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ✅ sbk5611_IONIQ5 LONGRANGE 2022_202303.csv: 완료 (73,116행, 47.8초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 42.7% | 성공: 85 | 실패: 43 | 예상 남은 시간: 6분 20.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: ltgdg-32_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 43.0% | 성공: 86 | 실패: 43 | 예상 남은 시간: 6분 17.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 🔄 처리 시작: yitaxi-5_IONIQ5 LONGRANGE 2022_202208.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 파일 병합 중 오류 (Client V007AJ0000): time data \"2025-07-16 07:46:32.081\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 18842. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85314)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m ✅ jinjinjw_IONIQ5 LONGRANGE_202202.csv: 완료 (4,906행, 3.8초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 📦 hahakuhyun_EV6 LONGRANGE_202401.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 43.3% | 성공: 86 | 실패: 44 | 예상 남은 시간: 6분 17.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 📦 ltgdg-32_PORTER2_2023.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 🔄 처리 시작: kate3070kr_GV70_202107.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 43.7% | 성공: 87 | 실패: 44 | 예상 남은 시간: 6분 15.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m 파일 병합 중 오류 (Client V004BA0027): time data \"2025-07-16 03:20:48.641\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85225)\u001b[0m ✅ joiltaxi-21_EV6 LONGRANGE_202201.csv: 완료 (101,245행, 59.4초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 44.0% | 성공: 88 | 실패: 44 | 예상 남은 시간: 6분 13.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 44.3% | 성공: 89 | 실패: 44 | 예상 남은 시간: 6분 8.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85691)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 📦 kate3070kr_GV70_202107.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 🔄 처리 시작: pgtaxi-16_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 44.7% | 성공: 90 | 실패: 44 | 예상 남은 시간: 6분 8.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 🔄 처리 시작: printo2000_PORTER2_202210.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 🔄 처리 시작: c1228kr_IONIQ5 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 🔄 처리 시작: delpainus_IONIQ5 LONGRANGE 2022_202307.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 45.0% | 성공: 91 | 실패: 44 | 예상 남은 시간: 6분 4.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 45.3% | 성공: 92 | 실패: 44 | 예상 남은 시간: 5분 60.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m ✅ whote564_IONIQ5 LONGRANGE 2022_202311.csv: 완료 (28,877행, 27.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 📦 delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 파일 병합 중 오류 (Client V000CD0095): time data \"2025-07-16 08:14:02.568\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 28877. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85458)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ✅ printo2000_PORTER2_202210.csv: 완료 (12,501행, 6.9초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 📦 pgtaxi-16_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85851)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m 🔄 처리 시작: wer007_THE NEW IONIQ5 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 📦 tsiyhj_EV6 LONGRANGE_202407.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 🔄 처리 시작: tsiyhj_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m 📦 wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 파일 병합 중 오류 (Client V011BE0004): time data \"2025-07-16 00:45:14.436\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 45.7% | 성공: 93 | 실패: 44 | 예상 남은 시간: 6분 2.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ✅ ltgdg-32_PORTER2_2023.csv: 완료 (90,094행, 22.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85922)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 🔄 처리 시작: ehman486_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 📦 c1228kr_IONIQ5 LONGRANGE_202201.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ delpainus_IONIQ5 LONGRANGE 2022_202307.csv: 완료 (14,450행, 10.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 46.0% | 성공: 94 | 실패: 44 | 예상 남은 시간: 6분 1.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 🔄 처리 시작: revu-n-64_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 📦 ehman486_EV3 LONGRANGE_202408.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 📦 revu-n-64_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 파일 병합 중 오류 (Client V000CE0022): time data \"2025-07-16 09:00:54.200\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 14450. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: rwww87_EV6 LONGRANGE_202311.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 46.3% | 성공: 95 | 실패: 44 | 예상 남은 시간: 6분 4.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 파일 병합 중 오류 (Client V004BI0001): time data \"2025-07-16 06:42:06.101\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21690. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84899)\u001b[0m ✅ tsiyhj_EV6 LONGRANGE_202407.csv: 완료 (21,690행, 16.8초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 46.7% | 성공: 96 | 실패: 44 | 예상 남은 시간: 6분 2.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ✅ pgtaxi-16_EV6 LONGRANGE.csv: 완료 (34,543행, 21.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 🔄 처리 시작: xlos20_EV6 LONGRANGE_202101.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 📦 rwww87_EV6 LONGRANGE_202311.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 47.0% | 성공: 97 | 실패: 44 | 예상 남은 시간: 5분 58.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 47.3% | 성공: 98 | 실패: 44 | 예상 남은 시간: 5분 53.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 47.7% | 성공: 98 | 실패: 45 | 예상 남은 시간: 5분 51.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 파일 병합 중 오류 (Client V000CC0001): time data \"2025-07-16 00:52:26.240\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=84109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ✅ ehman486_EV3 LONGRANGE_202408.csv: 완료 (26,078행, 11.0초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=84109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: lny-taxi-p1_IONIQ6 LONGRANGE_202311.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 📦 sl-ev-1_EV6 LONGRANGE_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: revu-n-63_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 파일 병합 중 오류 (Client V000CA0039): time data \"2025-07-16 00:00:01.556\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 48.0% | 성공: 99 | 실패: 45 | 예상 남은 시간: 5분 54.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ✅ ocs7777_ST1_202407.csv: 완료 (49,291행, 38.5초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 48.3% | 성공: 100 | 실패: 45 | 예상 남은 시간: 5분 50.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ revu-n-64_EV6 LONGRANGE.csv: 완료 (23,987행, 19.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 🔄 처리 시작: legojeon_NIRO LONGRANGE_201910.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 48.7% | 성공: 100 | 실패: 46 | 예상 남은 시간: 5분 45.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m ✅ wer007_THE NEW IONIQ5 LONGRANGE_202504.csv: 완료 (36,497행, 27.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 49.0% | 성공: 101 | 실패: 46 | 예상 남은 시간: 5분 41.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 49.3% | 성공: 102 | 실패: 46 | 예상 남은 시간: 5분 38.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 📦 revu-n-63_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85851)\u001b[0m 🔄 처리 시작: ltgdg-34_BONGO3.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 📦 revu-n-11_KONA LONGRANGE_202104.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 파일 병합 중 오류 (Client V000CD0084): time data \"2025-07-16 00:00:00.608\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m ✅ c1228kr_IONIQ5 LONGRANGE_202201.csv: 완료 (61,141행, 32.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85692)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 49.7% | 성공: 103 | 실패: 46 | 예상 남은 시간: 5분 43.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 🔄 처리 시작: airme_EV6 LONGRANGE_202403.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 파일 병합 중 오류 (Client V000CB0006): time data \"2025-07-16 08:00:25.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29483. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ✅ rwww87_EV6 LONGRANGE_202311.csv: 완료 (29,483행, 24.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85692)\u001b[0m 📦 airme_EV6 LONGRANGE_202403.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 27x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 50.0% | 성공: 104 | 실패: 46 | 예상 남은 시간: 5분 42.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 🔄 처리 시작: lotteglogis-dg-34_PORTER2_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 파일 병합 중 오류 (Client V011BE0011): time data \"2025-07-16 00:00:00.515\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m ✅ xlos20_EV6 LONGRANGE_202101.csv: 완료 (31,384행, 25.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 cjl-dgds-011_PORTER2.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ ltgyc-3_PORTER2.csv: 완료 (50,124행, 17.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 50.3% | 성공: 105 | 실패: 46 | 예상 남은 시간: 5분 40.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 50.7% | 성공: 106 | 실패: 46 | 예상 남은 시간: 5분 36.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 🔄 처리 시작: ltgdg-22_BONGO3_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 📦 lotteglogis-dg-34_PORTER2_202301.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 51.0% | 성공: 107 | 실패: 46 | 예상 남은 시간: 5분 34.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85922)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 51.3% | 성공: 107 | 실패: 47 | 예상 남은 시간: 5분 30.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 🔄 처리 시작: leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 51.7% | 성공: 108 | 실패: 47 | 예상 남은 시간: 5분 27.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 🔄 처리 시작: pgtaxi-17_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 52.0% | 성공: 108 | 실패: 48 | 예상 남은 시간: 5분 23.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 파일 병합 중 오류 (Client V009BL0006): time data \"2025-07-16 00:33:12.400\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ✅ revu-n-11_KONA LONGRANGE_202104.csv: 완료 (85,233행, 22.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 52.3% | 성공: 108 | 실패: 49 | 예상 남은 시간: 5분 19.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 🔄 처리 시작: maxcom3_EV9_202312.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 52.7% | 성공: 109 | 실패: 49 | 예상 남은 시간: 5분 15.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 53.0% | 성공: 109 | 실패: 50 | 예상 남은 시간: 5분 11.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ revu-n-63_IONIQ5 LONGRANGE.csv: 완료 (41,976행, 24.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 🔄 처리 시작: parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 📦 leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m 📦 ltgdg-22_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 📦 dmcdimo_EV6 LONGRANGE_202211.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 53.3% | 성공: 110 | 실패: 50 | 예상 남은 시간: 5분 9.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86199)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 53.7% | 성공: 111 | 실패: 50 | 예상 남은 시간: 5분 7.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: revu-n-9_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 54.0% | 성공: 111 | 실패: 51 | 예상 남은 시간: 5분 3.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 54.3% | 성공: 111 | 실패: 52 | 예상 남은 시간: 4분 59.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 54.7% | 성공: 111 | 실패: 53 | 예상 남은 시간: 4분 55.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 55.0% | 성공: 111 | 실패: 54 | 예상 남은 시간: 4분 51.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V011BE0023): time data \"2025-07-16 00:00:01.004\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ cjl-dgds-011_PORTER2.csv: 완료 (62,235행, 21.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: revu-n-25_NIRO2_202401.csv\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m 📦 parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 📦 needman_EV6 LONGRANGE_202403.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 55.3% | 성공: 111 | 실패: 55 | 예상 남은 시간: 4분 50.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 🔄 처리 시작: yousjun_IONIQ5 LONGRANGE 2022_202302.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86199)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V018BE0000): time data \"2025-07-17 18:57:13.506\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 15280. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 🔄 처리 시작: s112661140_EV6 LONGRANGE_202205.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ revu-n-25_NIRO2_202401.csv: 완료 (15,280행, 7.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 파일 병합 중 오류 (Client V011BD0010): time data \"2025-07-16 19:24:24.666\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 55.7% | 성공: 112 | 실패: 55 | 예상 남은 시간: 4분 49.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85691)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: helleus77_EV6 STANDARD_202108.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 56.0% | 성공: 113 | 실패: 55 | 예상 남은 시간: 4분 46.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 📦 yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86000)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 helleus77_EV6 STANDARD_202108.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 56.3% | 성공: 114 | 실패: 55 | 예상 남은 시간: 4분 44.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 56.7% | 성공: 115 | 실패: 55 | 예상 남은 시간: 4분 41.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85109)\u001b[0m ✅ ltgdg-22_BONGO3_2023.csv: 완료 (89,775행, 21.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 파일 병합 중 오류 (Client V000CC0032): time data \"2025-07-16 00:24:45.845\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ leejangju_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (31,434행, 19.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 🔄 처리 시작: cjl-dgss-012_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 📦 lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 📦 wce4122_EV6 LONGRANGE_202110.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 🔄 처리 시작: wce4122_EV6 LONGRANGE_202110.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 파일 병합 중 오류 (Client V000CC0005): time data \"2025-07-16 00:42:28.778\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 27301. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 57.0% | 성공: 116 | 실패: 55 | 예상 남은 시간: 4분 42.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ✅ dmcdimo_EV6 LONGRANGE_202211.csv: 완료 (27,301행, 24.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 🔄 처리 시작: hmp4522_EV3 LONGRANGE_202502.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 57.3% | 성공: 117 | 실패: 55 | 예상 남은 시간: 4분 41.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 🔄 처리 시작: cgtaxi-1_IONIQ5 LONGRANGE 2022_202212.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=85109)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 57.7% | 성공: 117 | 실패: 56 | 예상 남은 시간: 4분 38.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 58.0% | 성공: 118 | 실패: 56 | 예상 남은 시간: 4분 34.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 58.3% | 성공: 118 | 실패: 57 | 예상 남은 시간: 4분 30.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 58.7% | 성공: 118 | 실패: 58 | 예상 남은 시간: 4분 27.2초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 59.0% | 성공: 118 | 실패: 59 | 예상 남은 시간: 4분 23.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 📦 revu-n-18_BONGO3.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V005CA0000): time data \"2025-07-16 06:35:29.942\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26770. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ helleus77_EV6 STANDARD_202108.csv: 완료 (26,770행, 15.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: sunghyun_BONGO3_202412.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 59.3% | 성공: 119 | 실패: 59 | 예상 남은 시간: 4분 21.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85922)\u001b[0m ✅ parkee82_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (56,504행, 30.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86351)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 59.7% | 성공: 120 | 실패: 59 | 예상 남은 시간: 4분 20.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 60.0% | 성공: 120 | 실패: 60 | 예상 남은 시간: 4분 16.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 sunghyun_BONGO3_202412.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 파일 병합 중 오류 (Client V011BE0013): time data \"2025-07-16 08:14:23.270\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ cjl-dgss-012_PORTER2.csv: 완료 (49,002행, 16.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86351)\u001b[0m 🔄 처리 시작: lotteglogis-dg-22_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 60.3% | 성공: 121 | 실패: 60 | 예상 남은 시간: 4분 15.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ✅ yousjun_IONIQ5 LONGRANGE 2022_202302.csv: 완료 (52,329행, 28.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 60.7% | 성공: 122 | 실패: 60 | 예상 남은 시간: 4분 12.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m ✅ revu-n-18_BONGO3.csv: 완료 (8,174행, 10.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86351)\u001b[0m 📦 lotteglogis-dg-22_PORTER2_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 파일 병합 중 오류 (Client V000CB0067): time data \"2025-07-16 02:37:56.272\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 61.0% | 성공: 123 | 실패: 60 | 예상 남은 시간: 4분 9.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ lyj6081_THE NEW IONIQ5 LONGRANGE_202410.csv: 완료 (35,649행, 25.3초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 📦 jmjang2_ST1_202405.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 61.3% | 성공: 123 | 실패: 61 | 예상 남은 시간: 4분 6.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: reviewshare-4_KONA LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 61.7% | 성공: 124 | 실패: 61 | 예상 남은 시간: 4분 4.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 62.0% | 성공: 124 | 실패: 62 | 예상 남은 시간: 4분 0.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 📦 reviewshare-4_KONA LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 🔄 처리 시작: mamon_ST1_202408.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ✅ wce4122_EV6 LONGRANGE_202110.csv: 완료 (47,855행, 23.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m 파일 병합 중 오류 (Client V000CB0085): time data \"2025-07-16 00:00:00.667\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 📦 revu-n-66_EV6 LONGRANGE_202304.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 62.3% | 성공: 125 | 실패: 62 | 예상 남은 시간: 3분 59.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85799)\u001b[0m ✅ hmp4522_EV3 LONGRANGE_202502.csv: 완료 (49,566행, 21.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ reviewshare-4_KONA LONGRANGE.csv: 완료 (15,031행, 6.6초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 62.7% | 성공: 126 | 실패: 62 | 예상 남은 시간: 3분 57.1초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86186)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: junsuck86_EV6 LONGRANGE_202304.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 🔄 처리 시작: hwa9183_EV3 LONGRANGE_202410.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 63.0% | 성공: 126 | 실패: 63 | 예상 남은 시간: 3분 54.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 🔄 처리 시작: win7102_EV3 LONGRANGE_202503.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 63.3% | 성공: 127 | 실패: 63 | 예상 남은 시간: 3분 50.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 🔄 처리 시작: giugi_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 63.7% | 성공: 128 | 실패: 63 | 예상 남은 시간: 3분 47.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 📦 giugi_EV6 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m 파일 병합 중 오류 (Client V000CD0033): time data \"2025-07-16 00:02:38.110\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24784. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 📦 win7102_EV3 LONGRANGE_202503.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86390)\u001b[0m ✅ parksw7022_IONIQ6 STANDARD_202502.csv: 완료 (24,784행, 11.7초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 64.0% | 성공: 129 | 실패: 63 | 예상 남은 시간: 3분 46.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: go051s_BONGO3_202412.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: zoh71z_KONA LONGRANGE_201810.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 파일 병합 중 오류 (Client V000CD0034): time data \"2025-07-16 00:00:03.402\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 📦 zoh71z_KONA LONGRANGE_201810.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 64.3% | 성공: 130 | 실패: 63 | 예상 남은 시간: 3분 47.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m \n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=85868)\u001b[0m ✅ jmjang2_ST1_202405.csv: 완료 (65,327행, 24.7초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 64.7% | 성공: 131 | 실패: 63 | 예상 남은 시간: 3분 44.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 🔄 처리 시작: nukesub_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 파일 병합 중 오류 (Client V000CB0027): time data \"2025-07-16 12:44:07.662\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 21534. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 🔄 처리 시작: bbotti_IONIQ5 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 65.0% | 성공: 132 | 실패: 63 | 예상 남은 시간: 3분 42.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 65.3% | 성공: 132 | 실패: 64 | 예상 남은 시간: 3분 38.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ✅ giugi_EV6 LONGRANGE.csv: 완료 (16,342행, 13.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 🔄 처리 시작: daegitaxi-2_IONIQ5 LONGRANGE_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 🔄 처리 시작: cjl-dgno-005_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 65.7% | 성공: 132 | 실패: 65 | 예상 남은 시간: 3분 35.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 🔄 처리 시작: ldw8482_EV6 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 📦 bbotti_IONIQ5 LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 📦 nukesub_EV3 LONGRANGE_202504.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ junsuck86_EV6 LONGRANGE_202304.csv: 완료 (21,534행, 12.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 66.0% | 성공: 133 | 실패: 65 | 예상 남은 시간: 3분 33.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ✅ revu-n-66_EV6 LONGRANGE_202304.csv: 완료 (37,526행, 24.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 66.3% | 성공: 133 | 실패: 66 | 예상 남은 시간: 3분 30.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 66.7% | 성공: 134 | 실패: 66 | 예상 남은 시간: 3분 27.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 67.0% | 성공: 134 | 실패: 67 | 예상 남은 시간: 3분 24.6초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86537)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m 파일 병합 중 오류 (Client V000CE0017): time data \"2025-07-16 00:12:44.626\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86186)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 67.3% | 성공: 135 | 실패: 67 | 예상 남은 시간: 3분 21.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 📦 ldw8482_EV6 LONGRANGE_202204.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 67.7% | 성공: 136 | 실패: 67 | 예상 남은 시간: 3분 19.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 🔄 처리 시작: fojokr_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 📦 fojokr_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 68.0% | 성공: 137 | 실패: 67 | 예상 남은 시간: 3분 16.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 68.3% | 성공: 137 | 실패: 68 | 예상 남은 시간: 3분 13.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: hmc1006_ST1_202504.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: shome_SOUL LONGRANGE_201901.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: vunyvuny2_SOUL LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 68.7% | 성공: 138 | 실패: 68 | 예상 남은 시간: 3분 10.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 69.0% | 성공: 138 | 실패: 69 | 예상 남은 시간: 3분 7.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 69.3% | 성공: 138 | 실패: 70 | 예상 남은 시간: 3분 5.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 📦 vunyvuny2_SOUL LONGRANGE.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ✅ nukesub_EV3 LONGRANGE_202504.csv: 완료 (10,232행, 8.4초)\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86564)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 파일 병합 중 오류 (Client V000CE0014): time data \"2025-07-16 10:41:47.477\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 10232. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 📦 heo3252_KONA LONGRANGE_201901.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 🔄 처리 시작: heo3252_KONA LONGRANGE_201901.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 🔄 처리 시작: lee5957_IONIQ5 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 69.7% | 성공: 139 | 실패: 70 | 예상 남은 시간: 3분 5.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 📦 lee5957_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 파일 병합 중 오류 (Client V000CC0029): time data \"2025-07-16 01:07:52.143\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9499. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ✅ fojokr_CASPER LONGRANGE_202410.csv: 완료 (9,499행, 10.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 70.0% | 성공: 140 | 실패: 70 | 예상 남은 시간: 3분 3.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 70.3% | 성공: 141 | 실패: 70 | 예상 남은 시간: 3분 0.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ✅ mxri13_GV60_202307.csv: 완료 (19,982행, 12.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86469)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 22x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 70.7% | 성공: 142 | 실패: 70 | 예상 남은 시간: 2분 57.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 71.0% | 성공: 142 | 실패: 71 | 예상 남은 시간: 2분 54.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ✅ vunyvuny2_SOUL LONGRANGE.csv: 완료 (17,652행, 9.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 📦 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: juhwan7455_EV3 LONGRANGE_202407.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m 파일 병합 중 오류 (Client V000CA0034): time data \"2025-07-16 08:22:40.033\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ✅ emob-2_IONIQ 2019.csv: 완료 (26,301행, 8.8초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 71.3% | 성공: 143 | 실패: 71 | 예상 남은 시간: 2분 53.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86430)\u001b[0m ✅ ldw8482_EV6 LONGRANGE_202204.csv: 완료 (37,779행, 20.0초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86277)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 71.7% | 성공: 144 | 실패: 71 | 예상 남은 시간: 2분 52.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 72.0% | 성공: 145 | 실패: 71 | 예상 남은 시간: 2분 49.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ bbotti_IONIQ5 LONGRANGE.csv: 완료 (24,633행, 24.6초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 72.3% | 성공: 145 | 실패: 72 | 예상 남은 시간: 2분 46.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 72.7% | 성공: 145 | 실패: 73 | 예상 남은 시간: 2분 43.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 73.0% | 성공: 146 | 실패: 73 | 예상 남은 시간: 2분 41.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 🔄 처리 시작: revu-n-22_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 73.3% | 성공: 146 | 실패: 74 | 예상 남은 시간: 2분 38.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 joiltaxi-19_IONIQ5 LONGRANGE_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: joiltaxi-19_IONIQ5 LONGRANGE_202201.csv\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 파일 병합 중 오류 (Client V009BL0004): time data \"2025-07-16 09:59:30.156\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ✅ heo3252_KONA LONGRANGE_201901.csv: 완료 (35,974행, 15.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86694)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 📦 revu-n-22_EV6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ✅ lee5957_IONIQ5 LONGRANGE.csv: 완료 (38,821행, 22.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 73.7% | 성공: 147 | 실패: 74 | 예상 남은 시간: 2분 38.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 74.0% | 성공: 147 | 실패: 75 | 예상 남은 시간: 2분 35.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 📦 ltgdg-1_BONGO3_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 🔄 처리 시작: ddtaxi-4_KONA LONGRANGE_201901.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 파일 병합 중 오류 (Client V000BH0015): time data \"2025-07-16 06:19:26.981\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86695)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 파일 병합 중 오류 (Client V000CE0018): time data \"2025-07-16 15:53:51.106\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ✅ juhwan7455_EV3 LONGRANGE_202407.csv: 완료 (64,329행, 21.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 📦 eha031_PORTER2_202211.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 🔄 처리 시작: eha031_PORTER2_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 74.3% | 성공: 148 | 실패: 75 | 예상 남은 시간: 2분 35.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: yitaxi-3_EV6 LONGRANGE_202209.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 74.7% | 성공: 148 | 실패: 76 | 예상 남은 시간: 2분 32.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 🔄 처리 시작: tlsqjatjq628_EV3 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 75.0% | 성공: 149 | 실패: 76 | 예상 남은 시간: 2분 30.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 파일 병합 중 오류 (Client V012BE0000): time data \"2025-07-16 03:41:55.672\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86000)\u001b[0m ✅ ltgdg-1_BONGO3_2023.csv: 완료 (73,566행, 16.4초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 📦 tlsqjatjq628_EV3 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m 🔄 처리 시작: joiltaxi-26_EV6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 파일 병합 중 오류 (Client V000BL0011): time data \"2025-07-16 07:32:56.371\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 75.3% | 성공: 150 | 실패: 76 | 예상 남은 시간: 2분 29.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86469)\u001b[0m ✅ 1357rqwe_IONIQ5 LONGRANGE_202207.csv: 완료 (36,613행, 27.9초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 75.7% | 성공: 151 | 실패: 76 | 예상 남은 시간: 2분 26.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: revu-n-69_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 76.0% | 성공: 152 | 실패: 76 | 예상 남은 시간: 2분 24.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 🔄 처리 시작: jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 revu-n-69_EV6 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ✅ eha031_PORTER2_202211.csv: 완료 (36,731행, 14.9초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m 📦 joiltaxi-26_EV6 LONGRANGE_202201.csv: 4개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m 📦 jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 🔄 처리 시작: myhkk1797_EV3 LONGRANGE_202402.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 파일 병합 중 오류 (Client V000CC0081): time data \"2025-07-16 02:51:49.699\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 76.3% | 성공: 153 | 실패: 76 | 예상 남은 시간: 2분 25.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86428)\u001b[0m ✅ tlsqjatjq628_EV3 LONGRANGE_202408.csv: 완료 (57,177행, 19.2초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86786)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 76.7% | 성공: 154 | 실패: 76 | 예상 남은 시간: 2분 22.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m 📦 lotteglogis-dg-31_PORTER2_202401.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m 🔄 처리 시작: lotteglogis-dg-31_PORTER2_202401.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 파일 병합 중 오류 (Client V000BH0014): time data \"2025-07-16 00:00:00.958\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86277)\u001b[0m ✅ kepco-1_IONIQ5 LONGRANGE_202110.csv: 완료 (40,668행, 27.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86428)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 파일 병합 중 오류 (Client V000CA0035): time data \"2025-07-16 00:00:02.003\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 77.0% | 성공: 155 | 실패: 76 | 예상 남은 시간: 2분 23.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ✅ ddongkolip_ST1_202405.csv: 완료 (107,571행, 52.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 🔄 처리 시작: ssa1011_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 🔄 처리 시작: wjs4156_EV3 STANDARD_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 📦 myhkk1797_EV3 LONGRANGE_202402.csv: 6개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 77.3% | 성공: 156 | 실패: 76 | 예상 남은 시간: 2분 21.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ revu-n-69_EV6 LONGRANGE.csv: 완료 (34,991행, 26.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 📦 wjs4156_EV3 STANDARD_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 📦 ssa1011_KONA LONGRANGE 2세대_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V004BH0001): time data \"2025-07-16 07:04:21.113\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 🔄 처리 시작: ltgdg-33_PORTER2_2023.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 파일 병합 중 오류 (Client V004BE0008): time data \"2025-07-16 00:53:00.628\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: revu-n-38_IONIQ5 LONGRANGE 2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 77.7% | 성공: 157 | 실패: 76 | 예상 남은 시간: 2분 20.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86565)\u001b[0m ✅ revu-n-22_EV6 LONGRANGE.csv: 완료 (68,474행, 51.7초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 📦 ltgdg-33_PORTER2_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86970)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 🔄 처리 시작: ehdghans1_IONIQ5 LONGRANGE_202206.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 revu-n-38_IONIQ5 LONGRANGE 2022.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 78.0% | 성공: 157 | 실패: 77 | 예상 남은 시간: 2분 19.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 🔄 처리 시작: ky80901_ST1_202406.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m 파일 병합 중 오류 (Client V011BD0006): time data \"2025-07-16 06:28:22.151\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86786)\u001b[0m ✅ lotteglogis-dg-31_PORTER2_202401.csv: 완료 (63,974행, 25.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 78.3% | 성공: 158 | 실패: 77 | 예상 남은 시간: 2분 16.8초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 78.7% | 성공: 159 | 실패: 77 | 예상 남은 시간: 2분 14.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86537)\u001b[0m ✅ jmm3303_THE NEW IONIQ5 LONGRANGE_202503.csv: 완료 (38,182행, 36.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87015)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 79.0% | 성공: 159 | 실패: 78 | 예상 남은 시간: 2분 11.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 79.3% | 성공: 160 | 실패: 78 | 예상 남은 시간: 2분 9.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 79.7% | 성공: 161 | 실패: 78 | 예상 남은 시간: 2분 7.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m 🔄 처리 시작: dlcksgh3595_KONA LONGRANGE 2세대_202301.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 🔄 처리 시작: ddtaxi-5_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 80.0% | 성공: 161 | 실패: 79 | 예상 남은 시간: 2분 4.6초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 80.3% | 성공: 162 | 실패: 79 | 예상 남은 시간: 2분 2.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ revu-n-38_IONIQ5 LONGRANGE 2022.csv: 완료 (17,052행, 11.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: ignatius9107_IONIQ5 N NE_202502.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 파일 병합 중 오류 (Client V022AK0000): time data \"2025-07-16 07:36:20.441\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ✅ wjs4156_EV3 STANDARD_202502.csv: 완료 (36,161행, 18.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 80.7% | 성공: 163 | 실패: 79 | 예상 남은 시간: 1분 59.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m 📦 hophip5677_CASPER LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 81.0% | 성공: 164 | 실패: 79 | 예상 남은 시간: 1분 57.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 81.3% | 성공: 164 | 실패: 80 | 예상 남은 시간: 1분 55.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 ignatius9107_IONIQ5 N NE_202502.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 🔄 처리 시작: yitaxi-10_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 🔄 처리 시작: kgs0002_EV6 LONGRANGE_202205.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86226)\u001b[0m ✅ ssa1011_KONA LONGRANGE 2세대_202301.csv: 완료 (52,995행, 19.9초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 파일 병합 중 오류 (Client V011BE0006): time data \"2025-07-16 08:48:01.246\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ✅ ltgdg-33_PORTER2_2023.csv: 완료 (54,002행, 15.8초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 📦 kgs0002_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 🔄 처리 시작: ltj1937_EV3 LONGRANGE_202412.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 81.7% | 성공: 164 | 실패: 81 | 예상 남은 시간: 1분 54.8초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86226)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 📦 ltgdg-5_PORTER2_2023.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 82.0% | 성공: 164 | 실패: 82 | 예상 남은 시간: 1분 52.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m 🔄 처리 시작: revu-n-4_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 82.3% | 성공: 164 | 실패: 83 | 예상 남은 시간: 1분 50.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86694)\u001b[0m ✅ hophip5677_CASPER LONGRANGE_202408.csv: 완료 (30,073행, 17.5초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 82.7% | 성공: 165 | 실패: 83 | 예상 남은 시간: 1분 48.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m 🔄 처리 시작: adreamcar_PORTER2_202301.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87139)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 파일 병합 중 오류 (Client V011BE0008): time data \"2025-07-16 06:47:47.345\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 19707. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m 📦 adreamcar_PORTER2_202301.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 83.0% | 성공: 166 | 실패: 83 | 예상 남은 시간: 1분 46.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ ltgdg-5_PORTER2_2023.csv: 완료 (19,707행, 10.5초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 🔄 처리 시작: hyisjung_NIRO LONGRANGE_201808.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 83.3% | 성공: 167 | 실패: 83 | 예상 남은 시간: 1분 44.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 🔄 처리 시작: ksjksj87_EV3 LONGRANGE_202409.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 📦 hyisjung_NIRO LONGRANGE_201808.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 📦 ksjksj87_EV3 LONGRANGE_202409.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 83.7% | 성공: 168 | 실패: 83 | 예상 남은 시간: 1분 42.7초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87293)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V000CB0094): time data \"2025-07-19 00:51:14.209\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87137)\u001b[0m ✅ adreamcar_PORTER2_202301.csv: 완료 (40,718행, 11.7초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ ignatius9107_IONIQ5 N NE_202502.csv: 완료 (37,884행, 30.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 84.0% | 성공: 169 | 실패: 83 | 예상 남은 시간: 1분 40.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 84.3% | 성공: 169 | 실패: 84 | 예상 남은 시간: 1분 38.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 🔄 처리 시작: revu-n-58_EV6 LONGRANGE.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 🔄 처리 시작: jhs3101_PORTER2_202002.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 84.7% | 성공: 170 | 실패: 84 | 예상 남은 시간: 1분 36.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 85.0% | 성공: 171 | 실패: 84 | 예상 남은 시간: 1분 33.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ hyisjung_NIRO LONGRANGE_201808.csv: 완료 (9,951행, 8.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 📦 jhs3101_PORTER2_202002.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 파일 병합 중 오류 (Client V007AL0001): time data \"2025-07-16 09:40:23.701\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 9951. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ✅ revu-n-27_EV9.csv: 완료 (33,177행, 26.0초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 🔄 처리 시작: ltgdg-3_PORTER2_2023.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 📦 ltgdg-3_PORTER2_2023.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 파일 병합 중 오류 (Client V000CB0010): time data \"2025-07-16 06:49:12.111\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 85.3% | 성공: 172 | 실패: 84 | 예상 남은 시간: 1분 33.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ✅ kgs0002_EV6 LONGRANGE_202205.csv: 완료 (41,563행, 41.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 파일 병합 중 오류 (Client V029BL0001): time data \"2025-07-16 01:36:42.171\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 85.7% | 성공: 173 | 실패: 84 | 예상 남은 시간: 1분 31.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86833)\u001b[0m 🔄 처리 시작: ltgdg-6_PORTER2_2024.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 86.0% | 성공: 173 | 실패: 85 | 예상 남은 시간: 1분 28.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 86.3% | 성공: 174 | 실패: 85 | 예상 남은 시간: 1분 26.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 📦 revu-u-5_IONIQ5 LONGRANGE_202201.csv: 1개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87396)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ✅ ddtaxi-5_EV6 LONGRANGE_202201.csv: 완료 (89,880행, 47.1초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 파일 병합 중 오류 (Client V004BA0003): time data \"2025-07-16 00:00:00.749\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 🔄 처리 시작: vitadoice11_IONIQ5 LONGRANGE_202106.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 파일 병합 중 오류 (Client V000CD0024): time data \"2025-07-16 00:59:23.925\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 📦 vitadoice11_IONIQ5 LONGRANGE_202106.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 86.7% | 성공: 175 | 실패: 85 | 예상 남은 시간: 1분 25.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 87.0% | 성공: 176 | 실패: 85 | 예상 남은 시간: 1분 23.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ✅ ky80901_ST1_202406.csv: 완료 (103,991행, 1분 1.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 🔄 처리 시작: koreataxi-1_IONIQ5 LONGRANGE_202204.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ✅ jhs3101_PORTER2_202002.csv: 완료 (31,122행, 26.1초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 🔄 처리 시작: cjl-dgds-007_PORTER2.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 87.3% | 성공: 176 | 실패: 86 | 예상 남은 시간: 1분 20.5초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 87.7% | 성공: 176 | 실패: 87 | 예상 남은 시간: 1분 18.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 🔄 처리 시작: ys062789_EV6 LONGRANGE_202407.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 🔄 처리 시작: js5540810_IONIQ 2019_201607.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87338)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 88.0% | 성공: 177 | 실패: 87 | 예상 남은 시간: 1분 16.1초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 88.3% | 성공: 178 | 실패: 87 | 예상 남은 시간: 1분 13.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 88.7% | 성공: 179 | 실패: 87 | 예상 남은 시간: 1분 12.0초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 파일 병합 중 오류 (Client V000CD0081): time data \"2025-07-16 00:08:12.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 📦 js5540810_IONIQ 2019_201607.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ✅ geni8895_BONGO3_202210.csv: 완료 (60,279행, 29.3초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 🔄 처리 시작: ntragic_EV6 LONGRANGE_202005.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86969)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 📦 ntragic_EV6 LONGRANGE_202005.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 🔄 처리 시작: yaa7890_PORTER2_202003.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 89.0% | 성공: 179 | 실패: 88 | 예상 남은 시간: 1분 9.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 🔄 처리 시작: yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 89.3% | 성공: 180 | 실패: 88 | 예상 남은 시간: 1분 7.4초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 89.7% | 성공: 181 | 실패: 88 | 예상 남은 시간: 1분 5.3초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 90.0% | 성공: 181 | 실패: 89 | 예상 남은 시간: 1분 3.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86833)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client V000CB0070): time data \"2025-07-16 05:26:55.553\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ ltgdg-3_PORTER2_2023.csv: 완료 (79,420행, 35.8초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 📦 lotteglogis-dg-1_PORTER2_202306.csv: 1개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m 🔄 처리 시작: lotteglogis-dg-10_PORTER2_202310.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 90.3% | 성공: 182 | 실패: 89 | 예상 남은 시간: 1분 1.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ ldhljs7725_THE NEW IONIQ5 LONGRANGE_202408.csv: 완료 (44,214행, 41.7초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 90.7% | 성공: 183 | 실패: 89 | 예상 남은 시간: 59.0초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86924)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 91.0% | 성공: 184 | 실패: 89 | 예상 남은 시간: 56.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 파일 병합 중 오류 (Client V011BD0000): time data \"2025-07-16 09:59:32.236\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 26291. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ lotteglogis-dg-1_PORTER2_202306.csv: 완료 (26,291행, 8.2초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m 📦 lotteglogis-dg-10_PORTER2_202310.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: testev9_EV9_2023.csv\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 📦 yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 4개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 91.3% | 성공: 185 | 실패: 89 | 예상 남은 시간: 54.9초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 testev9_EV9_2023.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 파일 병합 중 오류 (Client V004CA0000): time data \"2025-07-16 00:00:01.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87079)\u001b[0m ✅ ntragic_EV6 LONGRANGE_202005.csv: 완료 (33,787행, 18.7초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87079)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "\u001b[36m(preprocess_batch_parallel pid=87654)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 🔄 처리 시작: lotteglogis-dg-7_PORTER2_202311.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 📦 cjawl74_PORTER2_202412.csv: 6개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 파일 병합 중 오류 (Client V000CB0041): time data \"2025-07-16 00:00:00.124\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 29233. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 91.7% | 성공: 186 | 실패: 89 | 예상 남은 시간: 53.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87296)\u001b[0m ✅ jsmtnaud_IONIQ5 LONGRANGE_202201.csv: 완료 (29,233행, 27.1초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(raylet)\u001b[0m Spilled 2853 MiB, 74 objects, write throughput 220 MiB/s. Set RAY_verbose_spill_logs=0 to disable this message.\n",
      "\u001b[36m(preprocess_batch_parallel pid=87653)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 📦 lotteglogis-dg-7_PORTER2_202311.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 🔄 처리 시작: gildagray_EV3 LONGRANGE_202411.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 92.0% | 성공: 186 | 실패: 90 | 예상 남은 시간: 51.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 🔄 처리 시작: yitaxi-9_IONIQ5 LONGRANGE 2022_202302.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 92.3% | 성공: 186 | 실패: 91 | 예상 남은 시간: 49.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 🔄 처리 시작: kor87_NIRO PLUS_202207.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 📦 kor87_NIRO PLUS_202207.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 92.7% | 성공: 187 | 실패: 91 | 예상 남은 시간: 47.3초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 파일 병합 중 오류 (Client TESTEV9): time data \"2025-07-16 04:13:54.321\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m ✅ testev9_EV9_2023.csv: 완료 (49,163행, 22.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87739)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 🔄 처리 시작: emr4540_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86080)\u001b[0m 📦 emr4540_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 93.0% | 성공: 188 | 실패: 91 | 예상 남은 시간: 45.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m 🔄 처리 시작: lotteglogis-dg-8_PORTER2_202308.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 파일 병합 중 오류 (Client V000BB0000): time data \"2025-07-16 00:25:46.182\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ✅ lotteglogis-dg-10_PORTER2_202310.csv: 완료 (116,157행, 35.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 93.3% | 성공: 189 | 실패: 91 | 예상 남은 시간: 43.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ✅ koreataxi-1_IONIQ5 LONGRANGE_202204.csv: 완료 (90,471행, 50.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 93.7% | 성공: 190 | 실패: 91 | 예상 남은 시간: 41.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 94.0% | 성공: 191 | 실패: 91 | 예상 남은 시간: 38.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 🔄 처리 시작: wntjdgml_CASPER LONGRANGE_202408.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 📦 wntjdgml_CASPER LONGRANGE_202408.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 🔄 처리 시작: janko7_EV3 LONGRANGE_202504.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m 📦 janko7_EV3 LONGRANGE_202504.csv: 2개 배치 병렬 처리 완료, 결합 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86080)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 94.3% | 성공: 192 | 실패: 91 | 예상 남은 시간: 36.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 🔄 처리 시작: taerok_KONA LONGRANGE_202302.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 파일 병합 중 오류 (Client V011BD0002): time data \"2025-07-16 06:36:25.437\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ✅ lotteglogis-dg-7_PORTER2_202311.csv: 완료 (82,676행, 22.5초)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 📦 taerok_KONA LONGRANGE_202302.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m 🔄 처리 시작: bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87815)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 🔄 처리 시작: thdwlsdn000_CASPER LONGRANGE_202410.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m 📦 lotteglogis-dg-8_PORTER2_202308.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 📦 thdwlsdn000_CASPER LONGRANGE_202410.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 파일 병합 중 오류 (Client V000CC0007): time data \"2025-07-16 00:00:02.643\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 94.7% | 성공: 193 | 실패: 91 | 예상 남은 시간: 34.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86924)\u001b[0m ✅ cjawl74_PORTER2_202412.csv: 완료 (158,984행, 43.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m 📦 bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 95.0% | 성공: 194 | 실패: 91 | 예상 남은 시간: 32.7초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ✅ wntjdgml_CASPER LONGRANGE_202408.csv: 완료 (30,879행, 15.9초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87653)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 🔄 처리 시작: beston_IONIQ6 LONGRANGE_202201.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 파일 병합 중 오류 (Client V000CA0008): time data \"2025-07-16 06:32:03.805\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 파일 병합 중 오류 (Client V000CD0023): time data \"2025-07-16 01:32:19.376\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 95.3% | 성공: 195 | 실패: 91 | 예상 남은 시간: 30.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ cjosooo_ST1_202407.csv: 완료 (74,386행, 49.0초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 95.7% | 성공: 196 | 실패: 91 | 예상 남은 시간: 28.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 🔄 처리 시작: musein_EV9_202404.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 96.0% | 성공: 197 | 실패: 91 | 예상 남은 시간: 26.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 📦 beston_IONIQ6 LONGRANGE_202201.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m ✅ taerok_KONA LONGRANGE_202302.csv: 완료 (40,146행, 18.1초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 96.3% | 성공: 198 | 실패: 91 | 예상 남은 시간: 23.9초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 96.7% | 성공: 198 | 실패: 92 | 예상 남은 시간: 21.7초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 97.0% | 성공: 198 | 실패: 93 | 예상 남은 시간: 19.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 파일 병합 중 오류 (Client V000CA0020): time data \"2025-07-16 01:00:11.095\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86970)\u001b[0m ✅ janko7_EV3 LONGRANGE_202504.csv: 완료 (49,586행, 22.5초)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87917)\u001b[0m 🔄 처리 시작: joiltaxi-9_EV6 LONGRANGE_202201.csv\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m 📦 heinzel_EV6 LONGRANGE_202205.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 97.3% | 성공: 198 | 실패: 94 | 예상 남은 시간: 17.4초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87917)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 📦 musein_EV9_202404.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 파일 병합 중 오류 (Client V003AL0003): time data \"2025-07-16 00:00:03.077\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 97.7% | 성공: 199 | 실패: 94 | 예상 남은 시간: 15.2초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=86969)\u001b[0m ✅ yjtaxi-6_IONIQ5 LONGRANGE 2022_202211.csv: 완료 (100,983행, 1분 12.2초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m 🔄 처리 시작: cody8406_IONIQ 2020_202007.csv\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 98.0% | 성공: 200 | 실패: 94 | 예상 남은 시간: 13.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87563)\u001b[0m ✅ lotteglogis-dg-8_PORTER2_202308.csv: 완료 (85,178행, 36.8초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=87563)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 📦 side3150_IONIQ6 LONGRANGE_202312.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m 파일 병합 중 오류 (Client V000CB0068): time data \"2025-07-16 01:39:04.233\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87817)\u001b[0m ✅ bluewing4_THE NEW IONIQ5 LONGRANGE_202411.csv: 완료 (48,937행, 35.4초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 98.3% | 성공: 201 | 실패: 94 | 예상 남은 시간: 11.0초\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 98.7% | 성공: 202 | 실패: 94 | 예상 남은 시간: 8.8초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m ✅ cody8406_IONIQ 2020_202007.csv: 완료 (22,273행, 17.2초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 99.0% | 성공: 203 | 실패: 94 | 예상 남은 시간: 6.6초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m 파일 병합 중 오류 (Client V019CA0000): time data \"2025-07-16 07:45:30.007\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 22273. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87916)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 파일 병합 중 오류 (Client V000CB0096): time data \"2025-07-16 00:00:02.639\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87816)\u001b[0m ✅ musein_EV9_202404.csv: 완료 (57,045행, 27.5초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 99.3% | 성공: 204 | 실패: 94 | 예상 남은 시간: 4.4초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m ✅ beston_IONIQ6 LONGRANGE_202201.csv: 완료 (37,923행, 33.8초)\n",
      "\u001b[36m(ProgressTracker pid=83925)\u001b[0m 📊 진행률: 99.7% | 성공: 205 | 실패: 94 | 예상 남은 시간: 2.2초\n",
      "\n",
      "================================================================================\n",
      "🎉 병렬 처리 완료!\n",
      "📈 성공: 206개 | ❌ 실패: 94개\n",
      "📊 총 처리 행 수: 9,670,662행\n",
      "⏱️  총 소요시간: 10분 58.4초\n",
      "⚡ 평균 파일당: 2.2초\n",
      "\n",
      "❌ 실패한 파일들:\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "   - Unknown: 처리할 데이터가 없습니다.\n",
      "\n",
      "📊 최종 처리 통계:\n",
      "   - 총 처리 시간: 10분 58.4초\n",
      "   - 파일당 평균: 2.2초\n",
      "   - 성공률: 68.7%\n",
      "   - 총 처리 행 수: 9,670,662행\n",
      "   - 시간당 처리량: 52878566행/시간\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m 파일 병합 중 오류 (Client V000CD0078): time data \"2025-07-16 05:34:57.584\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 30000. You might want to try:\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format` if your strings have a consistent format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87654)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87653)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=87140)\u001b[0m ✅ heinzel_EV6 LONGRANGE_202205.csv: 완료 (35,736행, 33.3초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=86969)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔚 Ray 종료 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 03:04:02,470\tINFO worker.py:1821 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Ray 초기화 완료 (워커 수: 8)\n",
      "📁 총 240개 파일 병렬 처리 시작\n",
      "📂 출력 디렉토리: /Volumes/Data/betterwhy_processed\n",
      "================================================================================\n",
      "⏳ 모든 파일 병렬 처리 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88141)\u001b[0m 🔄 처리 시작: cjl-dgss-011_PORTER2.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88137)\u001b[0m 🔄 처리 시작: pgtaxi-15_IONIQ6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 0.4% | 성공: 0 | 실패: 1 | 예상 남은 시간: 6분 32.5초\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 0.8% | 성공: 0 | 실패: 2 | 예상 남은 시간: 3분 22.3초\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 1.2% | 성공: 0 | 실패: 3 | 예상 남은 시간: 2분 14.9초\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 1.7% | 성공: 0 | 실패: 4 | 예상 남은 시간: 1분 42.7초\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 2.1% | 성공: 0 | 실패: 5 | 예상 남은 시간: 1분 23.7초\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 2.5% | 성공: 0 | 실패: 6 | 예상 남은 시간: 1분 14.5초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m 📦 ekfmd3152_KONA LONGRANGE_202004.csv: 1개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88136)\u001b[0m 📦 emob-1_IONIQ5 LONGRANGE.csv: 2개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m 🔄 처리 시작: cjl-dgds-006_PORTER2.csv\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88155)\u001b[0m 🔄 처리 시작: revu-n-68_EV6 LONGRANGE.csv\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:103: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:104: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "\u001b[36m(preprocess_batch_parallel pid=88169)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88141)\u001b[0m 📦 revu-n-34_GV70.csv: 2개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m 파일 병합 중 오류 (Client V009BL0002): time data \"2025-07-16 06:29:19.280\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 24902. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88137)\u001b[0m 📦 pgtaxi-15_IONIQ6 LONGRANGE.csv: 3개 배치 병렬 처리 완료, 결합 중...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 2.9% | 성공: 1 | 실패: 6 | 예상 남은 시간: 5분 43.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88135)\u001b[0m ✅ ekfmd3152_KONA LONGRANGE_202004.csv: 완료 (24,902행, 8.6초)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88187)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 21x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88140)\u001b[0m 📦 dufdl1025_EV6 LONGRANGE_202404.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m 🔄 처리 시작: ajutaxi-27_IONIQ 2019_201701.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 3.3% | 성공: 1 | 실패: 7 | 예상 남은 시간: 7분 23.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m 🔄 처리 시작: ltgdg-14_BONGO3_2022.csv\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m 파일 병합 중 오류 (Client V011BE0024): time data \"2025-07-16 02:04:47.180\" doesn't match format \" %Y-%m-%d %H:%M:%S.%f\", at position 12006. You might want to try:\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format` if your strings have a consistent format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format='ISO8601'` if your strings are all ISO8601 but not necessarily in exactly the same format;\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m     - passing `format='mixed'`, and the format will be inferred for each element individually. You might want to use `dayfirst` alongside this.\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 3.8% | 성공: 2 | 실패: 7 | 예상 남은 시간: 7분 4.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m 월별 저장 중 오류: Can only use .dt accessor with datetimelike values\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m ✅ cjl-dgds-006_PORTER2.csv: 완료 (12,006행, 14.6초)\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88138)\u001b[0m 🔄 처리 시작: revu-n-32_EV6 LONGRANGE.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 4.2% | 성공: 3 | 실패: 7 | 예상 남은 시간: 6분 28.2초\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preprocess_batch_parallel pid=88134)\u001b[0m /var/folders/bv/f_x33dnx0_d87vg42cs2ff600000gn/T/ipykernel_63946/1523317319.py:105: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\u001b[32m [repeated 24x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(preproc_betterwhy_parallel pid=88184)\u001b[0m 📦 ltgdg-14_BONGO3_2022.csv: 3개 배치 병렬 처리 완료, 결합 중...\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88134)\u001b[0m 🔄 처리 시작: iamme77_IONIQ5 LONGRANGE 2022_202310.csv\n",
      "\u001b[36m(ProgressTracker pid=88139)\u001b[0m 📊 진행률: 4.6% | 성공: 4 | 실패: 7 | 예상 남은 시간: 7분 1.1초\n",
      "\u001b[36m(preproc_betterwhy_parallel pid=88155)\u001b[0m ✅ revu-n-68_EV6 LONGRANGE.csv: 완료 (18,800행, 17.6초)\n"
     ]
    }
   ],
   "source": [
    "for folder in folder_list:\n",
    "    csv_files = glob.glob(f\"{folder}/**/*.csv\", recursive=True)\n",
    "    \n",
    "    \n",
    "    # 병렬 처리 실행 (CPU 코어 수의 80% 사용)\n",
    "    results = process_multiple_files_parallel(\n",
    "        csv_files=csv_files,\n",
    "        output_dir=\"/Volumes/Data/betterwhy_processed\",\n",
    "        remove_duplicates=True,\n",
    "        max_workers=None  # None이면 자동으로 CPU 코어 수의 80% 사용\n",
    "    )\n",
    "\n",
    "    # 결과 분석\n",
    "    if results:\n",
    "        print(f\"\\n📊 최종 처리 통계:\")\n",
    "        print(f\"   - 총 처리 시간: {format_duration(results['total_duration'])}\")\n",
    "        print(f\"   - 파일당 평균: {format_duration(results['avg_duration_per_file'])}\")\n",
    "        print(f\"   - 성공률: {(results['successful']/results['total_files']*100):.1f}%\")\n",
    "        print(f\"   - 총 처리 행 수: {results['total_rows_processed']:,}행\")\n",
    "        print(f\"   - 시간당 처리량: {results['total_rows_processed']/(results['total_duration']/3600):.0f}행/시간\")\n",
    "\n",
    "    # Ray 종료\n",
    "    ray.shutdown()\n",
    "    print(\"🔚 Ray 종료 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ec2380",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# ⭐⭐ 1. 대상 폴더 경로를 설정하세요. ⭐⭐\n",
    "# 현재 스크립트가 실행되는 폴더의 모든 CSV 파일을 대상으로 합니다.\n",
    "# 만약 '/Volumes/Data/betterwhy_origin/' 폴더 내의 파일을 대상으로 한다면:\n",
    "file_path_pattern = '/Volumes/Data/betterwhy_processed/**/*.csv'\n",
    "\n",
    "# glob.glob() 함수를 사용하여 모든 CSV 파일 경로를 찾습니다.\n",
    "# recursive=True를 사용하면 하위 폴더까지 재귀적으로 검색합니다.\n",
    "csv_files = glob.glob(file_path_pattern, recursive=True)\n",
    "\n",
    "# 변경된 파일 개수 카운트\n",
    "renamed_count = 0\n",
    "\n",
    "print(f\"총 {len(csv_files)}개의 CSV 파일을 찾았습니다.\")\n",
    "\n",
    "# 2. 각 파일에 대해 반복문 실행\n",
    "for old_file_path in csv_files:\n",
    "    # 파일명에서 'clientid_' 접두사를 확인하고 제거합니다.\n",
    "    # os.path.basename()은 경로에서 파일 이름만 추출합니다.\n",
    "    old_filename = os.path.basename(old_file_path)\n",
    "\n",
    "    # 파일 이름이 'clientid_'로 시작하는지 확인\n",
    "    if old_filename.startswith('clientid_'):\n",
    "        # 'clientid_'를 제거한 새로운 파일 이름 생성\n",
    "        new_filename = old_filename.replace('clientid_', '', 1)\n",
    "\n",
    "        # 새로운 파일의 전체 경로 생성\n",
    "        # os.path.dirname()은 파일 경로에서 디렉토리 부분만 추출합니다.\n",
    "        directory = os.path.dirname(old_file_path)\n",
    "        new_file_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        # 파일 이름 변경 (rename)\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"이름 변경 성공: '{old_filename}' -> '{new_filename}'\")\n",
    "            renamed_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"이름 변경 실패: '{old_filename}' -> '{new_filename}' - 오류: {e}\")\n",
    "            \n",
    "print(\"\\n--- 작업 완료 ---\")\n",
    "print(f\"총 {renamed_count}개의 파일 이름을 변경했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
